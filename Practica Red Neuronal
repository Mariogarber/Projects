{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mariogarber/Projects/blob/main/Practica%20Red%20Neuronal\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOSlxPKMUpNJ"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pncsa2gVlpQ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "9b482204-bab0-4893-b380-c87738082db4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gdrive'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-09dc62a1fa91>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gdrive'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, InputLayer\n",
        "from keras.initializers import he_normal\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxZxg9IaUrom"
      },
      "source": [
        "# Lad data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1WUofVVZuVU"
      },
      "outputs": [],
      "source": [
        "#path Mario\n",
        "OUTPUT_PATH = \"drive/MyDrive/Colab Notebooks/Aprendizaje2/Practica1/HotelReservationsOutput.csv\"\n",
        "DATA_PATH = \"drive/MyDrive/Colab Notebooks/Aprendizaje2/Practica1/HotelReservationsPreparedCleanAttributes.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421kzT4MS5eU"
      },
      "outputs": [],
      "source": [
        "# path Adonis\n",
        "#drive.mount('/gdrive', force_remount=True)\n",
        "OUTPUT_PATH = \"/gdrive/MyDrive/GIA/AA2/datasets/HotelReservations/HotelReservationsOutput.csv\"\n",
        "DATA_PATH = \"/gdrive/MyDrive/GIA/AA2/datasets/HotelReservations/HotelReservationsPreparedCleanAttributes.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-2qxuCLaXt2"
      },
      "source": [
        "Create the train, development and test subsets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Lgk6nnZ_mUDc",
        "outputId": "95141f9e-8ff9-4763-c648-38d4782f253c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Aprendizaje2/Practica1/HotelReservationsOutput.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a28a530e94b6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Aprendizaje2/Practica1/HotelReservationsOutput.csv'"
          ]
        }
      ],
      "source": [
        "labels = pd.read_csv(OUTPUT_PATH)\n",
        "data = pd.read_csv(DATA_PATH)\n",
        "\n",
        "num_train = int(len(data)*0.8)\n",
        "num_dev = num_train + int((len(data)-num_train)/2)\n",
        "\n",
        "data_train = data[:num_train]\n",
        "labels_train = labels[:num_train]\n",
        "\n",
        "data_dev = data[num_train:num_dev]\n",
        "labels_dev = labels[num_train:num_dev]\n",
        "\n",
        "data_test = data[num_dev:]\n",
        "labels_test = labels[num_dev:]\n",
        "\n",
        "data_train[:10]\n",
        "print(f\"Train: {data_train.shape[0]} | Dev: {data_dev.shape[0]} | Test: {data_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwoAHpzTZ6A1"
      },
      "source": [
        "Checking out the categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T1axpc0bc84",
        "outputId": "a81e8ec8-f662-42a7-bf73-4df1184bd43d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.unique(labels_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO50YEHqapbZ"
      },
      "source": [
        "## First model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlY3HngHzcI9",
        "outputId": "579979d5-71b8-458a-dc3a-21c84895385f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU disponible:  []\n"
          ]
        }
      ],
      "source": [
        "print(\"GPU disponible: \", tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJbovgxduiCz",
        "outputId": "021ce9dc-0870-4731-ba33-b51da187714f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "52/52 [==============================] - 6s 34ms/step - loss: 0.4716 - accuracy: 0.7723 - val_loss: 0.4302 - val_accuracy: 0.7974\n",
            "Epoch 2/1000\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.4151 - accuracy: 0.8040 - val_loss: 0.4105 - val_accuracy: 0.8001\n",
            "Epoch 3/1000\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.3913 - accuracy: 0.8185 - val_loss: 0.4160 - val_accuracy: 0.8053\n",
            "Epoch 4/1000\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.3791 - accuracy: 0.8255 - val_loss: 0.3875 - val_accuracy: 0.8241\n",
            "Epoch 5/1000\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.3708 - accuracy: 0.8314 - val_loss: 0.3805 - val_accuracy: 0.8285\n",
            "Epoch 6/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.3593 - accuracy: 0.8356 - val_loss: 0.3645 - val_accuracy: 0.8387\n",
            "Epoch 7/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.3522 - accuracy: 0.8390 - val_loss: 0.3635 - val_accuracy: 0.8393\n",
            "Epoch 8/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.3453 - accuracy: 0.8435 - val_loss: 0.3687 - val_accuracy: 0.8368\n",
            "Epoch 9/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.3388 - accuracy: 0.8475 - val_loss: 0.3700 - val_accuracy: 0.8371\n",
            "Epoch 10/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.3317 - accuracy: 0.8496 - val_loss: 0.3524 - val_accuracy: 0.8423\n",
            "Epoch 11/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.3280 - accuracy: 0.8530 - val_loss: 0.3537 - val_accuracy: 0.8398\n",
            "Epoch 12/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.3231 - accuracy: 0.8555 - val_loss: 0.3465 - val_accuracy: 0.8456\n",
            "Epoch 13/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.3213 - accuracy: 0.8562 - val_loss: 0.3447 - val_accuracy: 0.8462\n",
            "Epoch 14/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.3253 - accuracy: 0.8543 - val_loss: 0.3461 - val_accuracy: 0.8481\n",
            "Epoch 15/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.3084 - accuracy: 0.8624 - val_loss: 0.3388 - val_accuracy: 0.8486\n",
            "Epoch 16/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.3055 - accuracy: 0.8614 - val_loss: 0.3418 - val_accuracy: 0.8478\n",
            "Epoch 17/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.3075 - accuracy: 0.8615 - val_loss: 0.3397 - val_accuracy: 0.8492\n",
            "Epoch 18/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2983 - accuracy: 0.8652 - val_loss: 0.3380 - val_accuracy: 0.8533\n",
            "Epoch 19/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2955 - accuracy: 0.8673 - val_loss: 0.3357 - val_accuracy: 0.8500\n",
            "Epoch 20/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2893 - accuracy: 0.8707 - val_loss: 0.3353 - val_accuracy: 0.8594\n",
            "Epoch 21/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2899 - accuracy: 0.8694 - val_loss: 0.3337 - val_accuracy: 0.8569\n",
            "Epoch 22/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2840 - accuracy: 0.8707 - val_loss: 0.3310 - val_accuracy: 0.8541\n",
            "Epoch 23/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2811 - accuracy: 0.8739 - val_loss: 0.3317 - val_accuracy: 0.8564\n",
            "Epoch 24/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2772 - accuracy: 0.8759 - val_loss: 0.3405 - val_accuracy: 0.8536\n",
            "Epoch 25/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2803 - accuracy: 0.8745 - val_loss: 0.3365 - val_accuracy: 0.8519\n",
            "Epoch 26/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2750 - accuracy: 0.8759 - val_loss: 0.3568 - val_accuracy: 0.8561\n",
            "Epoch 27/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2725 - accuracy: 0.8783 - val_loss: 0.3367 - val_accuracy: 0.8519\n",
            "Epoch 28/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.2667 - accuracy: 0.8818 - val_loss: 0.3520 - val_accuracy: 0.8486\n",
            "Epoch 29/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.2691 - accuracy: 0.8807 - val_loss: 0.3426 - val_accuracy: 0.8519\n",
            "Epoch 30/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.2603 - accuracy: 0.8854 - val_loss: 0.3265 - val_accuracy: 0.8641\n",
            "Epoch 31/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.2573 - accuracy: 0.8863 - val_loss: 0.3418 - val_accuracy: 0.8442\n",
            "Epoch 32/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2579 - accuracy: 0.8848 - val_loss: 0.3493 - val_accuracy: 0.8577\n",
            "Epoch 33/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2662 - accuracy: 0.8810 - val_loss: 0.3397 - val_accuracy: 0.8533\n",
            "Epoch 34/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.2473 - accuracy: 0.8907 - val_loss: 0.3369 - val_accuracy: 0.8627\n",
            "Epoch 35/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2518 - accuracy: 0.8865 - val_loss: 0.3323 - val_accuracy: 0.8550\n",
            "Epoch 36/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2547 - accuracy: 0.8877 - val_loss: 0.3542 - val_accuracy: 0.8528\n",
            "Epoch 37/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2462 - accuracy: 0.8915 - val_loss: 0.3357 - val_accuracy: 0.8572\n",
            "Epoch 38/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2385 - accuracy: 0.8941 - val_loss: 0.3454 - val_accuracy: 0.8619\n",
            "Epoch 39/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2401 - accuracy: 0.8940 - val_loss: 0.3613 - val_accuracy: 0.8594\n",
            "Epoch 40/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2399 - accuracy: 0.8931 - val_loss: 0.3531 - val_accuracy: 0.8519\n",
            "Epoch 41/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2335 - accuracy: 0.8959 - val_loss: 0.3506 - val_accuracy: 0.8588\n",
            "Epoch 42/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2325 - accuracy: 0.8972 - val_loss: 0.3605 - val_accuracy: 0.8594\n",
            "Epoch 43/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2344 - accuracy: 0.8960 - val_loss: 0.3490 - val_accuracy: 0.8541\n",
            "Epoch 44/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2251 - accuracy: 0.9007 - val_loss: 0.3563 - val_accuracy: 0.8489\n",
            "Epoch 45/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2279 - accuracy: 0.8995 - val_loss: 0.3516 - val_accuracy: 0.8558\n",
            "Epoch 46/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.2234 - accuracy: 0.9003 - val_loss: 0.3676 - val_accuracy: 0.8550\n",
            "Epoch 47/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.2182 - accuracy: 0.9034 - val_loss: 0.3628 - val_accuracy: 0.8561\n",
            "Epoch 48/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.2168 - accuracy: 0.9029 - val_loss: 0.3586 - val_accuracy: 0.8657\n",
            "Epoch 49/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.2118 - accuracy: 0.9053 - val_loss: 0.3821 - val_accuracy: 0.8514\n",
            "Epoch 50/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2129 - accuracy: 0.9052 - val_loss: 0.3716 - val_accuracy: 0.8572\n",
            "Epoch 51/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2144 - accuracy: 0.9050 - val_loss: 0.3772 - val_accuracy: 0.8553\n",
            "Epoch 52/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.2158 - accuracy: 0.9057 - val_loss: 0.3651 - val_accuracy: 0.8583\n",
            "Epoch 53/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2100 - accuracy: 0.9070 - val_loss: 0.3717 - val_accuracy: 0.8668\n",
            "Epoch 54/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2036 - accuracy: 0.9092 - val_loss: 0.3712 - val_accuracy: 0.8619\n",
            "Epoch 55/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.2045 - accuracy: 0.9109 - val_loss: 0.3725 - val_accuracy: 0.8616\n",
            "Epoch 56/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2019 - accuracy: 0.9114 - val_loss: 0.3824 - val_accuracy: 0.8627\n",
            "Epoch 57/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.2010 - accuracy: 0.9111 - val_loss: 0.3868 - val_accuracy: 0.8530\n",
            "Epoch 58/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1972 - accuracy: 0.9119 - val_loss: 0.3903 - val_accuracy: 0.8569\n",
            "Epoch 59/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1927 - accuracy: 0.9157 - val_loss: 0.4105 - val_accuracy: 0.8602\n",
            "Epoch 60/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1962 - accuracy: 0.9127 - val_loss: 0.3929 - val_accuracy: 0.8624\n",
            "Epoch 61/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1980 - accuracy: 0.9122 - val_loss: 0.4090 - val_accuracy: 0.8536\n",
            "Epoch 62/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1954 - accuracy: 0.9129 - val_loss: 0.4032 - val_accuracy: 0.8599\n",
            "Epoch 63/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1897 - accuracy: 0.9172 - val_loss: 0.4076 - val_accuracy: 0.8558\n",
            "Epoch 64/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.1996 - accuracy: 0.9108 - val_loss: 0.4084 - val_accuracy: 0.8583\n",
            "Epoch 65/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1871 - accuracy: 0.9177 - val_loss: 0.4088 - val_accuracy: 0.8657\n",
            "Epoch 66/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1820 - accuracy: 0.9211 - val_loss: 0.3990 - val_accuracy: 0.8564\n",
            "Epoch 67/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1818 - accuracy: 0.9190 - val_loss: 0.3966 - val_accuracy: 0.8679\n",
            "Epoch 68/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.1765 - accuracy: 0.9222 - val_loss: 0.4090 - val_accuracy: 0.8588\n",
            "Epoch 69/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1797 - accuracy: 0.9203 - val_loss: 0.4297 - val_accuracy: 0.8602\n",
            "Epoch 70/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1759 - accuracy: 0.9235 - val_loss: 0.4129 - val_accuracy: 0.8616\n",
            "Epoch 71/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1731 - accuracy: 0.9243 - val_loss: 0.4371 - val_accuracy: 0.8572\n",
            "Epoch 72/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1736 - accuracy: 0.9252 - val_loss: 0.4189 - val_accuracy: 0.8594\n",
            "Epoch 73/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1673 - accuracy: 0.9266 - val_loss: 0.4295 - val_accuracy: 0.8525\n",
            "Epoch 74/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1700 - accuracy: 0.9268 - val_loss: 0.4542 - val_accuracy: 0.8591\n",
            "Epoch 75/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1663 - accuracy: 0.9272 - val_loss: 0.4375 - val_accuracy: 0.8677\n",
            "Epoch 76/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1660 - accuracy: 0.9279 - val_loss: 0.4500 - val_accuracy: 0.8630\n",
            "Epoch 77/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1734 - accuracy: 0.9232 - val_loss: 0.4658 - val_accuracy: 0.8613\n",
            "Epoch 78/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1710 - accuracy: 0.9263 - val_loss: 0.4397 - val_accuracy: 0.8575\n",
            "Epoch 79/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1594 - accuracy: 0.9306 - val_loss: 0.4579 - val_accuracy: 0.8621\n",
            "Epoch 80/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1608 - accuracy: 0.9306 - val_loss: 0.4488 - val_accuracy: 0.8627\n",
            "Epoch 81/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1529 - accuracy: 0.9339 - val_loss: 0.4702 - val_accuracy: 0.8641\n",
            "Epoch 82/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1594 - accuracy: 0.9316 - val_loss: 0.4680 - val_accuracy: 0.8671\n",
            "Epoch 83/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.1562 - accuracy: 0.9326 - val_loss: 0.4695 - val_accuracy: 0.8605\n",
            "Epoch 84/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1582 - accuracy: 0.9316 - val_loss: 0.4853 - val_accuracy: 0.8591\n",
            "Epoch 85/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1531 - accuracy: 0.9332 - val_loss: 0.4701 - val_accuracy: 0.8519\n",
            "Epoch 86/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.1523 - accuracy: 0.9347 - val_loss: 0.4646 - val_accuracy: 0.8564\n",
            "Epoch 87/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.1551 - accuracy: 0.9327 - val_loss: 0.4791 - val_accuracy: 0.8522\n",
            "Epoch 88/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1503 - accuracy: 0.9338 - val_loss: 0.4758 - val_accuracy: 0.8621\n",
            "Epoch 89/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1443 - accuracy: 0.9380 - val_loss: 0.4884 - val_accuracy: 0.8475\n",
            "Epoch 90/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1477 - accuracy: 0.9352 - val_loss: 0.4774 - val_accuracy: 0.8616\n",
            "Epoch 91/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1442 - accuracy: 0.9382 - val_loss: 0.4897 - val_accuracy: 0.8610\n",
            "Epoch 92/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1437 - accuracy: 0.9388 - val_loss: 0.5008 - val_accuracy: 0.8621\n",
            "Epoch 93/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1405 - accuracy: 0.9396 - val_loss: 0.4912 - val_accuracy: 0.8586\n",
            "Epoch 94/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1403 - accuracy: 0.9399 - val_loss: 0.4990 - val_accuracy: 0.8657\n",
            "Epoch 95/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1442 - accuracy: 0.9390 - val_loss: 0.5099 - val_accuracy: 0.8641\n",
            "Epoch 96/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1381 - accuracy: 0.9413 - val_loss: 0.5162 - val_accuracy: 0.8641\n",
            "Epoch 97/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1357 - accuracy: 0.9418 - val_loss: 0.5128 - val_accuracy: 0.8550\n",
            "Epoch 98/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1386 - accuracy: 0.9410 - val_loss: 0.5222 - val_accuracy: 0.8671\n",
            "Epoch 99/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.1326 - accuracy: 0.9439 - val_loss: 0.5126 - val_accuracy: 0.8630\n",
            "Epoch 100/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1333 - accuracy: 0.9429 - val_loss: 0.5488 - val_accuracy: 0.8693\n",
            "Epoch 101/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.1322 - accuracy: 0.9431 - val_loss: 0.5183 - val_accuracy: 0.8561\n",
            "Epoch 102/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1300 - accuracy: 0.9436 - val_loss: 0.5068 - val_accuracy: 0.8646\n",
            "Epoch 103/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1304 - accuracy: 0.9440 - val_loss: 0.5299 - val_accuracy: 0.8605\n",
            "Epoch 104/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1281 - accuracy: 0.9459 - val_loss: 0.5578 - val_accuracy: 0.8657\n",
            "Epoch 105/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.1293 - accuracy: 0.9447 - val_loss: 0.5295 - val_accuracy: 0.8638\n",
            "Epoch 106/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1307 - accuracy: 0.9424 - val_loss: 0.5466 - val_accuracy: 0.8616\n",
            "Epoch 107/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1312 - accuracy: 0.9437 - val_loss: 0.5591 - val_accuracy: 0.8685\n",
            "Epoch 108/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.1239 - accuracy: 0.9468 - val_loss: 0.5448 - val_accuracy: 0.8616\n",
            "Epoch 109/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1263 - accuracy: 0.9463 - val_loss: 0.5653 - val_accuracy: 0.8682\n",
            "Epoch 110/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1280 - accuracy: 0.9453 - val_loss: 0.5493 - val_accuracy: 0.8701\n",
            "Epoch 111/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1286 - accuracy: 0.9449 - val_loss: 0.5747 - val_accuracy: 0.8619\n",
            "Epoch 112/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1204 - accuracy: 0.9487 - val_loss: 0.5674 - val_accuracy: 0.8627\n",
            "Epoch 113/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1255 - accuracy: 0.9462 - val_loss: 0.5819 - val_accuracy: 0.8561\n",
            "Epoch 114/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1313 - accuracy: 0.9442 - val_loss: 0.5810 - val_accuracy: 0.8663\n",
            "Epoch 115/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1235 - accuracy: 0.9476 - val_loss: 0.5629 - val_accuracy: 0.8635\n",
            "Epoch 116/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1150 - accuracy: 0.9513 - val_loss: 0.5974 - val_accuracy: 0.8677\n",
            "Epoch 117/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1129 - accuracy: 0.9529 - val_loss: 0.6041 - val_accuracy: 0.8610\n",
            "Epoch 118/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1139 - accuracy: 0.9516 - val_loss: 0.5896 - val_accuracy: 0.8641\n",
            "Epoch 119/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1172 - accuracy: 0.9503 - val_loss: 0.6181 - val_accuracy: 0.8619\n",
            "Epoch 120/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.1082 - accuracy: 0.9544 - val_loss: 0.6130 - val_accuracy: 0.8649\n",
            "Epoch 121/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1080 - accuracy: 0.9545 - val_loss: 0.6082 - val_accuracy: 0.8613\n",
            "Epoch 122/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.1165 - accuracy: 0.9503 - val_loss: 0.6167 - val_accuracy: 0.8564\n",
            "Epoch 123/1000\n",
            "52/52 [==============================] - 2s 36ms/step - loss: 0.1103 - accuracy: 0.9542 - val_loss: 0.6159 - val_accuracy: 0.8660\n",
            "Epoch 124/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1112 - accuracy: 0.9530 - val_loss: 0.6111 - val_accuracy: 0.8530\n",
            "Epoch 125/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1138 - accuracy: 0.9520 - val_loss: 0.6026 - val_accuracy: 0.8610\n",
            "Epoch 126/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1160 - accuracy: 0.9515 - val_loss: 0.6389 - val_accuracy: 0.8668\n",
            "Epoch 127/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1026 - accuracy: 0.9551 - val_loss: 0.6690 - val_accuracy: 0.8536\n",
            "Epoch 128/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.1068 - accuracy: 0.9550 - val_loss: 0.6127 - val_accuracy: 0.8677\n",
            "Epoch 129/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1047 - accuracy: 0.9552 - val_loss: 0.6380 - val_accuracy: 0.8586\n",
            "Epoch 130/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1149 - accuracy: 0.9511 - val_loss: 0.6688 - val_accuracy: 0.8630\n",
            "Epoch 131/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1084 - accuracy: 0.9535 - val_loss: 0.6241 - val_accuracy: 0.8649\n",
            "Epoch 132/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1047 - accuracy: 0.9552 - val_loss: 0.6598 - val_accuracy: 0.8555\n",
            "Epoch 133/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.1053 - accuracy: 0.9551 - val_loss: 0.6514 - val_accuracy: 0.8641\n",
            "Epoch 134/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1030 - accuracy: 0.9569 - val_loss: 0.6451 - val_accuracy: 0.8605\n",
            "Epoch 135/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1027 - accuracy: 0.9568 - val_loss: 0.6509 - val_accuracy: 0.8555\n",
            "Epoch 136/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1088 - accuracy: 0.9539 - val_loss: 0.6431 - val_accuracy: 0.8682\n",
            "Epoch 137/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0991 - accuracy: 0.9583 - val_loss: 0.6421 - val_accuracy: 0.8558\n",
            "Epoch 138/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.1029 - accuracy: 0.9571 - val_loss: 0.6676 - val_accuracy: 0.8550\n",
            "Epoch 139/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0970 - accuracy: 0.9588 - val_loss: 0.6709 - val_accuracy: 0.8649\n",
            "Epoch 140/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0935 - accuracy: 0.9605 - val_loss: 0.6908 - val_accuracy: 0.8630\n",
            "Epoch 141/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.1017 - accuracy: 0.9565 - val_loss: 0.6524 - val_accuracy: 0.8701\n",
            "Epoch 142/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0920 - accuracy: 0.9608 - val_loss: 0.6845 - val_accuracy: 0.8564\n",
            "Epoch 143/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0955 - accuracy: 0.9596 - val_loss: 0.6781 - val_accuracy: 0.8599\n",
            "Epoch 144/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0959 - accuracy: 0.9597 - val_loss: 0.6724 - val_accuracy: 0.8627\n",
            "Epoch 145/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0920 - accuracy: 0.9620 - val_loss: 0.6845 - val_accuracy: 0.8660\n",
            "Epoch 146/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0974 - accuracy: 0.9591 - val_loss: 0.6913 - val_accuracy: 0.8704\n",
            "Epoch 147/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0896 - accuracy: 0.9624 - val_loss: 0.7176 - val_accuracy: 0.8621\n",
            "Epoch 148/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0926 - accuracy: 0.9613 - val_loss: 0.6988 - val_accuracy: 0.8621\n",
            "Epoch 149/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0866 - accuracy: 0.9646 - val_loss: 0.7507 - val_accuracy: 0.8541\n",
            "Epoch 150/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0941 - accuracy: 0.9604 - val_loss: 0.7044 - val_accuracy: 0.8624\n",
            "Epoch 151/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0934 - accuracy: 0.9596 - val_loss: 0.7113 - val_accuracy: 0.8586\n",
            "Epoch 152/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0877 - accuracy: 0.9649 - val_loss: 0.6851 - val_accuracy: 0.8649\n",
            "Epoch 153/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.1010 - accuracy: 0.9571 - val_loss: 0.7257 - val_accuracy: 0.8679\n",
            "Epoch 154/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0943 - accuracy: 0.9598 - val_loss: 0.7268 - val_accuracy: 0.8652\n",
            "Epoch 155/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.0943 - accuracy: 0.9611 - val_loss: 0.7115 - val_accuracy: 0.8627\n",
            "Epoch 156/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0921 - accuracy: 0.9605 - val_loss: 0.7164 - val_accuracy: 0.8624\n",
            "Epoch 157/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0891 - accuracy: 0.9625 - val_loss: 0.7194 - val_accuracy: 0.8671\n",
            "Epoch 158/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0922 - accuracy: 0.9614 - val_loss: 0.7213 - val_accuracy: 0.8550\n",
            "Epoch 159/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0908 - accuracy: 0.9620 - val_loss: 0.7291 - val_accuracy: 0.8632\n",
            "Epoch 160/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0887 - accuracy: 0.9635 - val_loss: 0.7370 - val_accuracy: 0.8690\n",
            "Epoch 161/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0844 - accuracy: 0.9645 - val_loss: 0.7336 - val_accuracy: 0.8682\n",
            "Epoch 162/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0842 - accuracy: 0.9656 - val_loss: 0.7594 - val_accuracy: 0.8591\n",
            "Epoch 163/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0880 - accuracy: 0.9631 - val_loss: 0.7116 - val_accuracy: 0.8533\n",
            "Epoch 164/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0826 - accuracy: 0.9654 - val_loss: 0.7847 - val_accuracy: 0.8690\n",
            "Epoch 165/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0848 - accuracy: 0.9649 - val_loss: 0.7752 - val_accuracy: 0.8616\n",
            "Epoch 166/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0926 - accuracy: 0.9613 - val_loss: 0.7448 - val_accuracy: 0.8666\n",
            "Epoch 167/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0833 - accuracy: 0.9658 - val_loss: 0.7531 - val_accuracy: 0.8613\n",
            "Epoch 168/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.0843 - accuracy: 0.9650 - val_loss: 0.7595 - val_accuracy: 0.8519\n",
            "Epoch 169/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0847 - accuracy: 0.9645 - val_loss: 0.7617 - val_accuracy: 0.8646\n",
            "Epoch 170/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0802 - accuracy: 0.9673 - val_loss: 0.7826 - val_accuracy: 0.8616\n",
            "Epoch 171/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0768 - accuracy: 0.9677 - val_loss: 0.7593 - val_accuracy: 0.8608\n",
            "Epoch 172/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0792 - accuracy: 0.9667 - val_loss: 0.7853 - val_accuracy: 0.8621\n",
            "Epoch 173/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0772 - accuracy: 0.9693 - val_loss: 0.7867 - val_accuracy: 0.8671\n",
            "Epoch 174/1000\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.0728 - accuracy: 0.9701 - val_loss: 0.7885 - val_accuracy: 0.8679\n",
            "Epoch 175/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0761 - accuracy: 0.9683 - val_loss: 0.7629 - val_accuracy: 0.8677\n",
            "Epoch 176/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0742 - accuracy: 0.9690 - val_loss: 0.8020 - val_accuracy: 0.8660\n",
            "Epoch 177/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0790 - accuracy: 0.9672 - val_loss: 0.8146 - val_accuracy: 0.8533\n",
            "Epoch 178/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0832 - accuracy: 0.9663 - val_loss: 0.7908 - val_accuracy: 0.8602\n",
            "Epoch 179/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0801 - accuracy: 0.9663 - val_loss: 0.8179 - val_accuracy: 0.8657\n",
            "Epoch 180/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0817 - accuracy: 0.9671 - val_loss: 0.7973 - val_accuracy: 0.8641\n",
            "Epoch 181/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0793 - accuracy: 0.9679 - val_loss: 0.7893 - val_accuracy: 0.8660\n",
            "Epoch 182/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0817 - accuracy: 0.9658 - val_loss: 0.7834 - val_accuracy: 0.8627\n",
            "Epoch 183/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0796 - accuracy: 0.9683 - val_loss: 0.7819 - val_accuracy: 0.8610\n",
            "Epoch 184/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0816 - accuracy: 0.9666 - val_loss: 0.8029 - val_accuracy: 0.8635\n",
            "Epoch 185/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0795 - accuracy: 0.9667 - val_loss: 0.8208 - val_accuracy: 0.8657\n",
            "Epoch 186/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0762 - accuracy: 0.9682 - val_loss: 0.8446 - val_accuracy: 0.8608\n",
            "Epoch 187/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0719 - accuracy: 0.9706 - val_loss: 0.7877 - val_accuracy: 0.8602\n",
            "Epoch 188/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0689 - accuracy: 0.9720 - val_loss: 0.7954 - val_accuracy: 0.8652\n",
            "Epoch 189/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0748 - accuracy: 0.9709 - val_loss: 0.8097 - val_accuracy: 0.8674\n",
            "Epoch 190/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0773 - accuracy: 0.9683 - val_loss: 0.8073 - val_accuracy: 0.8674\n",
            "Epoch 191/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0708 - accuracy: 0.9706 - val_loss: 0.8394 - val_accuracy: 0.8575\n",
            "Epoch 192/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0778 - accuracy: 0.9674 - val_loss: 0.8119 - val_accuracy: 0.8624\n",
            "Epoch 193/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0713 - accuracy: 0.9718 - val_loss: 0.8164 - val_accuracy: 0.8594\n",
            "Epoch 194/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0708 - accuracy: 0.9714 - val_loss: 0.8438 - val_accuracy: 0.8655\n",
            "Epoch 195/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0660 - accuracy: 0.9736 - val_loss: 0.8503 - val_accuracy: 0.8613\n",
            "Epoch 196/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0652 - accuracy: 0.9728 - val_loss: 0.8421 - val_accuracy: 0.8677\n",
            "Epoch 197/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0687 - accuracy: 0.9713 - val_loss: 0.8349 - val_accuracy: 0.8602\n",
            "Epoch 198/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0721 - accuracy: 0.9704 - val_loss: 0.8651 - val_accuracy: 0.8530\n",
            "Epoch 199/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0822 - accuracy: 0.9657 - val_loss: 0.8588 - val_accuracy: 0.8616\n",
            "Epoch 200/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0839 - accuracy: 0.9661 - val_loss: 0.8257 - val_accuracy: 0.8641\n",
            "Epoch 201/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0758 - accuracy: 0.9682 - val_loss: 0.8534 - val_accuracy: 0.8652\n",
            "Epoch 202/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0797 - accuracy: 0.9669 - val_loss: 0.8159 - val_accuracy: 0.8677\n",
            "Epoch 203/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0863 - accuracy: 0.9645 - val_loss: 0.8067 - val_accuracy: 0.8594\n",
            "Epoch 204/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0731 - accuracy: 0.9707 - val_loss: 0.8501 - val_accuracy: 0.8613\n",
            "Epoch 205/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0690 - accuracy: 0.9713 - val_loss: 0.8233 - val_accuracy: 0.8646\n",
            "Epoch 206/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0697 - accuracy: 0.9708 - val_loss: 0.8270 - val_accuracy: 0.8668\n",
            "Epoch 207/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0702 - accuracy: 0.9710 - val_loss: 0.8427 - val_accuracy: 0.8657\n",
            "Epoch 208/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0649 - accuracy: 0.9733 - val_loss: 0.8397 - val_accuracy: 0.8621\n",
            "Epoch 209/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0693 - accuracy: 0.9720 - val_loss: 0.8868 - val_accuracy: 0.8597\n",
            "Epoch 210/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0674 - accuracy: 0.9729 - val_loss: 0.8697 - val_accuracy: 0.8657\n",
            "Epoch 211/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0719 - accuracy: 0.9716 - val_loss: 0.8373 - val_accuracy: 0.8644\n",
            "Epoch 212/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0665 - accuracy: 0.9734 - val_loss: 0.9188 - val_accuracy: 0.8729\n",
            "Epoch 213/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0720 - accuracy: 0.9716 - val_loss: 0.8643 - val_accuracy: 0.8619\n",
            "Epoch 214/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0657 - accuracy: 0.9730 - val_loss: 0.8570 - val_accuracy: 0.8638\n",
            "Epoch 215/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0649 - accuracy: 0.9733 - val_loss: 0.8689 - val_accuracy: 0.8619\n",
            "Epoch 216/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0620 - accuracy: 0.9743 - val_loss: 0.8603 - val_accuracy: 0.8693\n",
            "Epoch 217/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0579 - accuracy: 0.9768 - val_loss: 0.8775 - val_accuracy: 0.8699\n",
            "Epoch 218/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0603 - accuracy: 0.9750 - val_loss: 0.8948 - val_accuracy: 0.8646\n",
            "Epoch 219/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0654 - accuracy: 0.9738 - val_loss: 0.9020 - val_accuracy: 0.8657\n",
            "Epoch 220/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0683 - accuracy: 0.9720 - val_loss: 0.8374 - val_accuracy: 0.8627\n",
            "Epoch 221/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0810 - accuracy: 0.9667 - val_loss: 0.9055 - val_accuracy: 0.8674\n",
            "Epoch 222/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0696 - accuracy: 0.9715 - val_loss: 0.8869 - val_accuracy: 0.8616\n",
            "Epoch 223/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0675 - accuracy: 0.9730 - val_loss: 0.8706 - val_accuracy: 0.8655\n",
            "Epoch 224/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0695 - accuracy: 0.9725 - val_loss: 0.8976 - val_accuracy: 0.8666\n",
            "Epoch 225/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0665 - accuracy: 0.9725 - val_loss: 0.8753 - val_accuracy: 0.8613\n",
            "Epoch 226/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0630 - accuracy: 0.9748 - val_loss: 0.9134 - val_accuracy: 0.8621\n",
            "Epoch 227/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0610 - accuracy: 0.9756 - val_loss: 0.9215 - val_accuracy: 0.8638\n",
            "Epoch 228/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0614 - accuracy: 0.9751 - val_loss: 0.8931 - val_accuracy: 0.8674\n",
            "Epoch 229/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0583 - accuracy: 0.9764 - val_loss: 0.9374 - val_accuracy: 0.8621\n",
            "Epoch 230/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0573 - accuracy: 0.9769 - val_loss: 0.9210 - val_accuracy: 0.8677\n",
            "Epoch 231/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0642 - accuracy: 0.9739 - val_loss: 0.9082 - val_accuracy: 0.8693\n",
            "Epoch 232/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0599 - accuracy: 0.9755 - val_loss: 0.8865 - val_accuracy: 0.8646\n",
            "Epoch 233/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0577 - accuracy: 0.9765 - val_loss: 0.9679 - val_accuracy: 0.8674\n",
            "Epoch 234/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0669 - accuracy: 0.9725 - val_loss: 0.8955 - val_accuracy: 0.8652\n",
            "Epoch 235/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0659 - accuracy: 0.9735 - val_loss: 0.9372 - val_accuracy: 0.8668\n",
            "Epoch 236/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0687 - accuracy: 0.9725 - val_loss: 0.9052 - val_accuracy: 0.8712\n",
            "Epoch 237/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0704 - accuracy: 0.9717 - val_loss: 0.9057 - val_accuracy: 0.8583\n",
            "Epoch 238/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0692 - accuracy: 0.9716 - val_loss: 0.9579 - val_accuracy: 0.8566\n",
            "Epoch 239/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0718 - accuracy: 0.9706 - val_loss: 0.8922 - val_accuracy: 0.8635\n",
            "Epoch 240/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0664 - accuracy: 0.9722 - val_loss: 0.8559 - val_accuracy: 0.8641\n",
            "Epoch 241/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0609 - accuracy: 0.9749 - val_loss: 0.9179 - val_accuracy: 0.8608\n",
            "Epoch 242/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0554 - accuracy: 0.9778 - val_loss: 0.9098 - val_accuracy: 0.8668\n",
            "Epoch 243/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0550 - accuracy: 0.9776 - val_loss: 0.8962 - val_accuracy: 0.8624\n",
            "Epoch 244/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0547 - accuracy: 0.9778 - val_loss: 0.9022 - val_accuracy: 0.8638\n",
            "Epoch 245/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0593 - accuracy: 0.9755 - val_loss: 0.9450 - val_accuracy: 0.8677\n",
            "Epoch 246/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0617 - accuracy: 0.9746 - val_loss: 0.9154 - val_accuracy: 0.8646\n",
            "Epoch 247/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0613 - accuracy: 0.9749 - val_loss: 0.8914 - val_accuracy: 0.8594\n",
            "Epoch 248/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0579 - accuracy: 0.9764 - val_loss: 0.9146 - val_accuracy: 0.8668\n",
            "Epoch 249/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0651 - accuracy: 0.9742 - val_loss: 0.8722 - val_accuracy: 0.8605\n",
            "Epoch 250/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0684 - accuracy: 0.9737 - val_loss: 0.9349 - val_accuracy: 0.8663\n",
            "Epoch 251/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0669 - accuracy: 0.9730 - val_loss: 0.9281 - val_accuracy: 0.8613\n",
            "Epoch 252/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0633 - accuracy: 0.9744 - val_loss: 0.9397 - val_accuracy: 0.8613\n",
            "Epoch 253/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0587 - accuracy: 0.9759 - val_loss: 0.8968 - val_accuracy: 0.8652\n",
            "Epoch 254/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0613 - accuracy: 0.9757 - val_loss: 0.9417 - val_accuracy: 0.8635\n",
            "Epoch 255/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0586 - accuracy: 0.9765 - val_loss: 0.9159 - val_accuracy: 0.8619\n",
            "Epoch 256/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0599 - accuracy: 0.9762 - val_loss: 0.9200 - val_accuracy: 0.8572\n",
            "Epoch 257/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0571 - accuracy: 0.9773 - val_loss: 0.9618 - val_accuracy: 0.8641\n",
            "Epoch 258/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0618 - accuracy: 0.9757 - val_loss: 0.9656 - val_accuracy: 0.8679\n",
            "Epoch 259/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0651 - accuracy: 0.9745 - val_loss: 0.9512 - val_accuracy: 0.8644\n",
            "Epoch 260/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0678 - accuracy: 0.9725 - val_loss: 0.9497 - val_accuracy: 0.8530\n",
            "Epoch 261/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0637 - accuracy: 0.9744 - val_loss: 0.9417 - val_accuracy: 0.8599\n",
            "Epoch 262/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0658 - accuracy: 0.9735 - val_loss: 0.9467 - val_accuracy: 0.8619\n",
            "Epoch 263/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0574 - accuracy: 0.9765 - val_loss: 0.9467 - val_accuracy: 0.8649\n",
            "Epoch 264/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0540 - accuracy: 0.9783 - val_loss: 0.9497 - val_accuracy: 0.8671\n",
            "Epoch 265/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0527 - accuracy: 0.9789 - val_loss: 0.9643 - val_accuracy: 0.8632\n",
            "Epoch 266/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0602 - accuracy: 0.9760 - val_loss: 0.9185 - val_accuracy: 0.8553\n",
            "Epoch 267/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0571 - accuracy: 0.9764 - val_loss: 0.9198 - val_accuracy: 0.8649\n",
            "Epoch 268/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0490 - accuracy: 0.9798 - val_loss: 0.9790 - val_accuracy: 0.8619\n",
            "Epoch 269/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0511 - accuracy: 0.9796 - val_loss: 0.9388 - val_accuracy: 0.8652\n",
            "Epoch 270/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0529 - accuracy: 0.9783 - val_loss: 0.9593 - val_accuracy: 0.8688\n",
            "Epoch 271/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0594 - accuracy: 0.9749 - val_loss: 0.9736 - val_accuracy: 0.8690\n",
            "Epoch 272/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0566 - accuracy: 0.9776 - val_loss: 0.9528 - val_accuracy: 0.8674\n",
            "Epoch 273/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0529 - accuracy: 0.9788 - val_loss: 0.9728 - val_accuracy: 0.8699\n",
            "Epoch 274/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0563 - accuracy: 0.9774 - val_loss: 0.9252 - val_accuracy: 0.8707\n",
            "Epoch 275/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0577 - accuracy: 0.9777 - val_loss: 0.9155 - val_accuracy: 0.8641\n",
            "Epoch 276/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0586 - accuracy: 0.9766 - val_loss: 0.9495 - val_accuracy: 0.8660\n",
            "Epoch 277/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0558 - accuracy: 0.9777 - val_loss: 0.9364 - val_accuracy: 0.8696\n",
            "Epoch 278/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0533 - accuracy: 0.9779 - val_loss: 0.9584 - val_accuracy: 0.8693\n",
            "Epoch 279/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0569 - accuracy: 0.9775 - val_loss: 0.9310 - val_accuracy: 0.8649\n",
            "Epoch 280/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0519 - accuracy: 0.9791 - val_loss: 0.9467 - val_accuracy: 0.8613\n",
            "Epoch 281/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0516 - accuracy: 0.9796 - val_loss: 0.9768 - val_accuracy: 0.8701\n",
            "Epoch 282/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0653 - accuracy: 0.9743 - val_loss: 0.9236 - val_accuracy: 0.8638\n",
            "Epoch 283/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0616 - accuracy: 0.9755 - val_loss: 0.9563 - val_accuracy: 0.8693\n",
            "Epoch 284/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0578 - accuracy: 0.9759 - val_loss: 0.9554 - val_accuracy: 0.8718\n",
            "Epoch 285/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0543 - accuracy: 0.9786 - val_loss: 0.9701 - val_accuracy: 0.8674\n",
            "Epoch 286/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0589 - accuracy: 0.9760 - val_loss: 0.9950 - val_accuracy: 0.8555\n",
            "Epoch 287/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0566 - accuracy: 0.9766 - val_loss: 0.9494 - val_accuracy: 0.8644\n",
            "Epoch 288/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0549 - accuracy: 0.9783 - val_loss: 0.9980 - val_accuracy: 0.8613\n",
            "Epoch 289/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0608 - accuracy: 0.9756 - val_loss: 0.9696 - val_accuracy: 0.8649\n",
            "Epoch 290/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0575 - accuracy: 0.9767 - val_loss: 0.9409 - val_accuracy: 0.8677\n",
            "Epoch 291/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0562 - accuracy: 0.9766 - val_loss: 0.9522 - val_accuracy: 0.8668\n",
            "Epoch 292/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0493 - accuracy: 0.9802 - val_loss: 1.0201 - val_accuracy: 0.8696\n",
            "Epoch 293/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0508 - accuracy: 0.9800 - val_loss: 0.9560 - val_accuracy: 0.8679\n",
            "Epoch 294/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0515 - accuracy: 0.9795 - val_loss: 0.9686 - val_accuracy: 0.8663\n",
            "Epoch 295/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0498 - accuracy: 0.9791 - val_loss: 0.9610 - val_accuracy: 0.8655\n",
            "Epoch 296/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0505 - accuracy: 0.9788 - val_loss: 0.9565 - val_accuracy: 0.8644\n",
            "Epoch 297/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0550 - accuracy: 0.9780 - val_loss: 0.9452 - val_accuracy: 0.8586\n",
            "Epoch 298/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0560 - accuracy: 0.9774 - val_loss: 0.9543 - val_accuracy: 0.8679\n",
            "Epoch 299/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0697 - accuracy: 0.9738 - val_loss: 0.9446 - val_accuracy: 0.8627\n",
            "Epoch 300/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0603 - accuracy: 0.9756 - val_loss: 0.9324 - val_accuracy: 0.8707\n",
            "Epoch 301/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0510 - accuracy: 0.9793 - val_loss: 0.9708 - val_accuracy: 0.8627\n",
            "Epoch 302/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0551 - accuracy: 0.9765 - val_loss: 0.9431 - val_accuracy: 0.8688\n",
            "Epoch 303/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0506 - accuracy: 0.9799 - val_loss: 0.9570 - val_accuracy: 0.8710\n",
            "Epoch 304/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0535 - accuracy: 0.9783 - val_loss: 0.9617 - val_accuracy: 0.8685\n",
            "Epoch 305/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0571 - accuracy: 0.9775 - val_loss: 0.9594 - val_accuracy: 0.8613\n",
            "Epoch 306/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0535 - accuracy: 0.9780 - val_loss: 0.9619 - val_accuracy: 0.8701\n",
            "Epoch 307/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0520 - accuracy: 0.9787 - val_loss: 0.9964 - val_accuracy: 0.8677\n",
            "Epoch 308/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0502 - accuracy: 0.9803 - val_loss: 0.9961 - val_accuracy: 0.8729\n",
            "Epoch 309/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0479 - accuracy: 0.9807 - val_loss: 0.9701 - val_accuracy: 0.8660\n",
            "Epoch 310/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0465 - accuracy: 0.9819 - val_loss: 0.9831 - val_accuracy: 0.8685\n",
            "Epoch 311/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0509 - accuracy: 0.9793 - val_loss: 0.9879 - val_accuracy: 0.8652\n",
            "Epoch 312/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0479 - accuracy: 0.9801 - val_loss: 0.9921 - val_accuracy: 0.8616\n",
            "Epoch 313/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0482 - accuracy: 0.9804 - val_loss: 0.9890 - val_accuracy: 0.8638\n",
            "Epoch 314/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0567 - accuracy: 0.9770 - val_loss: 1.0170 - val_accuracy: 0.8699\n",
            "Epoch 315/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0520 - accuracy: 0.9798 - val_loss: 0.9786 - val_accuracy: 0.8652\n",
            "Epoch 316/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0445 - accuracy: 0.9820 - val_loss: 1.0042 - val_accuracy: 0.8641\n",
            "Epoch 317/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0459 - accuracy: 0.9817 - val_loss: 1.0260 - val_accuracy: 0.8699\n",
            "Epoch 318/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0502 - accuracy: 0.9801 - val_loss: 0.9711 - val_accuracy: 0.8632\n",
            "Epoch 319/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0506 - accuracy: 0.9798 - val_loss: 0.9763 - val_accuracy: 0.8619\n",
            "Epoch 320/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0522 - accuracy: 0.9790 - val_loss: 0.9474 - val_accuracy: 0.8671\n",
            "Epoch 321/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0487 - accuracy: 0.9811 - val_loss: 1.0071 - val_accuracy: 0.8655\n",
            "Epoch 322/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0630 - accuracy: 0.9758 - val_loss: 0.9653 - val_accuracy: 0.8621\n",
            "Epoch 323/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0581 - accuracy: 0.9774 - val_loss: 1.0085 - val_accuracy: 0.8704\n",
            "Epoch 324/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0640 - accuracy: 0.9746 - val_loss: 0.9550 - val_accuracy: 0.8657\n",
            "Epoch 325/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0651 - accuracy: 0.9737 - val_loss: 0.9039 - val_accuracy: 0.8693\n",
            "Epoch 326/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0574 - accuracy: 0.9766 - val_loss: 0.9487 - val_accuracy: 0.8599\n",
            "Epoch 327/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0534 - accuracy: 0.9789 - val_loss: 0.9720 - val_accuracy: 0.8660\n",
            "Epoch 328/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0565 - accuracy: 0.9769 - val_loss: 0.9505 - val_accuracy: 0.8690\n",
            "Epoch 329/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0510 - accuracy: 0.9794 - val_loss: 0.9458 - val_accuracy: 0.8685\n",
            "Epoch 330/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0560 - accuracy: 0.9770 - val_loss: 1.0241 - val_accuracy: 0.8572\n",
            "Epoch 331/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0605 - accuracy: 0.9751 - val_loss: 0.9824 - val_accuracy: 0.8663\n",
            "Epoch 332/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0538 - accuracy: 0.9780 - val_loss: 0.9484 - val_accuracy: 0.8644\n",
            "Epoch 333/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0510 - accuracy: 0.9802 - val_loss: 0.9972 - val_accuracy: 0.8616\n",
            "Epoch 334/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0540 - accuracy: 0.9791 - val_loss: 0.9744 - val_accuracy: 0.8635\n",
            "Epoch 335/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0477 - accuracy: 0.9815 - val_loss: 0.9821 - val_accuracy: 0.8635\n",
            "Epoch 336/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0454 - accuracy: 0.9816 - val_loss: 0.9699 - val_accuracy: 0.8674\n",
            "Epoch 337/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0438 - accuracy: 0.9816 - val_loss: 1.0278 - val_accuracy: 0.8696\n",
            "Epoch 338/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0427 - accuracy: 0.9818 - val_loss: 1.0195 - val_accuracy: 0.8641\n",
            "Epoch 339/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0416 - accuracy: 0.9831 - val_loss: 0.9906 - val_accuracy: 0.8660\n",
            "Epoch 340/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0455 - accuracy: 0.9817 - val_loss: 1.0169 - val_accuracy: 0.8649\n",
            "Epoch 341/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0469 - accuracy: 0.9809 - val_loss: 0.9830 - val_accuracy: 0.8630\n",
            "Epoch 342/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0453 - accuracy: 0.9820 - val_loss: 1.0188 - val_accuracy: 0.8610\n",
            "Epoch 343/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0455 - accuracy: 0.9810 - val_loss: 1.0255 - val_accuracy: 0.8679\n",
            "Epoch 344/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0463 - accuracy: 0.9814 - val_loss: 1.0005 - val_accuracy: 0.8652\n",
            "Epoch 345/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0469 - accuracy: 0.9805 - val_loss: 1.0088 - val_accuracy: 0.8655\n",
            "Epoch 346/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0462 - accuracy: 0.9813 - val_loss: 0.9946 - val_accuracy: 0.8674\n",
            "Epoch 347/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 1.0206 - val_accuracy: 0.8699\n",
            "Epoch 348/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0464 - accuracy: 0.9807 - val_loss: 1.0466 - val_accuracy: 0.8630\n",
            "Epoch 349/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0510 - accuracy: 0.9791 - val_loss: 1.0338 - val_accuracy: 0.8610\n",
            "Epoch 350/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0517 - accuracy: 0.9789 - val_loss: 1.0004 - val_accuracy: 0.8649\n",
            "Epoch 351/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0450 - accuracy: 0.9821 - val_loss: 1.0502 - val_accuracy: 0.8591\n",
            "Epoch 352/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0465 - accuracy: 0.9818 - val_loss: 1.0467 - val_accuracy: 0.8704\n",
            "Epoch 353/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0477 - accuracy: 0.9802 - val_loss: 1.0362 - val_accuracy: 0.8671\n",
            "Epoch 354/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0502 - accuracy: 0.9806 - val_loss: 1.0208 - val_accuracy: 0.8610\n",
            "Epoch 355/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0485 - accuracy: 0.9801 - val_loss: 1.0334 - val_accuracy: 0.8608\n",
            "Epoch 356/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0478 - accuracy: 0.9806 - val_loss: 1.0257 - val_accuracy: 0.8644\n",
            "Epoch 357/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0545 - accuracy: 0.9784 - val_loss: 1.0309 - val_accuracy: 0.8638\n",
            "Epoch 358/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0493 - accuracy: 0.9800 - val_loss: 1.0458 - val_accuracy: 0.8668\n",
            "Epoch 359/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0553 - accuracy: 0.9791 - val_loss: 1.0380 - val_accuracy: 0.8655\n",
            "Epoch 360/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0463 - accuracy: 0.9814 - val_loss: 1.0477 - val_accuracy: 0.8608\n",
            "Epoch 361/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0458 - accuracy: 0.9818 - val_loss: 1.0075 - val_accuracy: 0.8621\n",
            "Epoch 362/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 1.0090 - val_accuracy: 0.8644\n",
            "Epoch 363/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0460 - accuracy: 0.9815 - val_loss: 1.0148 - val_accuracy: 0.8644\n",
            "Epoch 364/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0469 - accuracy: 0.9809 - val_loss: 1.0472 - val_accuracy: 0.8668\n",
            "Epoch 365/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0458 - accuracy: 0.9825 - val_loss: 1.0534 - val_accuracy: 0.8608\n",
            "Epoch 366/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0467 - accuracy: 0.9815 - val_loss: 1.0347 - val_accuracy: 0.8616\n",
            "Epoch 367/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0471 - accuracy: 0.9812 - val_loss: 1.0880 - val_accuracy: 0.8652\n",
            "Epoch 368/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0510 - accuracy: 0.9804 - val_loss: 1.0173 - val_accuracy: 0.8630\n",
            "Epoch 369/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0564 - accuracy: 0.9777 - val_loss: 1.0404 - val_accuracy: 0.8627\n",
            "Epoch 370/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0533 - accuracy: 0.9780 - val_loss: 1.0137 - val_accuracy: 0.8649\n",
            "Epoch 371/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0474 - accuracy: 0.9806 - val_loss: 1.0350 - val_accuracy: 0.8630\n",
            "Epoch 372/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0447 - accuracy: 0.9821 - val_loss: 1.0321 - val_accuracy: 0.8666\n",
            "Epoch 373/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0431 - accuracy: 0.9828 - val_loss: 1.0851 - val_accuracy: 0.8743\n",
            "Epoch 374/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0441 - accuracy: 0.9820 - val_loss: 1.0496 - val_accuracy: 0.8679\n",
            "Epoch 375/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0484 - accuracy: 0.9803 - val_loss: 1.0384 - val_accuracy: 0.8712\n",
            "Epoch 376/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0469 - accuracy: 0.9813 - val_loss: 1.0371 - val_accuracy: 0.8685\n",
            "Epoch 377/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0473 - accuracy: 0.9802 - val_loss: 1.0613 - val_accuracy: 0.8723\n",
            "Epoch 378/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0536 - accuracy: 0.9792 - val_loss: 1.0204 - val_accuracy: 0.8649\n",
            "Epoch 379/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0519 - accuracy: 0.9798 - val_loss: 1.0427 - val_accuracy: 0.8660\n",
            "Epoch 380/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0525 - accuracy: 0.9795 - val_loss: 1.0245 - val_accuracy: 0.8583\n",
            "Epoch 381/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0529 - accuracy: 0.9778 - val_loss: 0.9945 - val_accuracy: 0.8696\n",
            "Epoch 382/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0468 - accuracy: 0.9812 - val_loss: 1.0457 - val_accuracy: 0.8630\n",
            "Epoch 383/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0432 - accuracy: 0.9824 - val_loss: 1.0229 - val_accuracy: 0.8621\n",
            "Epoch 384/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9823 - val_loss: 1.0495 - val_accuracy: 0.8663\n",
            "Epoch 385/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0445 - accuracy: 0.9830 - val_loss: 1.0418 - val_accuracy: 0.8668\n",
            "Epoch 386/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0473 - accuracy: 0.9814 - val_loss: 1.0301 - val_accuracy: 0.8668\n",
            "Epoch 387/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0502 - accuracy: 0.9794 - val_loss: 1.0688 - val_accuracy: 0.8668\n",
            "Epoch 388/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0496 - accuracy: 0.9797 - val_loss: 1.0516 - val_accuracy: 0.8646\n",
            "Epoch 389/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0456 - accuracy: 0.9816 - val_loss: 1.0157 - val_accuracy: 0.8655\n",
            "Epoch 390/1000\n",
            "52/52 [==============================] - 2s 38ms/step - loss: 0.0439 - accuracy: 0.9819 - val_loss: 1.0346 - val_accuracy: 0.8657\n",
            "Epoch 391/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0437 - accuracy: 0.9824 - val_loss: 1.0698 - val_accuracy: 0.8660\n",
            "Epoch 392/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0438 - accuracy: 0.9828 - val_loss: 1.0209 - val_accuracy: 0.8704\n",
            "Epoch 393/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0514 - accuracy: 0.9785 - val_loss: 1.0325 - val_accuracy: 0.8621\n",
            "Epoch 394/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0457 - accuracy: 0.9817 - val_loss: 1.0716 - val_accuracy: 0.8646\n",
            "Epoch 395/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0466 - accuracy: 0.9814 - val_loss: 1.0608 - val_accuracy: 0.8674\n",
            "Epoch 396/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0477 - accuracy: 0.9813 - val_loss: 1.0744 - val_accuracy: 0.8608\n",
            "Epoch 397/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0442 - accuracy: 0.9820 - val_loss: 1.0366 - val_accuracy: 0.8657\n",
            "Epoch 398/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0434 - accuracy: 0.9818 - val_loss: 1.1063 - val_accuracy: 0.8655\n",
            "Epoch 399/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0424 - accuracy: 0.9825 - val_loss: 1.0810 - val_accuracy: 0.8646\n",
            "Epoch 400/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0421 - accuracy: 0.9821 - val_loss: 1.0836 - val_accuracy: 0.8627\n",
            "Epoch 401/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0413 - accuracy: 0.9832 - val_loss: 1.0703 - val_accuracy: 0.8688\n",
            "Epoch 402/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0381 - accuracy: 0.9847 - val_loss: 1.0545 - val_accuracy: 0.8657\n",
            "Epoch 403/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0376 - accuracy: 0.9849 - val_loss: 1.0697 - val_accuracy: 0.8701\n",
            "Epoch 404/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0395 - accuracy: 0.9836 - val_loss: 1.0785 - val_accuracy: 0.8696\n",
            "Epoch 405/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0436 - accuracy: 0.9820 - val_loss: 1.0761 - val_accuracy: 0.8666\n",
            "Epoch 406/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0476 - accuracy: 0.9809 - val_loss: 1.0550 - val_accuracy: 0.8677\n",
            "Epoch 407/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0588 - accuracy: 0.9768 - val_loss: 1.0298 - val_accuracy: 0.8621\n",
            "Epoch 408/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0488 - accuracy: 0.9808 - val_loss: 1.0630 - val_accuracy: 0.8674\n",
            "Epoch 409/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0470 - accuracy: 0.9804 - val_loss: 1.0245 - val_accuracy: 0.8663\n",
            "Epoch 410/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0422 - accuracy: 0.9825 - val_loss: 1.0420 - val_accuracy: 0.8699\n",
            "Epoch 411/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0408 - accuracy: 0.9830 - val_loss: 1.0740 - val_accuracy: 0.8721\n",
            "Epoch 412/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0400 - accuracy: 0.9847 - val_loss: 1.0776 - val_accuracy: 0.8666\n",
            "Epoch 413/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0412 - accuracy: 0.9829 - val_loss: 1.0690 - val_accuracy: 0.8641\n",
            "Epoch 414/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0454 - accuracy: 0.9817 - val_loss: 1.0921 - val_accuracy: 0.8544\n",
            "Epoch 415/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0517 - accuracy: 0.9792 - val_loss: 1.1235 - val_accuracy: 0.8657\n",
            "Epoch 416/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0527 - accuracy: 0.9785 - val_loss: 1.0676 - val_accuracy: 0.8544\n",
            "Epoch 417/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0524 - accuracy: 0.9800 - val_loss: 1.0410 - val_accuracy: 0.8605\n",
            "Epoch 418/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0475 - accuracy: 0.9804 - val_loss: 1.0721 - val_accuracy: 0.8627\n",
            "Epoch 419/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0407 - accuracy: 0.9840 - val_loss: 1.0405 - val_accuracy: 0.8660\n",
            "Epoch 420/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9829 - val_loss: 1.0834 - val_accuracy: 0.8652\n",
            "Epoch 421/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0405 - accuracy: 0.9829 - val_loss: 1.0755 - val_accuracy: 0.8657\n",
            "Epoch 422/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0383 - accuracy: 0.9844 - val_loss: 1.0725 - val_accuracy: 0.8613\n",
            "Epoch 423/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0402 - accuracy: 0.9835 - val_loss: 1.0523 - val_accuracy: 0.8632\n",
            "Epoch 424/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0383 - accuracy: 0.9837 - val_loss: 1.0677 - val_accuracy: 0.8649\n",
            "Epoch 425/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0404 - accuracy: 0.9830 - val_loss: 1.0815 - val_accuracy: 0.8635\n",
            "Epoch 426/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0384 - accuracy: 0.9839 - val_loss: 1.0579 - val_accuracy: 0.8668\n",
            "Epoch 427/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0396 - accuracy: 0.9841 - val_loss: 1.0766 - val_accuracy: 0.8721\n",
            "Epoch 428/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0404 - accuracy: 0.9833 - val_loss: 1.0549 - val_accuracy: 0.8619\n",
            "Epoch 429/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0405 - accuracy: 0.9828 - val_loss: 1.1005 - val_accuracy: 0.8649\n",
            "Epoch 430/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0461 - accuracy: 0.9807 - val_loss: 1.0757 - val_accuracy: 0.8660\n",
            "Epoch 431/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0394 - accuracy: 0.9834 - val_loss: 1.0750 - val_accuracy: 0.8668\n",
            "Epoch 432/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0382 - accuracy: 0.9837 - val_loss: 1.0945 - val_accuracy: 0.8693\n",
            "Epoch 433/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9823 - val_loss: 1.1357 - val_accuracy: 0.8572\n",
            "Epoch 434/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0467 - accuracy: 0.9800 - val_loss: 1.0638 - val_accuracy: 0.8677\n",
            "Epoch 435/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0519 - accuracy: 0.9790 - val_loss: 1.1172 - val_accuracy: 0.8671\n",
            "Epoch 436/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0499 - accuracy: 0.9796 - val_loss: 1.1225 - val_accuracy: 0.8690\n",
            "Epoch 437/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0459 - accuracy: 0.9814 - val_loss: 1.1517 - val_accuracy: 0.8690\n",
            "Epoch 438/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0563 - accuracy: 0.9788 - val_loss: 1.0816 - val_accuracy: 0.8621\n",
            "Epoch 439/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0561 - accuracy: 0.9776 - val_loss: 1.0434 - val_accuracy: 0.8586\n",
            "Epoch 440/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0531 - accuracy: 0.9785 - val_loss: 1.0477 - val_accuracy: 0.8701\n",
            "Epoch 441/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0428 - accuracy: 0.9829 - val_loss: 1.0501 - val_accuracy: 0.8632\n",
            "Epoch 442/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0395 - accuracy: 0.9835 - val_loss: 1.0676 - val_accuracy: 0.8660\n",
            "Epoch 443/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0400 - accuracy: 0.9837 - val_loss: 1.0860 - val_accuracy: 0.8671\n",
            "Epoch 444/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0393 - accuracy: 0.9835 - val_loss: 1.0553 - val_accuracy: 0.8690\n",
            "Epoch 445/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0378 - accuracy: 0.9840 - val_loss: 1.1012 - val_accuracy: 0.8641\n",
            "Epoch 446/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0381 - accuracy: 0.9851 - val_loss: 1.0949 - val_accuracy: 0.8682\n",
            "Epoch 447/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0402 - accuracy: 0.9844 - val_loss: 1.0893 - val_accuracy: 0.8660\n",
            "Epoch 448/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0411 - accuracy: 0.9830 - val_loss: 1.1032 - val_accuracy: 0.8682\n",
            "Epoch 449/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0366 - accuracy: 0.9844 - val_loss: 1.0919 - val_accuracy: 0.8627\n",
            "Epoch 450/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0363 - accuracy: 0.9843 - val_loss: 1.0807 - val_accuracy: 0.8632\n",
            "Epoch 451/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0385 - accuracy: 0.9842 - val_loss: 1.1042 - val_accuracy: 0.8627\n",
            "Epoch 452/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0400 - accuracy: 0.9838 - val_loss: 1.1286 - val_accuracy: 0.8632\n",
            "Epoch 453/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 1.0791 - val_accuracy: 0.8619\n",
            "Epoch 454/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 1.0454 - val_accuracy: 0.8646\n",
            "Epoch 455/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0420 - accuracy: 0.9827 - val_loss: 1.1097 - val_accuracy: 0.8682\n",
            "Epoch 456/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0405 - accuracy: 0.9837 - val_loss: 1.0555 - val_accuracy: 0.8632\n",
            "Epoch 457/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0405 - accuracy: 0.9829 - val_loss: 1.0583 - val_accuracy: 0.8630\n",
            "Epoch 458/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0386 - accuracy: 0.9837 - val_loss: 1.0825 - val_accuracy: 0.8644\n",
            "Epoch 459/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0365 - accuracy: 0.9847 - val_loss: 1.1190 - val_accuracy: 0.8660\n",
            "Epoch 460/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0377 - accuracy: 0.9845 - val_loss: 1.1303 - val_accuracy: 0.8608\n",
            "Epoch 461/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0478 - accuracy: 0.9805 - val_loss: 1.0600 - val_accuracy: 0.8638\n",
            "Epoch 462/1000\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.0484 - accuracy: 0.9805 - val_loss: 1.0634 - val_accuracy: 0.8638\n",
            "Epoch 463/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0444 - accuracy: 0.9820 - val_loss: 1.0575 - val_accuracy: 0.8616\n",
            "Epoch 464/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0480 - accuracy: 0.9803 - val_loss: 1.1040 - val_accuracy: 0.8641\n",
            "Epoch 465/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0456 - accuracy: 0.9807 - val_loss: 1.1081 - val_accuracy: 0.8649\n",
            "Epoch 466/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0418 - accuracy: 0.9829 - val_loss: 1.1147 - val_accuracy: 0.8688\n",
            "Epoch 467/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0392 - accuracy: 0.9845 - val_loss: 1.1039 - val_accuracy: 0.8679\n",
            "Epoch 468/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0393 - accuracy: 0.9834 - val_loss: 1.1084 - val_accuracy: 0.8621\n",
            "Epoch 469/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0399 - accuracy: 0.9832 - val_loss: 1.1105 - val_accuracy: 0.8599\n",
            "Epoch 470/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0409 - accuracy: 0.9834 - val_loss: 1.0951 - val_accuracy: 0.8632\n",
            "Epoch 471/1000\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.0414 - accuracy: 0.9837 - val_loss: 1.1564 - val_accuracy: 0.8666\n",
            "Epoch 472/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0408 - accuracy: 0.9834 - val_loss: 1.0779 - val_accuracy: 0.8597\n",
            "Epoch 473/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0372 - accuracy: 0.9849 - val_loss: 1.0595 - val_accuracy: 0.8729\n",
            "Epoch 474/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0365 - accuracy: 0.9850 - val_loss: 1.1174 - val_accuracy: 0.8688\n",
            "Epoch 475/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0389 - accuracy: 0.9835 - val_loss: 1.1374 - val_accuracy: 0.8627\n",
            "Epoch 476/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0408 - accuracy: 0.9833 - val_loss: 1.1145 - val_accuracy: 0.8608\n",
            "Epoch 477/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0401 - accuracy: 0.9837 - val_loss: 1.1307 - val_accuracy: 0.8699\n",
            "Epoch 478/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0410 - accuracy: 0.9828 - val_loss: 1.1247 - val_accuracy: 0.8690\n",
            "Epoch 479/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0473 - accuracy: 0.9811 - val_loss: 1.1668 - val_accuracy: 0.8646\n",
            "Epoch 480/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0473 - accuracy: 0.9799 - val_loss: 1.1032 - val_accuracy: 0.8704\n",
            "Epoch 481/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0477 - accuracy: 0.9804 - val_loss: 1.0431 - val_accuracy: 0.8690\n",
            "Epoch 482/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0505 - accuracy: 0.9803 - val_loss: 1.0746 - val_accuracy: 0.8655\n",
            "Epoch 483/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0468 - accuracy: 0.9806 - val_loss: 1.0927 - val_accuracy: 0.8696\n",
            "Epoch 484/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0420 - accuracy: 0.9828 - val_loss: 1.0637 - val_accuracy: 0.8649\n",
            "Epoch 485/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0377 - accuracy: 0.9845 - val_loss: 1.1232 - val_accuracy: 0.8685\n",
            "Epoch 486/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0363 - accuracy: 0.9846 - val_loss: 1.1256 - val_accuracy: 0.8663\n",
            "Epoch 487/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0365 - accuracy: 0.9850 - val_loss: 1.0829 - val_accuracy: 0.8712\n",
            "Epoch 488/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0365 - accuracy: 0.9851 - val_loss: 1.0643 - val_accuracy: 0.8671\n",
            "Epoch 489/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0341 - accuracy: 0.9858 - val_loss: 1.1334 - val_accuracy: 0.8657\n",
            "Epoch 490/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0360 - accuracy: 0.9850 - val_loss: 1.1336 - val_accuracy: 0.8616\n",
            "Epoch 491/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0401 - accuracy: 0.9841 - val_loss: 1.1862 - val_accuracy: 0.8668\n",
            "Epoch 492/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0417 - accuracy: 0.9825 - val_loss: 1.0819 - val_accuracy: 0.8679\n",
            "Epoch 493/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0432 - accuracy: 0.9824 - val_loss: 1.0840 - val_accuracy: 0.8674\n",
            "Epoch 494/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0429 - accuracy: 0.9821 - val_loss: 1.1060 - val_accuracy: 0.8671\n",
            "Epoch 495/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0423 - accuracy: 0.9818 - val_loss: 1.0661 - val_accuracy: 0.8610\n",
            "Epoch 496/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0459 - accuracy: 0.9813 - val_loss: 1.1023 - val_accuracy: 0.8646\n",
            "Epoch 497/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0383 - accuracy: 0.9846 - val_loss: 1.0957 - val_accuracy: 0.8638\n",
            "Epoch 498/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0413 - accuracy: 0.9835 - val_loss: 1.0921 - val_accuracy: 0.8674\n",
            "Epoch 499/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0467 - accuracy: 0.9811 - val_loss: 1.0693 - val_accuracy: 0.8586\n",
            "Epoch 500/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0410 - accuracy: 0.9836 - val_loss: 1.0763 - val_accuracy: 0.8621\n",
            "Epoch 501/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0444 - accuracy: 0.9819 - val_loss: 1.0722 - val_accuracy: 0.8641\n",
            "Epoch 502/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0449 - accuracy: 0.9814 - val_loss: 1.1061 - val_accuracy: 0.8668\n",
            "Epoch 503/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0443 - accuracy: 0.9830 - val_loss: 1.1049 - val_accuracy: 0.8588\n",
            "Epoch 504/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0424 - accuracy: 0.9830 - val_loss: 1.0830 - val_accuracy: 0.8630\n",
            "Epoch 505/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0371 - accuracy: 0.9852 - val_loss: 1.1045 - val_accuracy: 0.8635\n",
            "Epoch 506/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0374 - accuracy: 0.9843 - val_loss: 1.1261 - val_accuracy: 0.8657\n",
            "Epoch 507/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0376 - accuracy: 0.9850 - val_loss: 1.1302 - val_accuracy: 0.8707\n",
            "Epoch 508/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0372 - accuracy: 0.9849 - val_loss: 1.1046 - val_accuracy: 0.8677\n",
            "Epoch 509/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0356 - accuracy: 0.9856 - val_loss: 1.1209 - val_accuracy: 0.8677\n",
            "Epoch 510/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0389 - accuracy: 0.9847 - val_loss: 1.1389 - val_accuracy: 0.8652\n",
            "Epoch 511/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0395 - accuracy: 0.9839 - val_loss: 1.1455 - val_accuracy: 0.8723\n",
            "Epoch 512/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9819 - val_loss: 1.1176 - val_accuracy: 0.8652\n",
            "Epoch 513/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0615 - accuracy: 0.9756 - val_loss: 1.0873 - val_accuracy: 0.8690\n",
            "Epoch 514/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0540 - accuracy: 0.9790 - val_loss: 1.0708 - val_accuracy: 0.8657\n",
            "Epoch 515/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0516 - accuracy: 0.9795 - val_loss: 1.0757 - val_accuracy: 0.8594\n",
            "Epoch 516/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0420 - accuracy: 0.9826 - val_loss: 1.1222 - val_accuracy: 0.8630\n",
            "Epoch 517/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0416 - accuracy: 0.9835 - val_loss: 1.0918 - val_accuracy: 0.8594\n",
            "Epoch 518/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0385 - accuracy: 0.9835 - val_loss: 1.1090 - val_accuracy: 0.8602\n",
            "Epoch 519/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0350 - accuracy: 0.9859 - val_loss: 1.1344 - val_accuracy: 0.8663\n",
            "Epoch 520/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0380 - accuracy: 0.9840 - val_loss: 1.1091 - val_accuracy: 0.8690\n",
            "Epoch 521/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 1.1581 - val_accuracy: 0.8671\n",
            "Epoch 522/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0351 - accuracy: 0.9853 - val_loss: 1.1417 - val_accuracy: 0.8668\n",
            "Epoch 523/1000\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.0421 - accuracy: 0.9832 - val_loss: 1.1418 - val_accuracy: 0.8630\n",
            "Epoch 524/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0428 - accuracy: 0.9821 - val_loss: 1.1163 - val_accuracy: 0.8666\n",
            "Epoch 525/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0388 - accuracy: 0.9838 - val_loss: 1.1567 - val_accuracy: 0.8638\n",
            "Epoch 526/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0366 - accuracy: 0.9857 - val_loss: 1.1500 - val_accuracy: 0.8682\n",
            "Epoch 527/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0357 - accuracy: 0.9852 - val_loss: 1.1237 - val_accuracy: 0.8638\n",
            "Epoch 528/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0352 - accuracy: 0.9858 - val_loss: 1.1617 - val_accuracy: 0.8610\n",
            "Epoch 529/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0371 - accuracy: 0.9842 - val_loss: 1.1343 - val_accuracy: 0.8657\n",
            "Epoch 530/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0346 - accuracy: 0.9851 - val_loss: 1.1680 - val_accuracy: 0.8685\n",
            "Epoch 531/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9844 - val_loss: 1.1549 - val_accuracy: 0.8674\n",
            "Epoch 532/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0397 - accuracy: 0.9841 - val_loss: 1.0558 - val_accuracy: 0.8624\n",
            "Epoch 533/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0437 - accuracy: 0.9821 - val_loss: 1.1200 - val_accuracy: 0.8536\n",
            "Epoch 534/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0430 - accuracy: 0.9820 - val_loss: 1.1016 - val_accuracy: 0.8624\n",
            "Epoch 535/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0387 - accuracy: 0.9848 - val_loss: 1.1600 - val_accuracy: 0.8679\n",
            "Epoch 536/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0381 - accuracy: 0.9845 - val_loss: 1.1161 - val_accuracy: 0.8668\n",
            "Epoch 537/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0350 - accuracy: 0.9852 - val_loss: 1.1284 - val_accuracy: 0.8627\n",
            "Epoch 538/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0400 - accuracy: 0.9840 - val_loss: 1.1171 - val_accuracy: 0.8688\n",
            "Epoch 539/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0366 - accuracy: 0.9845 - val_loss: 1.1155 - val_accuracy: 0.8619\n",
            "Epoch 540/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0345 - accuracy: 0.9854 - val_loss: 1.1126 - val_accuracy: 0.8630\n",
            "Epoch 541/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0375 - accuracy: 0.9849 - val_loss: 1.1438 - val_accuracy: 0.8599\n",
            "Epoch 542/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0385 - accuracy: 0.9844 - val_loss: 1.1429 - val_accuracy: 0.8677\n",
            "Epoch 543/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0329 - accuracy: 0.9859 - val_loss: 1.0888 - val_accuracy: 0.8644\n",
            "Epoch 544/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0379 - accuracy: 0.9844 - val_loss: 1.1095 - val_accuracy: 0.8652\n",
            "Epoch 545/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0374 - accuracy: 0.9841 - val_loss: 1.1414 - val_accuracy: 0.8632\n",
            "Epoch 546/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0352 - accuracy: 0.9849 - val_loss: 1.1260 - val_accuracy: 0.8641\n",
            "Epoch 547/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0328 - accuracy: 0.9861 - val_loss: 1.1059 - val_accuracy: 0.8666\n",
            "Epoch 548/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0343 - accuracy: 0.9862 - val_loss: 1.1358 - val_accuracy: 0.8704\n",
            "Epoch 549/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0330 - accuracy: 0.9860 - val_loss: 1.1535 - val_accuracy: 0.8679\n",
            "Epoch 550/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0364 - accuracy: 0.9846 - val_loss: 1.1488 - val_accuracy: 0.8613\n",
            "Epoch 551/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0431 - accuracy: 0.9823 - val_loss: 1.1296 - val_accuracy: 0.8699\n",
            "Epoch 552/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0474 - accuracy: 0.9806 - val_loss: 1.1214 - val_accuracy: 0.8610\n",
            "Epoch 553/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0465 - accuracy: 0.9818 - val_loss: 1.1142 - val_accuracy: 0.8583\n",
            "Epoch 554/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0451 - accuracy: 0.9823 - val_loss: 1.0948 - val_accuracy: 0.8699\n",
            "Epoch 555/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0390 - accuracy: 0.9836 - val_loss: 1.0794 - val_accuracy: 0.8652\n",
            "Epoch 556/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0350 - accuracy: 0.9851 - val_loss: 1.1129 - val_accuracy: 0.8627\n",
            "Epoch 557/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0343 - accuracy: 0.9858 - val_loss: 1.1182 - val_accuracy: 0.8652\n",
            "Epoch 558/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0383 - accuracy: 0.9836 - val_loss: 1.1672 - val_accuracy: 0.8696\n",
            "Epoch 559/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0432 - accuracy: 0.9828 - val_loss: 1.1155 - val_accuracy: 0.8577\n",
            "Epoch 560/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0421 - accuracy: 0.9832 - val_loss: 1.1073 - val_accuracy: 0.8608\n",
            "Epoch 561/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0441 - accuracy: 0.9818 - val_loss: 1.0970 - val_accuracy: 0.8699\n",
            "Epoch 562/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0436 - accuracy: 0.9829 - val_loss: 1.1286 - val_accuracy: 0.8712\n",
            "Epoch 563/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0423 - accuracy: 0.9822 - val_loss: 1.1136 - val_accuracy: 0.8638\n",
            "Epoch 564/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0400 - accuracy: 0.9828 - val_loss: 1.1162 - val_accuracy: 0.8635\n",
            "Epoch 565/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0345 - accuracy: 0.9855 - val_loss: 1.1118 - val_accuracy: 0.8674\n",
            "Epoch 566/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0320 - accuracy: 0.9866 - val_loss: 1.1130 - val_accuracy: 0.8690\n",
            "Epoch 567/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0340 - accuracy: 0.9847 - val_loss: 1.1733 - val_accuracy: 0.8657\n",
            "Epoch 568/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.9856 - val_loss: 1.1880 - val_accuracy: 0.8682\n",
            "Epoch 569/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0334 - accuracy: 0.9862 - val_loss: 1.1211 - val_accuracy: 0.8616\n",
            "Epoch 570/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0330 - accuracy: 0.9855 - val_loss: 1.1945 - val_accuracy: 0.8674\n",
            "Epoch 571/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0324 - accuracy: 0.9867 - val_loss: 1.1796 - val_accuracy: 0.8704\n",
            "Epoch 572/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0344 - accuracy: 0.9855 - val_loss: 1.1390 - val_accuracy: 0.8652\n",
            "Epoch 573/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0368 - accuracy: 0.9848 - val_loss: 1.2089 - val_accuracy: 0.8715\n",
            "Epoch 574/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0375 - accuracy: 0.9844 - val_loss: 1.1793 - val_accuracy: 0.8591\n",
            "Epoch 575/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0377 - accuracy: 0.9850 - val_loss: 1.1823 - val_accuracy: 0.8627\n",
            "Epoch 576/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0366 - accuracy: 0.9846 - val_loss: 1.1573 - val_accuracy: 0.8677\n",
            "Epoch 577/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0392 - accuracy: 0.9833 - val_loss: 1.1693 - val_accuracy: 0.8613\n",
            "Epoch 578/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0486 - accuracy: 0.9802 - val_loss: 1.1043 - val_accuracy: 0.8632\n",
            "Epoch 579/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0429 - accuracy: 0.9821 - val_loss: 1.1217 - val_accuracy: 0.8663\n",
            "Epoch 580/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0538 - accuracy: 0.9791 - val_loss: 1.0816 - val_accuracy: 0.8674\n",
            "Epoch 581/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0442 - accuracy: 0.9823 - val_loss: 1.0769 - val_accuracy: 0.8690\n",
            "Epoch 582/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0482 - accuracy: 0.9813 - val_loss: 1.0802 - val_accuracy: 0.8635\n",
            "Epoch 583/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0435 - accuracy: 0.9823 - val_loss: 1.0730 - val_accuracy: 0.8608\n",
            "Epoch 584/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0373 - accuracy: 0.9853 - val_loss: 1.0767 - val_accuracy: 0.8663\n",
            "Epoch 585/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0325 - accuracy: 0.9864 - val_loss: 1.1322 - val_accuracy: 0.8624\n",
            "Epoch 586/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 1.1293 - val_accuracy: 0.8690\n",
            "Epoch 587/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0324 - accuracy: 0.9864 - val_loss: 1.1503 - val_accuracy: 0.8671\n",
            "Epoch 588/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0402 - accuracy: 0.9833 - val_loss: 1.1828 - val_accuracy: 0.8666\n",
            "Epoch 589/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0365 - accuracy: 0.9852 - val_loss: 1.1091 - val_accuracy: 0.8668\n",
            "Epoch 590/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0361 - accuracy: 0.9855 - val_loss: 1.1486 - val_accuracy: 0.8632\n",
            "Epoch 591/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0359 - accuracy: 0.9842 - val_loss: 1.1055 - val_accuracy: 0.8660\n",
            "Epoch 592/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0336 - accuracy: 0.9859 - val_loss: 1.1378 - val_accuracy: 0.8663\n",
            "Epoch 593/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0330 - accuracy: 0.9862 - val_loss: 1.0971 - val_accuracy: 0.8746\n",
            "Epoch 594/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0323 - accuracy: 0.9864 - val_loss: 1.1287 - val_accuracy: 0.8710\n",
            "Epoch 595/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0323 - accuracy: 0.9859 - val_loss: 1.1492 - val_accuracy: 0.8666\n",
            "Epoch 596/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0338 - accuracy: 0.9853 - val_loss: 1.1511 - val_accuracy: 0.8657\n",
            "Epoch 597/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0307 - accuracy: 0.9870 - val_loss: 1.1269 - val_accuracy: 0.8668\n",
            "Epoch 598/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0322 - accuracy: 0.9860 - val_loss: 1.1471 - val_accuracy: 0.8699\n",
            "Epoch 599/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0332 - accuracy: 0.9858 - val_loss: 1.1279 - val_accuracy: 0.8682\n",
            "Epoch 600/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0433 - accuracy: 0.9819 - val_loss: 1.1061 - val_accuracy: 0.8737\n",
            "Epoch 601/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0429 - accuracy: 0.9825 - val_loss: 1.1439 - val_accuracy: 0.8635\n",
            "Epoch 602/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0372 - accuracy: 0.9847 - val_loss: 1.1069 - val_accuracy: 0.8610\n",
            "Epoch 603/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0406 - accuracy: 0.9836 - val_loss: 1.1651 - val_accuracy: 0.8690\n",
            "Epoch 604/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0385 - accuracy: 0.9845 - val_loss: 1.0959 - val_accuracy: 0.8663\n",
            "Epoch 605/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0421 - accuracy: 0.9823 - val_loss: 1.1635 - val_accuracy: 0.8710\n",
            "Epoch 606/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0377 - accuracy: 0.9848 - val_loss: 1.1410 - val_accuracy: 0.8668\n",
            "Epoch 607/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0349 - accuracy: 0.9851 - val_loss: 1.1915 - val_accuracy: 0.8715\n",
            "Epoch 608/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0362 - accuracy: 0.9853 - val_loss: 1.1495 - val_accuracy: 0.8690\n",
            "Epoch 609/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0372 - accuracy: 0.9845 - val_loss: 1.0962 - val_accuracy: 0.8710\n",
            "Epoch 610/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0387 - accuracy: 0.9837 - val_loss: 1.1382 - val_accuracy: 0.8685\n",
            "Epoch 611/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0418 - accuracy: 0.9824 - val_loss: 1.1152 - val_accuracy: 0.8685\n",
            "Epoch 612/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0366 - accuracy: 0.9847 - val_loss: 1.1904 - val_accuracy: 0.8688\n",
            "Epoch 613/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0332 - accuracy: 0.9857 - val_loss: 1.1532 - val_accuracy: 0.8682\n",
            "Epoch 614/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0340 - accuracy: 0.9862 - val_loss: 1.1992 - val_accuracy: 0.8671\n",
            "Epoch 615/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0371 - accuracy: 0.9847 - val_loss: 1.1589 - val_accuracy: 0.8663\n",
            "Epoch 616/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 1.0781 - val_accuracy: 0.8718\n",
            "Epoch 617/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0313 - accuracy: 0.9868 - val_loss: 1.1221 - val_accuracy: 0.8652\n",
            "Epoch 618/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 1.1579 - val_accuracy: 0.8690\n",
            "Epoch 619/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0349 - accuracy: 0.9850 - val_loss: 1.1227 - val_accuracy: 0.8690\n",
            "Epoch 620/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0343 - accuracy: 0.9856 - val_loss: 1.1676 - val_accuracy: 0.8663\n",
            "Epoch 621/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0377 - accuracy: 0.9845 - val_loss: 1.1206 - val_accuracy: 0.8674\n",
            "Epoch 622/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0388 - accuracy: 0.9841 - val_loss: 1.1151 - val_accuracy: 0.8677\n",
            "Epoch 623/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0342 - accuracy: 0.9860 - val_loss: 1.2170 - val_accuracy: 0.8690\n",
            "Epoch 624/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0423 - accuracy: 0.9836 - val_loss: 1.1544 - val_accuracy: 0.8594\n",
            "Epoch 625/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0385 - accuracy: 0.9838 - val_loss: 1.1513 - val_accuracy: 0.8580\n",
            "Epoch 626/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0454 - accuracy: 0.9828 - val_loss: 1.1104 - val_accuracy: 0.8712\n",
            "Epoch 627/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0381 - accuracy: 0.9844 - val_loss: 1.1294 - val_accuracy: 0.8588\n",
            "Epoch 628/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0386 - accuracy: 0.9846 - val_loss: 1.0873 - val_accuracy: 0.8646\n",
            "Epoch 629/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0365 - accuracy: 0.9849 - val_loss: 1.1296 - val_accuracy: 0.8621\n",
            "Epoch 630/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0355 - accuracy: 0.9858 - val_loss: 1.1513 - val_accuracy: 0.8704\n",
            "Epoch 631/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0342 - accuracy: 0.9856 - val_loss: 1.1697 - val_accuracy: 0.8641\n",
            "Epoch 632/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0306 - accuracy: 0.9870 - val_loss: 1.1509 - val_accuracy: 0.8655\n",
            "Epoch 633/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0304 - accuracy: 0.9866 - val_loss: 1.1485 - val_accuracy: 0.8679\n",
            "Epoch 634/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0341 - accuracy: 0.9858 - val_loss: 1.1950 - val_accuracy: 0.8668\n",
            "Epoch 635/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0320 - accuracy: 0.9868 - val_loss: 1.1594 - val_accuracy: 0.8715\n",
            "Epoch 636/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0307 - accuracy: 0.9868 - val_loss: 1.1502 - val_accuracy: 0.8663\n",
            "Epoch 637/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0330 - accuracy: 0.9864 - val_loss: 1.1593 - val_accuracy: 0.8718\n",
            "Epoch 638/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9836 - val_loss: 1.0882 - val_accuracy: 0.8630\n",
            "Epoch 639/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0502 - accuracy: 0.9800 - val_loss: 1.1077 - val_accuracy: 0.8707\n",
            "Epoch 640/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0494 - accuracy: 0.9796 - val_loss: 1.1516 - val_accuracy: 0.8674\n",
            "Epoch 641/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0426 - accuracy: 0.9830 - val_loss: 1.1089 - val_accuracy: 0.8638\n",
            "Epoch 642/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0374 - accuracy: 0.9852 - val_loss: 1.1350 - val_accuracy: 0.8668\n",
            "Epoch 643/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0352 - accuracy: 0.9853 - val_loss: 1.1544 - val_accuracy: 0.8668\n",
            "Epoch 644/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0377 - accuracy: 0.9847 - val_loss: 1.1413 - val_accuracy: 0.8632\n",
            "Epoch 645/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0346 - accuracy: 0.9853 - val_loss: 1.1606 - val_accuracy: 0.8685\n",
            "Epoch 646/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0332 - accuracy: 0.9858 - val_loss: 1.1042 - val_accuracy: 0.8707\n",
            "Epoch 647/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0334 - accuracy: 0.9855 - val_loss: 1.1810 - val_accuracy: 0.8732\n",
            "Epoch 648/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0334 - accuracy: 0.9856 - val_loss: 1.1313 - val_accuracy: 0.8663\n",
            "Epoch 649/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0354 - accuracy: 0.9849 - val_loss: 1.1271 - val_accuracy: 0.8682\n",
            "Epoch 650/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0348 - accuracy: 0.9848 - val_loss: 1.1308 - val_accuracy: 0.8707\n",
            "Epoch 651/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0372 - accuracy: 0.9847 - val_loss: 1.1417 - val_accuracy: 0.8723\n",
            "Epoch 652/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0411 - accuracy: 0.9827 - val_loss: 1.1422 - val_accuracy: 0.8668\n",
            "Epoch 653/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0326 - accuracy: 0.9853 - val_loss: 1.1550 - val_accuracy: 0.8674\n",
            "Epoch 654/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0332 - accuracy: 0.9854 - val_loss: 1.1382 - val_accuracy: 0.8701\n",
            "Epoch 655/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0320 - accuracy: 0.9860 - val_loss: 1.1341 - val_accuracy: 0.8696\n",
            "Epoch 656/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0323 - accuracy: 0.9861 - val_loss: 1.1871 - val_accuracy: 0.8734\n",
            "Epoch 657/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0339 - accuracy: 0.9862 - val_loss: 1.1438 - val_accuracy: 0.8671\n",
            "Epoch 658/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0331 - accuracy: 0.9860 - val_loss: 1.1651 - val_accuracy: 0.8696\n",
            "Epoch 659/1000\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.0349 - accuracy: 0.9861 - val_loss: 1.1388 - val_accuracy: 0.8641\n",
            "Epoch 660/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0344 - accuracy: 0.9856 - val_loss: 1.1428 - val_accuracy: 0.8668\n",
            "Epoch 661/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0327 - accuracy: 0.9866 - val_loss: 1.2354 - val_accuracy: 0.8712\n",
            "Epoch 662/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0332 - accuracy: 0.9858 - val_loss: 1.1284 - val_accuracy: 0.8699\n",
            "Epoch 663/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0334 - accuracy: 0.9854 - val_loss: 1.1689 - val_accuracy: 0.8721\n",
            "Epoch 664/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0345 - accuracy: 0.9862 - val_loss: 1.1627 - val_accuracy: 0.8693\n",
            "Epoch 665/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0320 - accuracy: 0.9866 - val_loss: 1.1433 - val_accuracy: 0.8660\n",
            "Epoch 666/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0321 - accuracy: 0.9860 - val_loss: 1.1563 - val_accuracy: 0.8746\n",
            "Epoch 667/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0310 - accuracy: 0.9866 - val_loss: 1.1423 - val_accuracy: 0.8682\n",
            "Epoch 668/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0405 - accuracy: 0.9840 - val_loss: 1.0739 - val_accuracy: 0.8712\n",
            "Epoch 669/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0375 - accuracy: 0.9849 - val_loss: 1.1826 - val_accuracy: 0.8715\n",
            "Epoch 670/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0416 - accuracy: 0.9834 - val_loss: 1.1381 - val_accuracy: 0.8646\n",
            "Epoch 671/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0411 - accuracy: 0.9831 - val_loss: 1.1209 - val_accuracy: 0.8558\n",
            "Epoch 672/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0370 - accuracy: 0.9846 - val_loss: 1.1331 - val_accuracy: 0.8688\n",
            "Epoch 673/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0365 - accuracy: 0.9849 - val_loss: 1.2011 - val_accuracy: 0.8666\n",
            "Epoch 674/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0385 - accuracy: 0.9849 - val_loss: 1.1594 - val_accuracy: 0.8657\n",
            "Epoch 675/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0382 - accuracy: 0.9839 - val_loss: 1.2016 - val_accuracy: 0.8666\n",
            "Epoch 676/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0471 - accuracy: 0.9813 - val_loss: 1.1478 - val_accuracy: 0.8707\n",
            "Epoch 677/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0424 - accuracy: 0.9825 - val_loss: 1.1808 - val_accuracy: 0.8632\n",
            "Epoch 678/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0386 - accuracy: 0.9842 - val_loss: 1.1556 - val_accuracy: 0.8704\n",
            "Epoch 679/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0344 - accuracy: 0.9855 - val_loss: 1.1579 - val_accuracy: 0.8638\n",
            "Epoch 680/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0332 - accuracy: 0.9856 - val_loss: 1.1504 - val_accuracy: 0.8638\n",
            "Epoch 681/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0308 - accuracy: 0.9871 - val_loss: 1.1676 - val_accuracy: 0.8721\n",
            "Epoch 682/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0340 - accuracy: 0.9856 - val_loss: 1.1736 - val_accuracy: 0.8710\n",
            "Epoch 683/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0331 - accuracy: 0.9857 - val_loss: 1.1606 - val_accuracy: 0.8666\n",
            "Epoch 684/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0375 - accuracy: 0.9850 - val_loss: 1.1281 - val_accuracy: 0.8701\n",
            "Epoch 685/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0354 - accuracy: 0.9844 - val_loss: 1.1159 - val_accuracy: 0.8715\n",
            "Epoch 686/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0324 - accuracy: 0.9864 - val_loss: 1.1826 - val_accuracy: 0.8707\n",
            "Epoch 687/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0372 - accuracy: 0.9850 - val_loss: 1.1324 - val_accuracy: 0.8723\n",
            "Epoch 688/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0335 - accuracy: 0.9859 - val_loss: 1.1503 - val_accuracy: 0.8666\n",
            "Epoch 689/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0352 - accuracy: 0.9857 - val_loss: 1.1659 - val_accuracy: 0.8704\n",
            "Epoch 690/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 1.2036 - val_accuracy: 0.8734\n",
            "Epoch 691/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 1.1854 - val_accuracy: 0.8765\n",
            "Epoch 692/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0321 - accuracy: 0.9863 - val_loss: 1.1804 - val_accuracy: 0.8685\n",
            "Epoch 693/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 1.1376 - val_accuracy: 0.8718\n",
            "Epoch 694/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0325 - accuracy: 0.9865 - val_loss: 1.1825 - val_accuracy: 0.8729\n",
            "Epoch 695/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0307 - accuracy: 0.9872 - val_loss: 1.1491 - val_accuracy: 0.8641\n",
            "Epoch 696/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0312 - accuracy: 0.9862 - val_loss: 1.1472 - val_accuracy: 0.8679\n",
            "Epoch 697/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 1.1683 - val_accuracy: 0.8685\n",
            "Epoch 698/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0316 - accuracy: 0.9859 - val_loss: 1.2023 - val_accuracy: 0.8737\n",
            "Epoch 699/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0315 - accuracy: 0.9864 - val_loss: 1.2451 - val_accuracy: 0.8718\n",
            "Epoch 700/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0348 - accuracy: 0.9850 - val_loss: 1.1562 - val_accuracy: 0.8729\n",
            "Epoch 701/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0369 - accuracy: 0.9851 - val_loss: 1.1263 - val_accuracy: 0.8652\n",
            "Epoch 702/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0342 - accuracy: 0.9859 - val_loss: 1.1513 - val_accuracy: 0.8644\n",
            "Epoch 703/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0366 - accuracy: 0.9844 - val_loss: 1.1364 - val_accuracy: 0.8666\n",
            "Epoch 704/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0384 - accuracy: 0.9844 - val_loss: 1.1524 - val_accuracy: 0.8677\n",
            "Epoch 705/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0393 - accuracy: 0.9842 - val_loss: 1.1680 - val_accuracy: 0.8710\n",
            "Epoch 706/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0346 - accuracy: 0.9857 - val_loss: 1.1984 - val_accuracy: 0.8737\n",
            "Epoch 707/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0349 - accuracy: 0.9860 - val_loss: 1.1178 - val_accuracy: 0.8666\n",
            "Epoch 708/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0322 - accuracy: 0.9864 - val_loss: 1.1541 - val_accuracy: 0.8688\n",
            "Epoch 709/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0337 - accuracy: 0.9860 - val_loss: 1.1187 - val_accuracy: 0.8666\n",
            "Epoch 710/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0307 - accuracy: 0.9866 - val_loss: 1.1811 - val_accuracy: 0.8693\n",
            "Epoch 711/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0329 - accuracy: 0.9867 - val_loss: 1.1199 - val_accuracy: 0.8630\n",
            "Epoch 712/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0351 - accuracy: 0.9846 - val_loss: 1.1222 - val_accuracy: 0.8657\n",
            "Epoch 713/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0347 - accuracy: 0.9853 - val_loss: 1.1490 - val_accuracy: 0.8679\n",
            "Epoch 714/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0331 - accuracy: 0.9855 - val_loss: 1.1227 - val_accuracy: 0.8641\n",
            "Epoch 715/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0361 - accuracy: 0.9852 - val_loss: 1.1386 - val_accuracy: 0.8655\n",
            "Epoch 716/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0328 - accuracy: 0.9858 - val_loss: 1.1907 - val_accuracy: 0.8721\n",
            "Epoch 717/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0351 - accuracy: 0.9854 - val_loss: 1.1283 - val_accuracy: 0.8690\n",
            "Epoch 718/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0339 - accuracy: 0.9854 - val_loss: 1.1288 - val_accuracy: 0.8679\n",
            "Epoch 719/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0316 - accuracy: 0.9862 - val_loss: 1.1577 - val_accuracy: 0.8690\n",
            "Epoch 720/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0330 - accuracy: 0.9857 - val_loss: 1.1524 - val_accuracy: 0.8666\n",
            "Epoch 721/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0402 - accuracy: 0.9836 - val_loss: 1.1260 - val_accuracy: 0.8696\n",
            "Epoch 722/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0390 - accuracy: 0.9843 - val_loss: 1.0995 - val_accuracy: 0.8688\n",
            "Epoch 723/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0335 - accuracy: 0.9860 - val_loss: 1.1048 - val_accuracy: 0.8674\n",
            "Epoch 724/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0318 - accuracy: 0.9858 - val_loss: 1.1312 - val_accuracy: 0.8682\n",
            "Epoch 725/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0328 - accuracy: 0.9862 - val_loss: 1.1337 - val_accuracy: 0.8674\n",
            "Epoch 726/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0313 - accuracy: 0.9861 - val_loss: 1.1093 - val_accuracy: 0.8701\n",
            "Epoch 727/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0323 - accuracy: 0.9866 - val_loss: 1.1914 - val_accuracy: 0.8679\n",
            "Epoch 728/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0329 - accuracy: 0.9859 - val_loss: 1.1657 - val_accuracy: 0.8677\n",
            "Epoch 729/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0378 - accuracy: 0.9843 - val_loss: 1.0958 - val_accuracy: 0.8715\n",
            "Epoch 730/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0421 - accuracy: 0.9827 - val_loss: 1.1907 - val_accuracy: 0.8718\n",
            "Epoch 731/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0425 - accuracy: 0.9836 - val_loss: 1.0894 - val_accuracy: 0.8652\n",
            "Epoch 732/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0426 - accuracy: 0.9838 - val_loss: 1.1487 - val_accuracy: 0.8740\n",
            "Epoch 733/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0338 - accuracy: 0.9867 - val_loss: 1.0934 - val_accuracy: 0.8652\n",
            "Epoch 734/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0309 - accuracy: 0.9870 - val_loss: 1.1313 - val_accuracy: 0.8704\n",
            "Epoch 735/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0301 - accuracy: 0.9870 - val_loss: 1.1168 - val_accuracy: 0.8668\n",
            "Epoch 736/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 1.1208 - val_accuracy: 0.8701\n",
            "Epoch 737/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0294 - accuracy: 0.9874 - val_loss: 1.1620 - val_accuracy: 0.8685\n",
            "Epoch 738/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0316 - accuracy: 0.9865 - val_loss: 1.0994 - val_accuracy: 0.8715\n",
            "Epoch 739/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0292 - accuracy: 0.9877 - val_loss: 1.1948 - val_accuracy: 0.8710\n",
            "Epoch 740/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0338 - accuracy: 0.9860 - val_loss: 1.1496 - val_accuracy: 0.8668\n",
            "Epoch 741/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0367 - accuracy: 0.9850 - val_loss: 1.1023 - val_accuracy: 0.8707\n",
            "Epoch 742/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0393 - accuracy: 0.9840 - val_loss: 1.1272 - val_accuracy: 0.8674\n",
            "Epoch 743/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0372 - accuracy: 0.9844 - val_loss: 1.1463 - val_accuracy: 0.8644\n",
            "Epoch 744/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0344 - accuracy: 0.9861 - val_loss: 1.1453 - val_accuracy: 0.8690\n",
            "Epoch 745/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0346 - accuracy: 0.9854 - val_loss: 1.1502 - val_accuracy: 0.8723\n",
            "Epoch 746/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0360 - accuracy: 0.9854 - val_loss: 1.1004 - val_accuracy: 0.8696\n",
            "Epoch 747/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0315 - accuracy: 0.9861 - val_loss: 1.1409 - val_accuracy: 0.8732\n",
            "Epoch 748/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0298 - accuracy: 0.9871 - val_loss: 1.1458 - val_accuracy: 0.8699\n",
            "Epoch 749/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0339 - accuracy: 0.9852 - val_loss: 1.2124 - val_accuracy: 0.8732\n",
            "Epoch 750/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0341 - accuracy: 0.9863 - val_loss: 1.1850 - val_accuracy: 0.8737\n",
            "Epoch 751/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0330 - accuracy: 0.9862 - val_loss: 1.1794 - val_accuracy: 0.8723\n",
            "Epoch 752/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0329 - accuracy: 0.9865 - val_loss: 1.1345 - val_accuracy: 0.8712\n",
            "Epoch 753/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0293 - accuracy: 0.9868 - val_loss: 1.1823 - val_accuracy: 0.8729\n",
            "Epoch 754/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0325 - accuracy: 0.9868 - val_loss: 1.1325 - val_accuracy: 0.8632\n",
            "Epoch 755/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0316 - accuracy: 0.9860 - val_loss: 1.1549 - val_accuracy: 0.8710\n",
            "Epoch 756/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0340 - accuracy: 0.9859 - val_loss: 1.1764 - val_accuracy: 0.8655\n",
            "Epoch 757/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0346 - accuracy: 0.9849 - val_loss: 1.1485 - val_accuracy: 0.8734\n",
            "Epoch 758/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0354 - accuracy: 0.9850 - val_loss: 1.1193 - val_accuracy: 0.8732\n",
            "Epoch 759/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0297 - accuracy: 0.9876 - val_loss: 1.1529 - val_accuracy: 0.8657\n",
            "Epoch 760/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0293 - accuracy: 0.9873 - val_loss: 1.1588 - val_accuracy: 0.8677\n",
            "Epoch 761/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0361 - accuracy: 0.9854 - val_loss: 1.1384 - val_accuracy: 0.8679\n",
            "Epoch 762/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0355 - accuracy: 0.9847 - val_loss: 1.1554 - val_accuracy: 0.8712\n",
            "Epoch 763/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0385 - accuracy: 0.9843 - val_loss: 1.1989 - val_accuracy: 0.8663\n",
            "Epoch 764/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0416 - accuracy: 0.9840 - val_loss: 1.1424 - val_accuracy: 0.8663\n",
            "Epoch 765/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0456 - accuracy: 0.9817 - val_loss: 1.1512 - val_accuracy: 0.8649\n",
            "Epoch 766/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0398 - accuracy: 0.9838 - val_loss: 1.1682 - val_accuracy: 0.8699\n",
            "Epoch 767/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0365 - accuracy: 0.9843 - val_loss: 1.1679 - val_accuracy: 0.8690\n",
            "Epoch 768/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0342 - accuracy: 0.9862 - val_loss: 1.1750 - val_accuracy: 0.8715\n",
            "Epoch 769/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0406 - accuracy: 0.9844 - val_loss: 1.1391 - val_accuracy: 0.8721\n",
            "Epoch 770/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0341 - accuracy: 0.9860 - val_loss: 1.1259 - val_accuracy: 0.8704\n",
            "Epoch 771/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0308 - accuracy: 0.9864 - val_loss: 1.1621 - val_accuracy: 0.8740\n",
            "Epoch 772/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0308 - accuracy: 0.9869 - val_loss: 1.1379 - val_accuracy: 0.8710\n",
            "Epoch 773/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0288 - accuracy: 0.9879 - val_loss: 1.1349 - val_accuracy: 0.8688\n",
            "Epoch 774/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0314 - accuracy: 0.9869 - val_loss: 1.1930 - val_accuracy: 0.8751\n",
            "Epoch 775/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0311 - accuracy: 0.9868 - val_loss: 1.1769 - val_accuracy: 0.8762\n",
            "Epoch 776/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0305 - accuracy: 0.9871 - val_loss: 1.1926 - val_accuracy: 0.8682\n",
            "Epoch 777/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0318 - accuracy: 0.9860 - val_loss: 1.1409 - val_accuracy: 0.8696\n",
            "Epoch 778/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0291 - accuracy: 0.9878 - val_loss: 1.1462 - val_accuracy: 0.8751\n",
            "Epoch 779/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 1.1436 - val_accuracy: 0.8696\n",
            "Epoch 780/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0261 - accuracy: 0.9880 - val_loss: 1.2035 - val_accuracy: 0.8770\n",
            "Epoch 781/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0273 - accuracy: 0.9877 - val_loss: 1.1647 - val_accuracy: 0.8748\n",
            "Epoch 782/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0284 - accuracy: 0.9874 - val_loss: 1.1267 - val_accuracy: 0.8690\n",
            "Epoch 783/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0299 - accuracy: 0.9872 - val_loss: 1.1913 - val_accuracy: 0.8773\n",
            "Epoch 784/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0307 - accuracy: 0.9868 - val_loss: 1.1725 - val_accuracy: 0.8723\n",
            "Epoch 785/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0328 - accuracy: 0.9859 - val_loss: 1.1569 - val_accuracy: 0.8632\n",
            "Epoch 786/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0297 - accuracy: 0.9876 - val_loss: 1.1207 - val_accuracy: 0.8770\n",
            "Epoch 787/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0339 - accuracy: 0.9863 - val_loss: 1.1741 - val_accuracy: 0.8641\n",
            "Epoch 788/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0305 - accuracy: 0.9870 - val_loss: 1.1506 - val_accuracy: 0.8712\n",
            "Epoch 789/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0359 - accuracy: 0.9856 - val_loss: 1.1898 - val_accuracy: 0.8737\n",
            "Epoch 790/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0396 - accuracy: 0.9840 - val_loss: 1.1485 - val_accuracy: 0.8641\n",
            "Epoch 791/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0346 - accuracy: 0.9854 - val_loss: 1.1937 - val_accuracy: 0.8759\n",
            "Epoch 792/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0321 - accuracy: 0.9860 - val_loss: 1.1597 - val_accuracy: 0.8748\n",
            "Epoch 793/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9871 - val_loss: 1.1837 - val_accuracy: 0.8715\n",
            "Epoch 794/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0304 - accuracy: 0.9871 - val_loss: 1.2121 - val_accuracy: 0.8712\n",
            "Epoch 795/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9867 - val_loss: 1.1795 - val_accuracy: 0.8726\n",
            "Epoch 796/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 1.2180 - val_accuracy: 0.8652\n",
            "Epoch 797/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0335 - accuracy: 0.9857 - val_loss: 1.1868 - val_accuracy: 0.8696\n",
            "Epoch 798/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0322 - accuracy: 0.9864 - val_loss: 1.1979 - val_accuracy: 0.8655\n",
            "Epoch 799/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0380 - accuracy: 0.9851 - val_loss: 1.1881 - val_accuracy: 0.8718\n",
            "Epoch 800/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0428 - accuracy: 0.9821 - val_loss: 1.1734 - val_accuracy: 0.8704\n",
            "Epoch 801/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0436 - accuracy: 0.9826 - val_loss: 1.1824 - val_accuracy: 0.8663\n",
            "Epoch 802/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0456 - accuracy: 0.9813 - val_loss: 1.1667 - val_accuracy: 0.8630\n",
            "Epoch 803/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0362 - accuracy: 0.9847 - val_loss: 1.1506 - val_accuracy: 0.8710\n",
            "Epoch 804/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0371 - accuracy: 0.9849 - val_loss: 1.1297 - val_accuracy: 0.8688\n",
            "Epoch 805/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0308 - accuracy: 0.9868 - val_loss: 1.1509 - val_accuracy: 0.8679\n",
            "Epoch 806/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0282 - accuracy: 0.9879 - val_loss: 1.1354 - val_accuracy: 0.8668\n",
            "Epoch 807/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0296 - accuracy: 0.9866 - val_loss: 1.1821 - val_accuracy: 0.8704\n",
            "Epoch 808/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0294 - accuracy: 0.9869 - val_loss: 1.1985 - val_accuracy: 0.8729\n",
            "Epoch 809/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0285 - accuracy: 0.9871 - val_loss: 1.1870 - val_accuracy: 0.8704\n",
            "Epoch 810/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0295 - accuracy: 0.9868 - val_loss: 1.1844 - val_accuracy: 0.8685\n",
            "Epoch 811/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0311 - accuracy: 0.9865 - val_loss: 1.1834 - val_accuracy: 0.8710\n",
            "Epoch 812/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0339 - accuracy: 0.9859 - val_loss: 1.1886 - val_accuracy: 0.8690\n",
            "Epoch 813/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 1.1764 - val_accuracy: 0.8710\n",
            "Epoch 814/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0323 - accuracy: 0.9859 - val_loss: 1.1870 - val_accuracy: 0.8751\n",
            "Epoch 815/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0304 - accuracy: 0.9865 - val_loss: 1.1657 - val_accuracy: 0.8690\n",
            "Epoch 816/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0293 - accuracy: 0.9876 - val_loss: 1.1949 - val_accuracy: 0.8734\n",
            "Epoch 817/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0325 - accuracy: 0.9861 - val_loss: 1.2017 - val_accuracy: 0.8685\n",
            "Epoch 818/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0378 - accuracy: 0.9845 - val_loss: 1.2346 - val_accuracy: 0.8635\n",
            "Epoch 819/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0446 - accuracy: 0.9815 - val_loss: 1.1819 - val_accuracy: 0.8630\n",
            "Epoch 820/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0409 - accuracy: 0.9834 - val_loss: 1.2355 - val_accuracy: 0.8751\n",
            "Epoch 821/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0382 - accuracy: 0.9839 - val_loss: 1.1963 - val_accuracy: 0.8624\n",
            "Epoch 822/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0519 - accuracy: 0.9801 - val_loss: 1.1587 - val_accuracy: 0.8644\n",
            "Epoch 823/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0326 - accuracy: 0.9864 - val_loss: 1.1244 - val_accuracy: 0.8685\n",
            "Epoch 824/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0288 - accuracy: 0.9874 - val_loss: 1.1103 - val_accuracy: 0.8663\n",
            "Epoch 825/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0263 - accuracy: 0.9877 - val_loss: 1.1316 - val_accuracy: 0.8696\n",
            "Epoch 826/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0266 - accuracy: 0.9879 - val_loss: 1.1656 - val_accuracy: 0.8726\n",
            "Epoch 827/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0290 - accuracy: 0.9880 - val_loss: 1.1585 - val_accuracy: 0.8668\n",
            "Epoch 828/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0278 - accuracy: 0.9880 - val_loss: 1.1600 - val_accuracy: 0.8663\n",
            "Epoch 829/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0275 - accuracy: 0.9875 - val_loss: 1.1665 - val_accuracy: 0.8660\n",
            "Epoch 830/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0272 - accuracy: 0.9877 - val_loss: 1.2177 - val_accuracy: 0.8729\n",
            "Epoch 831/1000\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.0264 - accuracy: 0.9886 - val_loss: 1.1865 - val_accuracy: 0.8688\n",
            "Epoch 832/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0280 - accuracy: 0.9879 - val_loss: 1.1849 - val_accuracy: 0.8693\n",
            "Epoch 833/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0273 - accuracy: 0.9875 - val_loss: 1.1737 - val_accuracy: 0.8712\n",
            "Epoch 834/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0288 - accuracy: 0.9875 - val_loss: 1.2079 - val_accuracy: 0.8734\n",
            "Epoch 835/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0269 - accuracy: 0.9877 - val_loss: 1.1759 - val_accuracy: 0.8718\n",
            "Epoch 836/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0292 - accuracy: 0.9872 - val_loss: 1.2233 - val_accuracy: 0.8688\n",
            "Epoch 837/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0325 - accuracy: 0.9863 - val_loss: 1.1674 - val_accuracy: 0.8701\n",
            "Epoch 838/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0316 - accuracy: 0.9868 - val_loss: 1.2130 - val_accuracy: 0.8732\n",
            "Epoch 839/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0359 - accuracy: 0.9849 - val_loss: 1.1770 - val_accuracy: 0.8712\n",
            "Epoch 840/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0450 - accuracy: 0.9813 - val_loss: 1.1323 - val_accuracy: 0.8652\n",
            "Epoch 841/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0469 - accuracy: 0.9811 - val_loss: 1.1384 - val_accuracy: 0.8682\n",
            "Epoch 842/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0359 - accuracy: 0.9847 - val_loss: 1.1030 - val_accuracy: 0.8666\n",
            "Epoch 843/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0362 - accuracy: 0.9851 - val_loss: 1.1004 - val_accuracy: 0.8699\n",
            "Epoch 844/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0325 - accuracy: 0.9862 - val_loss: 1.1242 - val_accuracy: 0.8732\n",
            "Epoch 845/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0287 - accuracy: 0.9874 - val_loss: 1.1561 - val_accuracy: 0.8718\n",
            "Epoch 846/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0319 - accuracy: 0.9864 - val_loss: 1.1468 - val_accuracy: 0.8679\n",
            "Epoch 847/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0321 - accuracy: 0.9869 - val_loss: 1.1902 - val_accuracy: 0.8704\n",
            "Epoch 848/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0306 - accuracy: 0.9861 - val_loss: 1.2050 - val_accuracy: 0.8663\n",
            "Epoch 849/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0314 - accuracy: 0.9868 - val_loss: 1.1586 - val_accuracy: 0.8734\n",
            "Epoch 850/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0349 - accuracy: 0.9852 - val_loss: 1.2215 - val_accuracy: 0.8734\n",
            "Epoch 851/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0363 - accuracy: 0.9846 - val_loss: 1.1475 - val_accuracy: 0.8677\n",
            "Epoch 852/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0312 - accuracy: 0.9870 - val_loss: 1.2000 - val_accuracy: 0.8710\n",
            "Epoch 853/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0297 - accuracy: 0.9872 - val_loss: 1.1953 - val_accuracy: 0.8652\n",
            "Epoch 854/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0314 - accuracy: 0.9867 - val_loss: 1.2050 - val_accuracy: 0.8732\n",
            "Epoch 855/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0305 - accuracy: 0.9868 - val_loss: 1.2192 - val_accuracy: 0.8655\n",
            "Epoch 856/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0294 - accuracy: 0.9871 - val_loss: 1.1703 - val_accuracy: 0.8696\n",
            "Epoch 857/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0325 - accuracy: 0.9865 - val_loss: 1.1670 - val_accuracy: 0.8718\n",
            "Epoch 858/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0302 - accuracy: 0.9863 - val_loss: 1.1569 - val_accuracy: 0.8712\n",
            "Epoch 859/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0293 - accuracy: 0.9870 - val_loss: 1.1836 - val_accuracy: 0.8710\n",
            "Epoch 860/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0304 - accuracy: 0.9871 - val_loss: 1.2246 - val_accuracy: 0.8663\n",
            "Epoch 861/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0320 - accuracy: 0.9861 - val_loss: 1.1713 - val_accuracy: 0.8671\n",
            "Epoch 862/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0492 - accuracy: 0.9806 - val_loss: 1.1096 - val_accuracy: 0.8627\n",
            "Epoch 863/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0368 - accuracy: 0.9846 - val_loss: 1.1752 - val_accuracy: 0.8718\n",
            "Epoch 864/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0339 - accuracy: 0.9860 - val_loss: 1.1273 - val_accuracy: 0.8674\n",
            "Epoch 865/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0295 - accuracy: 0.9864 - val_loss: 1.1133 - val_accuracy: 0.8699\n",
            "Epoch 866/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0301 - accuracy: 0.9872 - val_loss: 1.1216 - val_accuracy: 0.8701\n",
            "Epoch 867/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0331 - accuracy: 0.9867 - val_loss: 1.1150 - val_accuracy: 0.8638\n",
            "Epoch 868/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0304 - accuracy: 0.9868 - val_loss: 1.1311 - val_accuracy: 0.8657\n",
            "Epoch 869/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0278 - accuracy: 0.9872 - val_loss: 1.1447 - val_accuracy: 0.8682\n",
            "Epoch 870/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 1.1642 - val_accuracy: 0.8701\n",
            "Epoch 871/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0247 - accuracy: 0.9888 - val_loss: 1.1648 - val_accuracy: 0.8721\n",
            "Epoch 872/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0261 - accuracy: 0.9884 - val_loss: 1.1367 - val_accuracy: 0.8674\n",
            "Epoch 873/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0266 - accuracy: 0.9880 - val_loss: 1.2024 - val_accuracy: 0.8704\n",
            "Epoch 874/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0269 - accuracy: 0.9879 - val_loss: 1.1966 - val_accuracy: 0.8710\n",
            "Epoch 875/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0262 - accuracy: 0.9885 - val_loss: 1.2196 - val_accuracy: 0.8688\n",
            "Epoch 876/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0286 - accuracy: 0.9875 - val_loss: 1.1728 - val_accuracy: 0.8613\n",
            "Epoch 877/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9870 - val_loss: 1.1500 - val_accuracy: 0.8696\n",
            "Epoch 878/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0305 - accuracy: 0.9867 - val_loss: 1.2440 - val_accuracy: 0.8718\n",
            "Epoch 879/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0328 - accuracy: 0.9863 - val_loss: 1.2265 - val_accuracy: 0.8715\n",
            "Epoch 880/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0308 - accuracy: 0.9868 - val_loss: 1.1625 - val_accuracy: 0.8746\n",
            "Epoch 881/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0307 - accuracy: 0.9869 - val_loss: 1.1859 - val_accuracy: 0.8701\n",
            "Epoch 882/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0297 - accuracy: 0.9871 - val_loss: 1.1671 - val_accuracy: 0.8663\n",
            "Epoch 883/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0309 - accuracy: 0.9863 - val_loss: 1.2052 - val_accuracy: 0.8671\n",
            "Epoch 884/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0288 - accuracy: 0.9871 - val_loss: 1.1680 - val_accuracy: 0.8699\n",
            "Epoch 885/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0296 - accuracy: 0.9872 - val_loss: 1.1884 - val_accuracy: 0.8679\n",
            "Epoch 886/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0303 - accuracy: 0.9870 - val_loss: 1.1852 - val_accuracy: 0.8690\n",
            "Epoch 887/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0316 - accuracy: 0.9868 - val_loss: 1.1828 - val_accuracy: 0.8710\n",
            "Epoch 888/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0340 - accuracy: 0.9855 - val_loss: 1.1449 - val_accuracy: 0.8655\n",
            "Epoch 889/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0327 - accuracy: 0.9859 - val_loss: 1.1923 - val_accuracy: 0.8704\n",
            "Epoch 890/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0398 - accuracy: 0.9833 - val_loss: 1.0962 - val_accuracy: 0.8632\n",
            "Epoch 891/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0431 - accuracy: 0.9816 - val_loss: 1.1805 - val_accuracy: 0.8677\n",
            "Epoch 892/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0441 - accuracy: 0.9822 - val_loss: 1.2288 - val_accuracy: 0.8699\n",
            "Epoch 893/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0425 - accuracy: 0.9830 - val_loss: 1.2196 - val_accuracy: 0.8644\n",
            "Epoch 894/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0341 - accuracy: 0.9860 - val_loss: 1.1997 - val_accuracy: 0.8701\n",
            "Epoch 895/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0341 - accuracy: 0.9857 - val_loss: 1.1276 - val_accuracy: 0.8740\n",
            "Epoch 896/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0325 - accuracy: 0.9862 - val_loss: 1.1901 - val_accuracy: 0.8712\n",
            "Epoch 897/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0289 - accuracy: 0.9871 - val_loss: 1.1732 - val_accuracy: 0.8660\n",
            "Epoch 898/1000\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.0274 - accuracy: 0.9881 - val_loss: 1.1988 - val_accuracy: 0.8696\n",
            "Epoch 899/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0270 - accuracy: 0.9879 - val_loss: 1.2299 - val_accuracy: 0.8718\n",
            "Epoch 900/1000\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.0266 - accuracy: 0.9884 - val_loss: 1.1799 - val_accuracy: 0.8723\n",
            "Epoch 901/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0256 - accuracy: 0.9884 - val_loss: 1.2117 - val_accuracy: 0.8663\n",
            "Epoch 902/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0281 - accuracy: 0.9871 - val_loss: 1.2212 - val_accuracy: 0.8701\n",
            "Epoch 903/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0310 - accuracy: 0.9859 - val_loss: 1.1833 - val_accuracy: 0.8707\n",
            "Epoch 904/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0314 - accuracy: 0.9875 - val_loss: 1.2027 - val_accuracy: 0.8718\n",
            "Epoch 905/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0326 - accuracy: 0.9868 - val_loss: 1.1833 - val_accuracy: 0.8699\n",
            "Epoch 906/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0315 - accuracy: 0.9869 - val_loss: 1.1340 - val_accuracy: 0.8630\n",
            "Epoch 907/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9875 - val_loss: 1.1881 - val_accuracy: 0.8732\n",
            "Epoch 908/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0309 - accuracy: 0.9872 - val_loss: 1.1533 - val_accuracy: 0.8674\n",
            "Epoch 909/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0280 - accuracy: 0.9874 - val_loss: 1.2130 - val_accuracy: 0.8707\n",
            "Epoch 910/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0291 - accuracy: 0.9876 - val_loss: 1.1392 - val_accuracy: 0.8671\n",
            "Epoch 911/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0268 - accuracy: 0.9878 - val_loss: 1.1905 - val_accuracy: 0.8712\n",
            "Epoch 912/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0287 - accuracy: 0.9872 - val_loss: 1.2589 - val_accuracy: 0.8743\n",
            "Epoch 913/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0304 - accuracy: 0.9864 - val_loss: 1.1968 - val_accuracy: 0.8668\n",
            "Epoch 914/1000\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.0314 - accuracy: 0.9858 - val_loss: 1.1859 - val_accuracy: 0.8690\n",
            "Epoch 915/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0258 - accuracy: 0.9884 - val_loss: 1.1954 - val_accuracy: 0.8718\n",
            "Epoch 916/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0271 - accuracy: 0.9881 - val_loss: 1.1791 - val_accuracy: 0.8693\n",
            "Epoch 917/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0285 - accuracy: 0.9870 - val_loss: 1.2022 - val_accuracy: 0.8734\n",
            "Epoch 918/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0289 - accuracy: 0.9875 - val_loss: 1.1843 - val_accuracy: 0.8693\n",
            "Epoch 919/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0301 - accuracy: 0.9868 - val_loss: 1.2030 - val_accuracy: 0.8704\n",
            "Epoch 920/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0298 - accuracy: 0.9873 - val_loss: 1.2026 - val_accuracy: 0.8682\n",
            "Epoch 921/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0337 - accuracy: 0.9858 - val_loss: 1.1809 - val_accuracy: 0.8677\n",
            "Epoch 922/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0370 - accuracy: 0.9848 - val_loss: 1.1682 - val_accuracy: 0.8704\n",
            "Epoch 923/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0372 - accuracy: 0.9848 - val_loss: 1.1355 - val_accuracy: 0.8693\n",
            "Epoch 924/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0354 - accuracy: 0.9854 - val_loss: 1.1759 - val_accuracy: 0.8707\n",
            "Epoch 925/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0311 - accuracy: 0.9870 - val_loss: 1.1996 - val_accuracy: 0.8663\n",
            "Epoch 926/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0318 - accuracy: 0.9860 - val_loss: 1.1744 - val_accuracy: 0.8690\n",
            "Epoch 927/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0313 - accuracy: 0.9864 - val_loss: 1.1500 - val_accuracy: 0.8693\n",
            "Epoch 928/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0284 - accuracy: 0.9879 - val_loss: 1.1944 - val_accuracy: 0.8655\n",
            "Epoch 929/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 1.1976 - val_accuracy: 0.8696\n",
            "Epoch 930/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0292 - accuracy: 0.9870 - val_loss: 1.1933 - val_accuracy: 0.8668\n",
            "Epoch 931/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0287 - accuracy: 0.9877 - val_loss: 1.2002 - val_accuracy: 0.8715\n",
            "Epoch 932/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0302 - accuracy: 0.9870 - val_loss: 1.1886 - val_accuracy: 0.8715\n",
            "Epoch 933/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0293 - accuracy: 0.9869 - val_loss: 1.2095 - val_accuracy: 0.8668\n",
            "Epoch 934/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0309 - accuracy: 0.9868 - val_loss: 1.2362 - val_accuracy: 0.8726\n",
            "Epoch 935/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0286 - accuracy: 0.9873 - val_loss: 1.1773 - val_accuracy: 0.8737\n",
            "Epoch 936/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0295 - accuracy: 0.9870 - val_loss: 1.1740 - val_accuracy: 0.8679\n",
            "Epoch 937/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0296 - accuracy: 0.9871 - val_loss: 1.1840 - val_accuracy: 0.8663\n",
            "Epoch 938/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0329 - accuracy: 0.9867 - val_loss: 1.2008 - val_accuracy: 0.8677\n",
            "Epoch 939/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0363 - accuracy: 0.9844 - val_loss: 1.1929 - val_accuracy: 0.8715\n",
            "Epoch 940/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0354 - accuracy: 0.9846 - val_loss: 1.2144 - val_accuracy: 0.8666\n",
            "Epoch 941/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0332 - accuracy: 0.9859 - val_loss: 1.1506 - val_accuracy: 0.8616\n",
            "Epoch 942/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0303 - accuracy: 0.9868 - val_loss: 1.1796 - val_accuracy: 0.8657\n",
            "Epoch 943/1000\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.0294 - accuracy: 0.9872 - val_loss: 1.2001 - val_accuracy: 0.8671\n",
            "Epoch 944/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0283 - accuracy: 0.9879 - val_loss: 1.2112 - val_accuracy: 0.8644\n",
            "Epoch 945/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0291 - accuracy: 0.9878 - val_loss: 1.1839 - val_accuracy: 0.8707\n",
            "Epoch 946/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0268 - accuracy: 0.9886 - val_loss: 1.2350 - val_accuracy: 0.8685\n",
            "Epoch 947/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0274 - accuracy: 0.9882 - val_loss: 1.2013 - val_accuracy: 0.8723\n",
            "Epoch 948/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0305 - accuracy: 0.9867 - val_loss: 1.2003 - val_accuracy: 0.8701\n",
            "Epoch 949/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0316 - accuracy: 0.9857 - val_loss: 1.2337 - val_accuracy: 0.8685\n",
            "Epoch 950/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0333 - accuracy: 0.9865 - val_loss: 1.2012 - val_accuracy: 0.8696\n",
            "Epoch 951/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0277 - accuracy: 0.9879 - val_loss: 1.2278 - val_accuracy: 0.8679\n",
            "Epoch 952/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0300 - accuracy: 0.9871 - val_loss: 1.2121 - val_accuracy: 0.8721\n",
            "Epoch 953/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0314 - accuracy: 0.9867 - val_loss: 1.1741 - val_accuracy: 0.8685\n",
            "Epoch 954/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0318 - accuracy: 0.9865 - val_loss: 1.2468 - val_accuracy: 0.8685\n",
            "Epoch 955/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0292 - accuracy: 0.9871 - val_loss: 1.2488 - val_accuracy: 0.8668\n",
            "Epoch 956/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0283 - accuracy: 0.9878 - val_loss: 1.2336 - val_accuracy: 0.8707\n",
            "Epoch 957/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0274 - accuracy: 0.9878 - val_loss: 1.2285 - val_accuracy: 0.8682\n",
            "Epoch 958/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0275 - accuracy: 0.9877 - val_loss: 1.2565 - val_accuracy: 0.8693\n",
            "Epoch 959/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0281 - accuracy: 0.9875 - val_loss: 1.2053 - val_accuracy: 0.8688\n",
            "Epoch 960/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0296 - accuracy: 0.9875 - val_loss: 1.2256 - val_accuracy: 0.8652\n",
            "Epoch 961/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0294 - accuracy: 0.9872 - val_loss: 1.2047 - val_accuracy: 0.8748\n",
            "Epoch 962/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0297 - accuracy: 0.9873 - val_loss: 1.2172 - val_accuracy: 0.8624\n",
            "Epoch 963/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0329 - accuracy: 0.9865 - val_loss: 1.1660 - val_accuracy: 0.8635\n",
            "Epoch 964/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0351 - accuracy: 0.9856 - val_loss: 1.2134 - val_accuracy: 0.8679\n",
            "Epoch 965/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0367 - accuracy: 0.9846 - val_loss: 1.2100 - val_accuracy: 0.8668\n",
            "Epoch 966/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0344 - accuracy: 0.9854 - val_loss: 1.1826 - val_accuracy: 0.8657\n",
            "Epoch 967/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0294 - accuracy: 0.9869 - val_loss: 1.2705 - val_accuracy: 0.8710\n",
            "Epoch 968/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0294 - accuracy: 0.9870 - val_loss: 1.2210 - val_accuracy: 0.8721\n",
            "Epoch 969/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0284 - accuracy: 0.9870 - val_loss: 1.1675 - val_accuracy: 0.8721\n",
            "Epoch 970/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0328 - accuracy: 0.9866 - val_loss: 1.2190 - val_accuracy: 0.8707\n",
            "Epoch 971/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0353 - accuracy: 0.9850 - val_loss: 1.1645 - val_accuracy: 0.8699\n",
            "Epoch 972/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0390 - accuracy: 0.9842 - val_loss: 1.1823 - val_accuracy: 0.8666\n",
            "Epoch 973/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0336 - accuracy: 0.9855 - val_loss: 1.1759 - val_accuracy: 0.8707\n",
            "Epoch 974/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0305 - accuracy: 0.9869 - val_loss: 1.1918 - val_accuracy: 0.8690\n",
            "Epoch 975/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0287 - accuracy: 0.9876 - val_loss: 1.1937 - val_accuracy: 0.8688\n",
            "Epoch 976/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0266 - accuracy: 0.9879 - val_loss: 1.2377 - val_accuracy: 0.8688\n",
            "Epoch 977/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0271 - accuracy: 0.9882 - val_loss: 1.2128 - val_accuracy: 0.8721\n",
            "Epoch 978/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0299 - accuracy: 0.9868 - val_loss: 1.2224 - val_accuracy: 0.8740\n",
            "Epoch 979/1000\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.0268 - accuracy: 0.9887 - val_loss: 1.1827 - val_accuracy: 0.8677\n",
            "Epoch 980/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0302 - accuracy: 0.9869 - val_loss: 1.2642 - val_accuracy: 0.8638\n",
            "Epoch 981/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0309 - accuracy: 0.9871 - val_loss: 1.2064 - val_accuracy: 0.8707\n",
            "Epoch 982/1000\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.0299 - accuracy: 0.9867 - val_loss: 1.2113 - val_accuracy: 0.8685\n",
            "Epoch 983/1000\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.0302 - accuracy: 0.9869 - val_loss: 1.2350 - val_accuracy: 0.8701\n",
            "Epoch 984/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0280 - accuracy: 0.9878 - val_loss: 1.2226 - val_accuracy: 0.8677\n",
            "Epoch 985/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0317 - accuracy: 0.9861 - val_loss: 1.2121 - val_accuracy: 0.8710\n",
            "Epoch 986/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0318 - accuracy: 0.9867 - val_loss: 1.2318 - val_accuracy: 0.8704\n",
            "Epoch 987/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0276 - accuracy: 0.9872 - val_loss: 1.2584 - val_accuracy: 0.8668\n",
            "Epoch 988/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0304 - accuracy: 0.9870 - val_loss: 1.2737 - val_accuracy: 0.8682\n",
            "Epoch 989/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0328 - accuracy: 0.9866 - val_loss: 1.2055 - val_accuracy: 0.8693\n",
            "Epoch 990/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0318 - accuracy: 0.9865 - val_loss: 1.2204 - val_accuracy: 0.8699\n",
            "Epoch 991/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0299 - accuracy: 0.9871 - val_loss: 1.2187 - val_accuracy: 0.8723\n",
            "Epoch 992/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0272 - accuracy: 0.9871 - val_loss: 1.2616 - val_accuracy: 0.8715\n",
            "Epoch 993/1000\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.0285 - accuracy: 0.9881 - val_loss: 1.2476 - val_accuracy: 0.8704\n",
            "Epoch 994/1000\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.0289 - accuracy: 0.9873 - val_loss: 1.2674 - val_accuracy: 0.8685\n",
            "Epoch 995/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0285 - accuracy: 0.9878 - val_loss: 1.2719 - val_accuracy: 0.8679\n",
            "Epoch 996/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0347 - accuracy: 0.9856 - val_loss: 1.2004 - val_accuracy: 0.8677\n",
            "Epoch 997/1000\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.0304 - accuracy: 0.9865 - val_loss: 1.2289 - val_accuracy: 0.8671\n",
            "Epoch 998/1000\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.0344 - accuracy: 0.9856 - val_loss: 1.2512 - val_accuracy: 0.8682\n",
            "Epoch 999/1000\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.0320 - accuracy: 0.9862 - val_loss: 1.2343 - val_accuracy: 0.8688\n",
            "Epoch 1000/1000\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.0316 - accuracy: 0.9866 - val_loss: 1.2408 - val_accuracy: 0.8655\n"
          ]
        }
      ],
      "source": [
        "# 1. Set hyperparameters\n",
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 1000\n",
        "BATCH_SIZE = 558\n",
        "neurons_per_layer = [50, 150, 300, 150, 80]\n",
        "\n",
        "#2. Build the deep neural model\n",
        "init = he_normal(seed=1243)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=16, batch_size=BATCH_SIZE))\n",
        "for neurons in neurons_per_layer:\n",
        "  model.add(Dense(neurons, activation=\"relu\", kernel_initializer=init))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "#3. Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "#4. Train the model with M-BGD\n",
        "train = model.fit(data_train, labels_train, epochs=EPOCHS, batch_size=BATCH_SIZE,validation_data=(data_dev, labels_dev))\n",
        "\n",
        "# Save the results\n",
        "results=pd.DataFrame(train.history)\n",
        "path = \"/gdrive/MyDrive/GIA/AA2/trainHistoryModel1.csv\"\n",
        "results.to_csv(path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "k21XZFqW79k5",
        "outputId": "8066ac8c-9c58-458e-81a0-2f111d73d767"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss = train.history[\"loss\"]\n",
        "plt.plot(range(1, len(loss) + 1), loss, 'b', label='Error de entrenamiento')\n",
        "plt.xlabel (\"Epochs\")\n",
        "plt.ylabel (\"Train loss\")\n",
        "plt.title(\"Train loss\")\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "jwiN7mWRZVtd",
        "outputId": "69e96de4-5502-4d76-b3f4-b0d01efbbb61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "results=pd.DataFrame(train.history)\n",
        "results.plot(figsize=(8, 5))\n",
        "plt.grid(True)\n",
        "plt.xlabel (\"Epochs\")\n",
        "plt.ylabel (\"Accuracy - Mean Log Loss\")\n",
        "plt.title(\"Train loss\")\n",
        "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFf9wGx5shCv",
        "outputId": "dfcb564b-8379-47e1-c2ec-e75a82c1b6da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114/114 [==============================] - 1s 3ms/step\n",
            "1809 2\n",
            "Develompent accuracy: 0.8654535428728977\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(data_dev)\n",
        "predictions_binary = np.round(predictions)\n",
        "print(len(np.unique(predictions)), len(np.unique(predictions_binary)))\n",
        "pred = 0\n",
        "for i in range(len(labels_dev)):\n",
        "  if labels_dev.values[i] == predictions_binary[i]:\n",
        "    pred +=1\n",
        "dev_accuracy = pred/len(labels_dev)\n",
        "print(f'Develompent accuracy: {dev_accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBm7DoOFbhIr",
        "outputId": "958ba8aa-17d0-4833-e256-c5f07bbf1aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         loss  accuracy  val_loss  val_accuracy\n",
            "999  0.031587  0.986559  1.240823      0.865454\n"
          ]
        }
      ],
      "source": [
        "results=pd.DataFrame(train.history)\n",
        "print(results[-1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl6nEZh47N5O",
        "outputId": "eecb9ce0-db13-4933-a709-b4d40f8f5f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79      1175\n",
            "           1       0.90      0.91      0.90      2452\n",
            "\n",
            "    accuracy                           0.87      3627\n",
            "   macro avg       0.85      0.85      0.85      3627\n",
            "weighted avg       0.87      0.87      0.87      3627\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(labels_dev.values, predictions_binary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfidqjZ9tIOI"
      },
      "source": [
        "HEMOS OBTENIDO UN SOBREENTRENO EN LA RED, YA QUE TENEMOS UN ACCURACY DE 0.99 EN TRAIN, PERO DE 87.7 % EN DEV. APLICAREMOS TCNICAS PARA REDUCIRLO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8D8uE02avZt"
      },
      "source": [
        "## Second model: adding L2 regularized and ajusting the strenght"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghSEI7zsZe8m"
      },
      "source": [
        "We keep the same hyper parameters except for the number of epochs, that goes down from 1000 to 850"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmQ3cKANtTA5"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 850"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJk8-A0abNTR"
      },
      "source": [
        "We add the l2 regularizer for the weights in the hidden layers. The rest remains the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGFrCjEjcb4b"
      },
      "source": [
        "### Model 2.1: l2(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPsr1TLLB3aD",
        "outputId": "f71900a5-6c93-4fd6-bfd2-a1f612ba2299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/850\n",
            "52/52 [==============================] - 2s 21ms/step - loss: 11.4555 - accuracy: 0.7661 - val_loss: 8.2996 - val_accuracy: 0.7860\n",
            "Epoch 2/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 6.3990 - accuracy: 0.7940 - val_loss: 4.8379 - val_accuracy: 0.7833\n",
            "Epoch 3/850\n",
            "52/52 [==============================] - 1s 29ms/step - loss: 3.8732 - accuracy: 0.7930 - val_loss: 3.0724 - val_accuracy: 0.7860\n",
            "Epoch 4/850\n",
            "52/52 [==============================] - 2s 31ms/step - loss: 2.5536 - accuracy: 0.7968 - val_loss: 2.1318 - val_accuracy: 0.7816\n",
            "Epoch 5/850\n",
            "52/52 [==============================] - 2s 36ms/step - loss: 1.8378 - accuracy: 0.7919 - val_loss: 1.5932 - val_accuracy: 0.7896\n",
            "Epoch 6/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 1.4199 - accuracy: 0.7954 - val_loss: 1.2778 - val_accuracy: 0.7894\n",
            "Epoch 7/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 1.1650 - accuracy: 0.7964 - val_loss: 1.0768 - val_accuracy: 0.7907\n",
            "Epoch 8/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 1.0015 - accuracy: 0.7977 - val_loss: 0.9433 - val_accuracy: 0.7927\n",
            "Epoch 9/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.8917 - accuracy: 0.7980 - val_loss: 0.8552 - val_accuracy: 0.7883\n",
            "Epoch 10/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.8146 - accuracy: 0.7963 - val_loss: 0.7888 - val_accuracy: 0.7916\n",
            "Epoch 11/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.7591 - accuracy: 0.7970 - val_loss: 0.7406 - val_accuracy: 0.7938\n",
            "Epoch 12/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.7175 - accuracy: 0.7992 - val_loss: 0.7055 - val_accuracy: 0.7924\n",
            "Epoch 13/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.6863 - accuracy: 0.7985 - val_loss: 0.6775 - val_accuracy: 0.7940\n",
            "Epoch 14/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.6608 - accuracy: 0.7987 - val_loss: 0.6583 - val_accuracy: 0.7946\n",
            "Epoch 15/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.6459 - accuracy: 0.7967 - val_loss: 0.6474 - val_accuracy: 0.7891\n",
            "Epoch 16/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.6276 - accuracy: 0.8000 - val_loss: 0.6273 - val_accuracy: 0.7960\n",
            "Epoch 17/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.6182 - accuracy: 0.7988 - val_loss: 0.6185 - val_accuracy: 0.7929\n",
            "Epoch 18/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.6055 - accuracy: 0.8017 - val_loss: 0.6090 - val_accuracy: 0.7918\n",
            "Epoch 19/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5978 - accuracy: 0.8012 - val_loss: 0.6011 - val_accuracy: 0.7921\n",
            "Epoch 20/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5928 - accuracy: 0.7999 - val_loss: 0.5966 - val_accuracy: 0.7924\n",
            "Epoch 21/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5857 - accuracy: 0.8001 - val_loss: 0.5924 - val_accuracy: 0.7935\n",
            "Epoch 22/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5840 - accuracy: 0.7993 - val_loss: 0.5915 - val_accuracy: 0.7913\n",
            "Epoch 23/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5772 - accuracy: 0.8005 - val_loss: 0.5836 - val_accuracy: 0.7927\n",
            "Epoch 24/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5744 - accuracy: 0.8006 - val_loss: 0.5813 - val_accuracy: 0.7940\n",
            "Epoch 25/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5752 - accuracy: 0.7986 - val_loss: 0.5776 - val_accuracy: 0.7940\n",
            "Epoch 26/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5700 - accuracy: 0.8001 - val_loss: 0.5768 - val_accuracy: 0.7913\n",
            "Epoch 27/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5674 - accuracy: 0.7991 - val_loss: 0.5839 - val_accuracy: 0.7888\n",
            "Epoch 28/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5668 - accuracy: 0.7996 - val_loss: 0.5719 - val_accuracy: 0.7902\n",
            "Epoch 29/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5647 - accuracy: 0.8016 - val_loss: 0.5737 - val_accuracy: 0.7927\n",
            "Epoch 30/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.7995 - val_loss: 0.5726 - val_accuracy: 0.7899\n",
            "Epoch 31/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5614 - accuracy: 0.8000 - val_loss: 0.5697 - val_accuracy: 0.7910\n",
            "Epoch 32/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5607 - accuracy: 0.8001 - val_loss: 0.5690 - val_accuracy: 0.7927\n",
            "Epoch 33/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5590 - accuracy: 0.7999 - val_loss: 0.5661 - val_accuracy: 0.7938\n",
            "Epoch 34/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5597 - accuracy: 0.8007 - val_loss: 0.5657 - val_accuracy: 0.7916\n",
            "Epoch 35/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5598 - accuracy: 0.8005 - val_loss: 0.5727 - val_accuracy: 0.7918\n",
            "Epoch 36/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5608 - accuracy: 0.7990 - val_loss: 0.5640 - val_accuracy: 0.7902\n",
            "Epoch 37/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5554 - accuracy: 0.7999 - val_loss: 0.5627 - val_accuracy: 0.7907\n",
            "Epoch 38/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5543 - accuracy: 0.7999 - val_loss: 0.5624 - val_accuracy: 0.7921\n",
            "Epoch 39/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5542 - accuracy: 0.7999 - val_loss: 0.5630 - val_accuracy: 0.7916\n",
            "Epoch 40/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5539 - accuracy: 0.7995 - val_loss: 0.5611 - val_accuracy: 0.7927\n",
            "Epoch 41/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5527 - accuracy: 0.8007 - val_loss: 0.5607 - val_accuracy: 0.7929\n",
            "Epoch 42/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5533 - accuracy: 0.7991 - val_loss: 0.5611 - val_accuracy: 0.7907\n",
            "Epoch 43/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5523 - accuracy: 0.8002 - val_loss: 0.5622 - val_accuracy: 0.7891\n",
            "Epoch 44/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5527 - accuracy: 0.7993 - val_loss: 0.5590 - val_accuracy: 0.7935\n",
            "Epoch 45/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5522 - accuracy: 0.7994 - val_loss: 0.5598 - val_accuracy: 0.7932\n",
            "Epoch 46/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5509 - accuracy: 0.7996 - val_loss: 0.5602 - val_accuracy: 0.7916\n",
            "Epoch 47/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5505 - accuracy: 0.8001 - val_loss: 0.5592 - val_accuracy: 0.7910\n",
            "Epoch 48/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5510 - accuracy: 0.8008 - val_loss: 0.5584 - val_accuracy: 0.7932\n",
            "Epoch 49/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5497 - accuracy: 0.7990 - val_loss: 0.5653 - val_accuracy: 0.7894\n",
            "Epoch 50/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5517 - accuracy: 0.7989 - val_loss: 0.5589 - val_accuracy: 0.7905\n",
            "Epoch 51/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5489 - accuracy: 0.7988 - val_loss: 0.5582 - val_accuracy: 0.7951\n",
            "Epoch 52/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5494 - accuracy: 0.7992 - val_loss: 0.5612 - val_accuracy: 0.7899\n",
            "Epoch 53/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5502 - accuracy: 0.8012 - val_loss: 0.5576 - val_accuracy: 0.7929\n",
            "Epoch 54/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5496 - accuracy: 0.8008 - val_loss: 0.5564 - val_accuracy: 0.7916\n",
            "Epoch 55/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5490 - accuracy: 0.8007 - val_loss: 0.5571 - val_accuracy: 0.7913\n",
            "Epoch 56/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5487 - accuracy: 0.8006 - val_loss: 0.5573 - val_accuracy: 0.7899\n",
            "Epoch 57/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5490 - accuracy: 0.7991 - val_loss: 0.5568 - val_accuracy: 0.7905\n",
            "Epoch 58/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5530 - accuracy: 0.7979 - val_loss: 0.5599 - val_accuracy: 0.7918\n",
            "Epoch 59/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5486 - accuracy: 0.7988 - val_loss: 0.5576 - val_accuracy: 0.7916\n",
            "Epoch 60/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5483 - accuracy: 0.8008 - val_loss: 0.5583 - val_accuracy: 0.7935\n",
            "Epoch 61/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5488 - accuracy: 0.7995 - val_loss: 0.5579 - val_accuracy: 0.7927\n",
            "Epoch 62/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5487 - accuracy: 0.7990 - val_loss: 0.5560 - val_accuracy: 0.7943\n",
            "Epoch 63/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5479 - accuracy: 0.8000 - val_loss: 0.5567 - val_accuracy: 0.7894\n",
            "Epoch 64/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5471 - accuracy: 0.7994 - val_loss: 0.5568 - val_accuracy: 0.7913\n",
            "Epoch 65/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5481 - accuracy: 0.8000 - val_loss: 0.5547 - val_accuracy: 0.7924\n",
            "Epoch 66/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5521 - accuracy: 0.7987 - val_loss: 0.5633 - val_accuracy: 0.7869\n",
            "Epoch 67/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5471 - accuracy: 0.7994 - val_loss: 0.5546 - val_accuracy: 0.7913\n",
            "Epoch 68/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5469 - accuracy: 0.8014 - val_loss: 0.5547 - val_accuracy: 0.7927\n",
            "Epoch 69/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5478 - accuracy: 0.7989 - val_loss: 0.5556 - val_accuracy: 0.7916\n",
            "Epoch 70/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5472 - accuracy: 0.8001 - val_loss: 0.5555 - val_accuracy: 0.7938\n",
            "Epoch 71/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5466 - accuracy: 0.7992 - val_loss: 0.5547 - val_accuracy: 0.7954\n",
            "Epoch 72/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5472 - accuracy: 0.8004 - val_loss: 0.5558 - val_accuracy: 0.7938\n",
            "Epoch 73/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5479 - accuracy: 0.7997 - val_loss: 0.5547 - val_accuracy: 0.7910\n",
            "Epoch 74/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5468 - accuracy: 0.7991 - val_loss: 0.5550 - val_accuracy: 0.7916\n",
            "Epoch 75/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5464 - accuracy: 0.7994 - val_loss: 0.5546 - val_accuracy: 0.7935\n",
            "Epoch 76/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5467 - accuracy: 0.7999 - val_loss: 0.5541 - val_accuracy: 0.7946\n",
            "Epoch 77/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5459 - accuracy: 0.7995 - val_loss: 0.5540 - val_accuracy: 0.7924\n",
            "Epoch 78/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5453 - accuracy: 0.7986 - val_loss: 0.5543 - val_accuracy: 0.7907\n",
            "Epoch 79/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5473 - accuracy: 0.7990 - val_loss: 0.5543 - val_accuracy: 0.7932\n",
            "Epoch 80/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5481 - accuracy: 0.7977 - val_loss: 0.5542 - val_accuracy: 0.7929\n",
            "Epoch 81/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5459 - accuracy: 0.8004 - val_loss: 0.5562 - val_accuracy: 0.7902\n",
            "Epoch 82/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5469 - accuracy: 0.8005 - val_loss: 0.5540 - val_accuracy: 0.7918\n",
            "Epoch 83/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5455 - accuracy: 0.7991 - val_loss: 0.5616 - val_accuracy: 0.7943\n",
            "Epoch 84/850\n",
            "52/52 [==============================] - 2s 44ms/step - loss: 0.5487 - accuracy: 0.7975 - val_loss: 0.5533 - val_accuracy: 0.7951\n",
            "Epoch 85/850\n",
            "52/52 [==============================] - 2s 31ms/step - loss: 0.5471 - accuracy: 0.7997 - val_loss: 0.5543 - val_accuracy: 0.7899\n",
            "Epoch 86/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5454 - accuracy: 0.7996 - val_loss: 0.5552 - val_accuracy: 0.7907\n",
            "Epoch 87/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5457 - accuracy: 0.7992 - val_loss: 0.5549 - val_accuracy: 0.7913\n",
            "Epoch 88/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5453 - accuracy: 0.8004 - val_loss: 0.5536 - val_accuracy: 0.7938\n",
            "Epoch 89/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5453 - accuracy: 0.7997 - val_loss: 0.5543 - val_accuracy: 0.7932\n",
            "Epoch 90/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5453 - accuracy: 0.7993 - val_loss: 0.5589 - val_accuracy: 0.7877\n",
            "Epoch 91/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5461 - accuracy: 0.7996 - val_loss: 0.5538 - val_accuracy: 0.7932\n",
            "Epoch 92/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5458 - accuracy: 0.7989 - val_loss: 0.5551 - val_accuracy: 0.7894\n",
            "Epoch 93/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5450 - accuracy: 0.7992 - val_loss: 0.5555 - val_accuracy: 0.7910\n",
            "Epoch 94/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5450 - accuracy: 0.7984 - val_loss: 0.5535 - val_accuracy: 0.7902\n",
            "Epoch 95/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5449 - accuracy: 0.7988 - val_loss: 0.5564 - val_accuracy: 0.7894\n",
            "Epoch 96/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5455 - accuracy: 0.7986 - val_loss: 0.5533 - val_accuracy: 0.7940\n",
            "Epoch 97/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5449 - accuracy: 0.7987 - val_loss: 0.5561 - val_accuracy: 0.7874\n",
            "Epoch 98/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5458 - accuracy: 0.7991 - val_loss: 0.5531 - val_accuracy: 0.7905\n",
            "Epoch 99/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5451 - accuracy: 0.7991 - val_loss: 0.5593 - val_accuracy: 0.7880\n",
            "Epoch 100/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5455 - accuracy: 0.7994 - val_loss: 0.5534 - val_accuracy: 0.7916\n",
            "Epoch 101/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5456 - accuracy: 0.7986 - val_loss: 0.5535 - val_accuracy: 0.7954\n",
            "Epoch 102/850\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.5451 - accuracy: 0.7992 - val_loss: 0.5553 - val_accuracy: 0.7872\n",
            "Epoch 103/850\n",
            "52/52 [==============================] - 2s 31ms/step - loss: 0.5457 - accuracy: 0.7989 - val_loss: 0.5599 - val_accuracy: 0.7896\n",
            "Epoch 104/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5468 - accuracy: 0.7980 - val_loss: 0.5553 - val_accuracy: 0.7935\n",
            "Epoch 105/850\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.5450 - accuracy: 0.7981 - val_loss: 0.5554 - val_accuracy: 0.7896\n",
            "Epoch 106/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5464 - accuracy: 0.7997 - val_loss: 0.5534 - val_accuracy: 0.7918\n",
            "Epoch 107/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5447 - accuracy: 0.7984 - val_loss: 0.5539 - val_accuracy: 0.7916\n",
            "Epoch 108/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5484 - accuracy: 0.7984 - val_loss: 0.5539 - val_accuracy: 0.7938\n",
            "Epoch 109/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5451 - accuracy: 0.7991 - val_loss: 0.5534 - val_accuracy: 0.7913\n",
            "Epoch 110/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5458 - accuracy: 0.7976 - val_loss: 0.5539 - val_accuracy: 0.7924\n",
            "Epoch 111/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5450 - accuracy: 0.7996 - val_loss: 0.5539 - val_accuracy: 0.7924\n",
            "Epoch 112/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5450 - accuracy: 0.8002 - val_loss: 0.5560 - val_accuracy: 0.7896\n",
            "Epoch 113/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5454 - accuracy: 0.7981 - val_loss: 0.5535 - val_accuracy: 0.7913\n",
            "Epoch 114/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5455 - accuracy: 0.7985 - val_loss: 0.5541 - val_accuracy: 0.7932\n",
            "Epoch 115/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5449 - accuracy: 0.7990 - val_loss: 0.5534 - val_accuracy: 0.7927\n",
            "Epoch 116/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5445 - accuracy: 0.7991 - val_loss: 0.5544 - val_accuracy: 0.7896\n",
            "Epoch 117/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5447 - accuracy: 0.7981 - val_loss: 0.5532 - val_accuracy: 0.7935\n",
            "Epoch 118/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5452 - accuracy: 0.7993 - val_loss: 0.5542 - val_accuracy: 0.7894\n",
            "Epoch 119/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5455 - accuracy: 0.7984 - val_loss: 0.5550 - val_accuracy: 0.7885\n",
            "Epoch 120/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5461 - accuracy: 0.7994 - val_loss: 0.5527 - val_accuracy: 0.7910\n",
            "Epoch 121/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5449 - accuracy: 0.7994 - val_loss: 0.5550 - val_accuracy: 0.7891\n",
            "Epoch 122/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5446 - accuracy: 0.7990 - val_loss: 0.5528 - val_accuracy: 0.7951\n",
            "Epoch 123/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5454 - accuracy: 0.7995 - val_loss: 0.5539 - val_accuracy: 0.7916\n",
            "Epoch 124/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5450 - accuracy: 0.7996 - val_loss: 0.5529 - val_accuracy: 0.7938\n",
            "Epoch 125/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5449 - accuracy: 0.7998 - val_loss: 0.5535 - val_accuracy: 0.7921\n",
            "Epoch 126/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5451 - accuracy: 0.7992 - val_loss: 0.5563 - val_accuracy: 0.7913\n",
            "Epoch 127/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5443 - accuracy: 0.7994 - val_loss: 0.5538 - val_accuracy: 0.7905\n",
            "Epoch 128/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5468 - accuracy: 0.7999 - val_loss: 0.5529 - val_accuracy: 0.7938\n",
            "Epoch 129/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5450 - accuracy: 0.7988 - val_loss: 0.5544 - val_accuracy: 0.7932\n",
            "Epoch 130/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5446 - accuracy: 0.7993 - val_loss: 0.5540 - val_accuracy: 0.7894\n",
            "Epoch 131/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5444 - accuracy: 0.7979 - val_loss: 0.5550 - val_accuracy: 0.7872\n",
            "Epoch 132/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5455 - accuracy: 0.8008 - val_loss: 0.5529 - val_accuracy: 0.7918\n",
            "Epoch 133/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5462 - accuracy: 0.7995 - val_loss: 0.5532 - val_accuracy: 0.7927\n",
            "Epoch 134/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5442 - accuracy: 0.8003 - val_loss: 0.5584 - val_accuracy: 0.7885\n",
            "Epoch 135/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.7993 - val_loss: 0.5581 - val_accuracy: 0.7932\n",
            "Epoch 136/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5457 - accuracy: 0.7979 - val_loss: 0.5526 - val_accuracy: 0.7902\n",
            "Epoch 137/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5448 - accuracy: 0.7992 - val_loss: 0.5534 - val_accuracy: 0.7888\n",
            "Epoch 138/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5452 - accuracy: 0.8001 - val_loss: 0.5544 - val_accuracy: 0.7918\n",
            "Epoch 139/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5462 - accuracy: 0.7990 - val_loss: 0.5535 - val_accuracy: 0.7910\n",
            "Epoch 140/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5488 - accuracy: 0.7988 - val_loss: 0.5569 - val_accuracy: 0.7910\n",
            "Epoch 141/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5458 - accuracy: 0.7986 - val_loss: 0.5555 - val_accuracy: 0.7896\n",
            "Epoch 142/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5452 - accuracy: 0.7992 - val_loss: 0.5581 - val_accuracy: 0.7916\n",
            "Epoch 143/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5459 - accuracy: 0.7987 - val_loss: 0.5524 - val_accuracy: 0.7927\n",
            "Epoch 144/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5450 - accuracy: 0.8001 - val_loss: 0.5529 - val_accuracy: 0.7916\n",
            "Epoch 145/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5442 - accuracy: 0.7988 - val_loss: 0.5531 - val_accuracy: 0.7905\n",
            "Epoch 146/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5447 - accuracy: 0.7992 - val_loss: 0.5533 - val_accuracy: 0.7918\n",
            "Epoch 147/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.7983 - val_loss: 0.5544 - val_accuracy: 0.7888\n",
            "Epoch 148/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5453 - accuracy: 0.7995 - val_loss: 0.5587 - val_accuracy: 0.7872\n",
            "Epoch 149/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.7984 - val_loss: 0.5530 - val_accuracy: 0.7932\n",
            "Epoch 150/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5442 - accuracy: 0.7985 - val_loss: 0.5528 - val_accuracy: 0.7924\n",
            "Epoch 151/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5447 - accuracy: 0.7999 - val_loss: 0.5550 - val_accuracy: 0.7883\n",
            "Epoch 152/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5458 - accuracy: 0.7984 - val_loss: 0.5532 - val_accuracy: 0.7927\n",
            "Epoch 153/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5445 - accuracy: 0.7977 - val_loss: 0.5542 - val_accuracy: 0.7916\n",
            "Epoch 154/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.7986 - val_loss: 0.5522 - val_accuracy: 0.7943\n",
            "Epoch 155/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5449 - accuracy: 0.7996 - val_loss: 0.5531 - val_accuracy: 0.7902\n",
            "Epoch 156/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5454 - accuracy: 0.7981 - val_loss: 0.5532 - val_accuracy: 0.7918\n",
            "Epoch 157/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5446 - accuracy: 0.7984 - val_loss: 0.5527 - val_accuracy: 0.7916\n",
            "Epoch 158/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5529 - val_accuracy: 0.7910\n",
            "Epoch 159/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5447 - accuracy: 0.7995 - val_loss: 0.5563 - val_accuracy: 0.7880\n",
            "Epoch 160/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5449 - accuracy: 0.7986 - val_loss: 0.5577 - val_accuracy: 0.7913\n",
            "Epoch 161/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.7985 - val_loss: 0.5536 - val_accuracy: 0.7929\n",
            "Epoch 162/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5446 - accuracy: 0.7980 - val_loss: 0.5528 - val_accuracy: 0.7927\n",
            "Epoch 163/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5450 - accuracy: 0.7990 - val_loss: 0.5591 - val_accuracy: 0.7916\n",
            "Epoch 164/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5448 - accuracy: 0.7995 - val_loss: 0.5547 - val_accuracy: 0.7907\n",
            "Epoch 165/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5451 - accuracy: 0.8005 - val_loss: 0.5523 - val_accuracy: 0.7932\n",
            "Epoch 166/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5444 - accuracy: 0.7991 - val_loss: 0.5526 - val_accuracy: 0.7905\n",
            "Epoch 167/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.7992 - val_loss: 0.5528 - val_accuracy: 0.7921\n",
            "Epoch 168/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5445 - accuracy: 0.7986 - val_loss: 0.5532 - val_accuracy: 0.7907\n",
            "Epoch 169/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5448 - accuracy: 0.7983 - val_loss: 0.5529 - val_accuracy: 0.7924\n",
            "Epoch 170/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5444 - accuracy: 0.7995 - val_loss: 0.5533 - val_accuracy: 0.7951\n",
            "Epoch 171/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5456 - accuracy: 0.7985 - val_loss: 0.5550 - val_accuracy: 0.7899\n",
            "Epoch 172/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5454 - accuracy: 0.7998 - val_loss: 0.5527 - val_accuracy: 0.7921\n",
            "Epoch 173/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7985 - val_loss: 0.5526 - val_accuracy: 0.7927\n",
            "Epoch 174/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.7991 - val_loss: 0.5582 - val_accuracy: 0.7888\n",
            "Epoch 175/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5450 - accuracy: 0.7985 - val_loss: 0.5529 - val_accuracy: 0.7880\n",
            "Epoch 176/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.7989 - val_loss: 0.5525 - val_accuracy: 0.7918\n",
            "Epoch 177/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5448 - accuracy: 0.7999 - val_loss: 0.5529 - val_accuracy: 0.7921\n",
            "Epoch 178/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5450 - accuracy: 0.7994 - val_loss: 0.5531 - val_accuracy: 0.7905\n",
            "Epoch 179/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5470 - accuracy: 0.7974 - val_loss: 0.5532 - val_accuracy: 0.7916\n",
            "Epoch 180/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5441 - accuracy: 0.7982 - val_loss: 0.5529 - val_accuracy: 0.7896\n",
            "Epoch 181/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5441 - accuracy: 0.7991 - val_loss: 0.5544 - val_accuracy: 0.7866\n",
            "Epoch 182/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5450 - accuracy: 0.7980 - val_loss: 0.5529 - val_accuracy: 0.7916\n",
            "Epoch 183/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5439 - accuracy: 0.7974 - val_loss: 0.5535 - val_accuracy: 0.7883\n",
            "Epoch 184/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5444 - accuracy: 0.7991 - val_loss: 0.5544 - val_accuracy: 0.7910\n",
            "Epoch 185/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.8004 - val_loss: 0.5562 - val_accuracy: 0.7883\n",
            "Epoch 186/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5452 - accuracy: 0.7980 - val_loss: 0.5533 - val_accuracy: 0.7924\n",
            "Epoch 187/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5442 - accuracy: 0.7986 - val_loss: 0.5538 - val_accuracy: 0.7918\n",
            "Epoch 188/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5450 - accuracy: 0.7997 - val_loss: 0.5528 - val_accuracy: 0.7921\n",
            "Epoch 189/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.7988 - val_loss: 0.5532 - val_accuracy: 0.7927\n",
            "Epoch 190/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5452 - accuracy: 0.7988 - val_loss: 0.5527 - val_accuracy: 0.7905\n",
            "Epoch 191/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5445 - accuracy: 0.7982 - val_loss: 0.5550 - val_accuracy: 0.7894\n",
            "Epoch 192/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5445 - accuracy: 0.7990 - val_loss: 0.5528 - val_accuracy: 0.7921\n",
            "Epoch 193/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5450 - accuracy: 0.7997 - val_loss: 0.5553 - val_accuracy: 0.7883\n",
            "Epoch 194/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7981 - val_loss: 0.5527 - val_accuracy: 0.7932\n",
            "Epoch 195/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5443 - accuracy: 0.7986 - val_loss: 0.5525 - val_accuracy: 0.7921\n",
            "Epoch 196/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5447 - accuracy: 0.7981 - val_loss: 0.5564 - val_accuracy: 0.7905\n",
            "Epoch 197/850\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.5442 - accuracy: 0.7994 - val_loss: 0.5526 - val_accuracy: 0.7935\n",
            "Epoch 198/850\n",
            "52/52 [==============================] - 2s 36ms/step - loss: 0.5443 - accuracy: 0.7990 - val_loss: 0.5561 - val_accuracy: 0.7910\n",
            "Epoch 199/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5453 - accuracy: 0.7997 - val_loss: 0.5523 - val_accuracy: 0.7913\n",
            "Epoch 200/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5448 - accuracy: 0.7991 - val_loss: 0.5547 - val_accuracy: 0.7883\n",
            "Epoch 201/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5443 - accuracy: 0.7987 - val_loss: 0.5526 - val_accuracy: 0.7921\n",
            "Epoch 202/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5445 - accuracy: 0.7986 - val_loss: 0.5524 - val_accuracy: 0.7921\n",
            "Epoch 203/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5446 - accuracy: 0.7999 - val_loss: 0.5580 - val_accuracy: 0.7899\n",
            "Epoch 204/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5454 - accuracy: 0.7992 - val_loss: 0.5522 - val_accuracy: 0.7940\n",
            "Epoch 205/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7983 - val_loss: 0.5548 - val_accuracy: 0.7910\n",
            "Epoch 206/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.7997 - val_loss: 0.5537 - val_accuracy: 0.7885\n",
            "Epoch 207/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.7996 - val_loss: 0.5530 - val_accuracy: 0.7938\n",
            "Epoch 208/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.7996 - val_loss: 0.5531 - val_accuracy: 0.7927\n",
            "Epoch 209/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5448 - accuracy: 0.7999 - val_loss: 0.5536 - val_accuracy: 0.7907\n",
            "Epoch 210/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5442 - accuracy: 0.7981 - val_loss: 0.5526 - val_accuracy: 0.7924\n",
            "Epoch 211/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5455 - accuracy: 0.7989 - val_loss: 0.5573 - val_accuracy: 0.7896\n",
            "Epoch 212/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5452 - accuracy: 0.7986 - val_loss: 0.5524 - val_accuracy: 0.7918\n",
            "Epoch 213/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5442 - accuracy: 0.7976 - val_loss: 0.5536 - val_accuracy: 0.7918\n",
            "Epoch 214/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.7997 - val_loss: 0.5518 - val_accuracy: 0.7924\n",
            "Epoch 215/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5439 - accuracy: 0.7988 - val_loss: 0.5526 - val_accuracy: 0.7902\n",
            "Epoch 216/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5447 - accuracy: 0.7989 - val_loss: 0.5539 - val_accuracy: 0.7921\n",
            "Epoch 217/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.7996 - val_loss: 0.5524 - val_accuracy: 0.7905\n",
            "Epoch 218/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7975 - val_loss: 0.5546 - val_accuracy: 0.7860\n",
            "Epoch 219/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5444 - accuracy: 0.7987 - val_loss: 0.5526 - val_accuracy: 0.7924\n",
            "Epoch 220/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5446 - accuracy: 0.7990 - val_loss: 0.5527 - val_accuracy: 0.7905\n",
            "Epoch 221/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7980 - val_loss: 0.5526 - val_accuracy: 0.7929\n",
            "Epoch 222/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5451 - accuracy: 0.7982 - val_loss: 0.5579 - val_accuracy: 0.7880\n",
            "Epoch 223/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5459 - accuracy: 0.7996 - val_loss: 0.5544 - val_accuracy: 0.7910\n",
            "Epoch 224/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5458 - accuracy: 0.7985 - val_loss: 0.5543 - val_accuracy: 0.7910\n",
            "Epoch 225/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.7983 - val_loss: 0.5531 - val_accuracy: 0.7885\n",
            "Epoch 226/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5444 - accuracy: 0.7995 - val_loss: 0.5541 - val_accuracy: 0.7891\n",
            "Epoch 227/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5443 - accuracy: 0.7985 - val_loss: 0.5536 - val_accuracy: 0.7916\n",
            "Epoch 228/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5445 - accuracy: 0.7992 - val_loss: 0.5524 - val_accuracy: 0.7916\n",
            "Epoch 229/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5449 - accuracy: 0.7994 - val_loss: 0.5523 - val_accuracy: 0.7916\n",
            "Epoch 230/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5441 - accuracy: 0.7984 - val_loss: 0.5529 - val_accuracy: 0.7907\n",
            "Epoch 231/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5441 - accuracy: 0.7982 - val_loss: 0.5527 - val_accuracy: 0.7905\n",
            "Epoch 232/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7993 - val_loss: 0.5571 - val_accuracy: 0.7907\n",
            "Epoch 233/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5447 - accuracy: 0.7989 - val_loss: 0.5525 - val_accuracy: 0.7932\n",
            "Epoch 234/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7994 - val_loss: 0.5525 - val_accuracy: 0.7940\n",
            "Epoch 235/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5453 - accuracy: 0.7976 - val_loss: 0.5528 - val_accuracy: 0.7940\n",
            "Epoch 236/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.7986 - val_loss: 0.5522 - val_accuracy: 0.7905\n",
            "Epoch 237/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5447 - accuracy: 0.7996 - val_loss: 0.5670 - val_accuracy: 0.7880\n",
            "Epoch 238/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5456 - accuracy: 0.7994 - val_loss: 0.5521 - val_accuracy: 0.7913\n",
            "Epoch 239/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5443 - accuracy: 0.8010 - val_loss: 0.5520 - val_accuracy: 0.7924\n",
            "Epoch 240/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5451 - accuracy: 0.7986 - val_loss: 0.5523 - val_accuracy: 0.7938\n",
            "Epoch 241/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5438 - accuracy: 0.7989 - val_loss: 0.5524 - val_accuracy: 0.7929\n",
            "Epoch 242/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5521 - val_accuracy: 0.7916\n",
            "Epoch 243/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5443 - accuracy: 0.7983 - val_loss: 0.5524 - val_accuracy: 0.7943\n",
            "Epoch 244/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5438 - accuracy: 0.7988 - val_loss: 0.5533 - val_accuracy: 0.7921\n",
            "Epoch 245/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5438 - accuracy: 0.8004 - val_loss: 0.5531 - val_accuracy: 0.7927\n",
            "Epoch 246/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.7999 - val_loss: 0.5521 - val_accuracy: 0.7943\n",
            "Epoch 247/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7992 - val_loss: 0.5520 - val_accuracy: 0.7916\n",
            "Epoch 248/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5437 - accuracy: 0.7990 - val_loss: 0.5524 - val_accuracy: 0.7913\n",
            "Epoch 249/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5443 - accuracy: 0.8003 - val_loss: 0.5534 - val_accuracy: 0.7924\n",
            "Epoch 250/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.7997 - val_loss: 0.5538 - val_accuracy: 0.7913\n",
            "Epoch 251/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5453 - accuracy: 0.7995 - val_loss: 0.5548 - val_accuracy: 0.7888\n",
            "Epoch 252/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5451 - accuracy: 0.7998 - val_loss: 0.5527 - val_accuracy: 0.7927\n",
            "Epoch 253/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5453 - accuracy: 0.7997 - val_loss: 0.5532 - val_accuracy: 0.7913\n",
            "Epoch 254/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5436 - accuracy: 0.8012 - val_loss: 0.5519 - val_accuracy: 0.7954\n",
            "Epoch 255/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.8001 - val_loss: 0.5523 - val_accuracy: 0.7924\n",
            "Epoch 256/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.7989 - val_loss: 0.5526 - val_accuracy: 0.7929\n",
            "Epoch 257/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5444 - accuracy: 0.7994 - val_loss: 0.5538 - val_accuracy: 0.7891\n",
            "Epoch 258/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5448 - accuracy: 0.7989 - val_loss: 0.5528 - val_accuracy: 0.7938\n",
            "Epoch 259/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5447 - accuracy: 0.7994 - val_loss: 0.5528 - val_accuracy: 0.7913\n",
            "Epoch 260/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5435 - accuracy: 0.7985 - val_loss: 0.5529 - val_accuracy: 0.7921\n",
            "Epoch 261/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5438 - accuracy: 0.8000 - val_loss: 0.5522 - val_accuracy: 0.7927\n",
            "Epoch 262/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5442 - accuracy: 0.8003 - val_loss: 0.5526 - val_accuracy: 0.7907\n",
            "Epoch 263/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5439 - accuracy: 0.7993 - val_loss: 0.5571 - val_accuracy: 0.7913\n",
            "Epoch 264/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5454 - accuracy: 0.7998 - val_loss: 0.5546 - val_accuracy: 0.7894\n",
            "Epoch 265/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5447 - accuracy: 0.7990 - val_loss: 0.5523 - val_accuracy: 0.7918\n",
            "Epoch 266/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5524 - val_accuracy: 0.7921\n",
            "Epoch 267/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.7988 - val_loss: 0.5546 - val_accuracy: 0.7921\n",
            "Epoch 268/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7995 - val_loss: 0.5573 - val_accuracy: 0.7877\n",
            "Epoch 269/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5435 - accuracy: 0.7994 - val_loss: 0.5522 - val_accuracy: 0.7929\n",
            "Epoch 270/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.8001 - val_loss: 0.5537 - val_accuracy: 0.7921\n",
            "Epoch 271/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5456 - accuracy: 0.7988 - val_loss: 0.5577 - val_accuracy: 0.7888\n",
            "Epoch 272/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.7938\n",
            "Epoch 273/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7993 - val_loss: 0.5521 - val_accuracy: 0.7927\n",
            "Epoch 274/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5433 - accuracy: 0.8002 - val_loss: 0.5529 - val_accuracy: 0.7940\n",
            "Epoch 275/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5440 - accuracy: 0.7990 - val_loss: 0.5534 - val_accuracy: 0.7932\n",
            "Epoch 276/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5437 - accuracy: 0.8008 - val_loss: 0.5520 - val_accuracy: 0.7907\n",
            "Epoch 277/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5440 - accuracy: 0.8005 - val_loss: 0.5521 - val_accuracy: 0.7935\n",
            "Epoch 278/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5449 - accuracy: 0.8002 - val_loss: 0.5566 - val_accuracy: 0.7896\n",
            "Epoch 279/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5450 - accuracy: 0.7994 - val_loss: 0.5526 - val_accuracy: 0.7918\n",
            "Epoch 280/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5456 - accuracy: 0.8003 - val_loss: 0.5528 - val_accuracy: 0.7935\n",
            "Epoch 281/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7997 - val_loss: 0.5522 - val_accuracy: 0.7902\n",
            "Epoch 282/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.8006 - val_loss: 0.5520 - val_accuracy: 0.7924\n",
            "Epoch 283/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5453 - accuracy: 0.7997 - val_loss: 0.5517 - val_accuracy: 0.7940\n",
            "Epoch 284/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.7995 - val_loss: 0.5522 - val_accuracy: 0.7921\n",
            "Epoch 285/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5433 - accuracy: 0.7996 - val_loss: 0.5530 - val_accuracy: 0.7935\n",
            "Epoch 286/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.7993 - val_loss: 0.5524 - val_accuracy: 0.7951\n",
            "Epoch 287/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7984 - val_loss: 0.5566 - val_accuracy: 0.7885\n",
            "Epoch 288/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.7988 - val_loss: 0.5517 - val_accuracy: 0.7938\n",
            "Epoch 289/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5438 - accuracy: 0.7996 - val_loss: 0.5532 - val_accuracy: 0.7918\n",
            "Epoch 290/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5446 - accuracy: 0.7995 - val_loss: 0.5556 - val_accuracy: 0.7899\n",
            "Epoch 291/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5436 - accuracy: 0.7989 - val_loss: 0.5521 - val_accuracy: 0.7918\n",
            "Epoch 292/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5443 - accuracy: 0.8001 - val_loss: 0.5520 - val_accuracy: 0.7902\n",
            "Epoch 293/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5434 - accuracy: 0.7987 - val_loss: 0.5532 - val_accuracy: 0.7935\n",
            "Epoch 294/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5439 - accuracy: 0.7994 - val_loss: 0.5526 - val_accuracy: 0.7935\n",
            "Epoch 295/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8011 - val_loss: 0.5518 - val_accuracy: 0.7924\n",
            "Epoch 296/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.7998 - val_loss: 0.5523 - val_accuracy: 0.7905\n",
            "Epoch 297/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7994 - val_loss: 0.5527 - val_accuracy: 0.7913\n",
            "Epoch 298/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5443 - accuracy: 0.7999 - val_loss: 0.5528 - val_accuracy: 0.7938\n",
            "Epoch 299/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7996 - val_loss: 0.5532 - val_accuracy: 0.7891\n",
            "Epoch 300/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.7993 - val_loss: 0.5521 - val_accuracy: 0.7918\n",
            "Epoch 301/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.8017 - val_loss: 0.5525 - val_accuracy: 0.7938\n",
            "Epoch 302/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7991 - val_loss: 0.5522 - val_accuracy: 0.7927\n",
            "Epoch 303/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8008 - val_loss: 0.5521 - val_accuracy: 0.7943\n",
            "Epoch 304/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5445 - accuracy: 0.7997 - val_loss: 0.5526 - val_accuracy: 0.7918\n",
            "Epoch 305/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5437 - accuracy: 0.7996 - val_loss: 0.5531 - val_accuracy: 0.7921\n",
            "Epoch 306/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7997 - val_loss: 0.5521 - val_accuracy: 0.7918\n",
            "Epoch 307/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5441 - accuracy: 0.7994 - val_loss: 0.5557 - val_accuracy: 0.7899\n",
            "Epoch 308/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5461 - accuracy: 0.8016 - val_loss: 0.5535 - val_accuracy: 0.7927\n",
            "Epoch 309/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5443 - accuracy: 0.8009 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 310/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5440 - accuracy: 0.8006 - val_loss: 0.5547 - val_accuracy: 0.7905\n",
            "Epoch 311/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8012 - val_loss: 0.5517 - val_accuracy: 0.7949\n",
            "Epoch 312/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5522 - val_accuracy: 0.7929\n",
            "Epoch 313/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.7993 - val_loss: 0.5527 - val_accuracy: 0.7954\n",
            "Epoch 314/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7994 - val_loss: 0.5518 - val_accuracy: 0.7927\n",
            "Epoch 315/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.7995 - val_loss: 0.5523 - val_accuracy: 0.7929\n",
            "Epoch 316/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5441 - accuracy: 0.8006 - val_loss: 0.5560 - val_accuracy: 0.7880\n",
            "Epoch 317/850\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.5441 - accuracy: 0.7998 - val_loss: 0.5519 - val_accuracy: 0.7916\n",
            "Epoch 318/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5445 - accuracy: 0.8008 - val_loss: 0.5570 - val_accuracy: 0.7896\n",
            "Epoch 319/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.7996 - val_loss: 0.5521 - val_accuracy: 0.7924\n",
            "Epoch 320/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5455 - accuracy: 0.8007 - val_loss: 0.5527 - val_accuracy: 0.7916\n",
            "Epoch 321/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5438 - accuracy: 0.8007 - val_loss: 0.5544 - val_accuracy: 0.7913\n",
            "Epoch 322/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5450 - accuracy: 0.8001 - val_loss: 0.5551 - val_accuracy: 0.7888\n",
            "Epoch 323/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5444 - accuracy: 0.7990 - val_loss: 0.5522 - val_accuracy: 0.7949\n",
            "Epoch 324/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5440 - accuracy: 0.7992 - val_loss: 0.5528 - val_accuracy: 0.7935\n",
            "Epoch 325/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.7993 - val_loss: 0.5530 - val_accuracy: 0.7921\n",
            "Epoch 326/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5433 - accuracy: 0.8003 - val_loss: 0.5522 - val_accuracy: 0.7910\n",
            "Epoch 327/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.8012 - val_loss: 0.5523 - val_accuracy: 0.7946\n",
            "Epoch 328/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.7997 - val_loss: 0.5524 - val_accuracy: 0.7910\n",
            "Epoch 329/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7994 - val_loss: 0.5518 - val_accuracy: 0.7905\n",
            "Epoch 330/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8005 - val_loss: 0.5550 - val_accuracy: 0.7907\n",
            "Epoch 331/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8002 - val_loss: 0.5528 - val_accuracy: 0.7907\n",
            "Epoch 332/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5433 - accuracy: 0.8000 - val_loss: 0.5531 - val_accuracy: 0.7918\n",
            "Epoch 333/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.8005 - val_loss: 0.5518 - val_accuracy: 0.7932\n",
            "Epoch 334/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7995 - val_loss: 0.5521 - val_accuracy: 0.7940\n",
            "Epoch 335/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.8002 - val_loss: 0.5533 - val_accuracy: 0.7938\n",
            "Epoch 336/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7995 - val_loss: 0.5534 - val_accuracy: 0.7960\n",
            "Epoch 337/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5577 - val_accuracy: 0.7872\n",
            "Epoch 338/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5440 - accuracy: 0.8002 - val_loss: 0.5522 - val_accuracy: 0.7938\n",
            "Epoch 339/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5451 - accuracy: 0.8005 - val_loss: 0.5521 - val_accuracy: 0.7921\n",
            "Epoch 340/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5441 - accuracy: 0.8001 - val_loss: 0.5523 - val_accuracy: 0.7902\n",
            "Epoch 341/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.8016 - val_loss: 0.5546 - val_accuracy: 0.7916\n",
            "Epoch 342/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8006 - val_loss: 0.5534 - val_accuracy: 0.7921\n",
            "Epoch 343/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8001 - val_loss: 0.5519 - val_accuracy: 0.7924\n",
            "Epoch 344/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5445 - accuracy: 0.7997 - val_loss: 0.5535 - val_accuracy: 0.7894\n",
            "Epoch 345/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7985 - val_loss: 0.5522 - val_accuracy: 0.7943\n",
            "Epoch 346/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.7985 - val_loss: 0.5530 - val_accuracy: 0.7929\n",
            "Epoch 347/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7997 - val_loss: 0.5522 - val_accuracy: 0.7921\n",
            "Epoch 348/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5439 - accuracy: 0.7991 - val_loss: 0.5526 - val_accuracy: 0.7940\n",
            "Epoch 349/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8007 - val_loss: 0.5567 - val_accuracy: 0.7910\n",
            "Epoch 350/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.7994 - val_loss: 0.5547 - val_accuracy: 0.7905\n",
            "Epoch 351/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7996 - val_loss: 0.5531 - val_accuracy: 0.7924\n",
            "Epoch 352/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5437 - accuracy: 0.8007 - val_loss: 0.5521 - val_accuracy: 0.7924\n",
            "Epoch 353/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.7994 - val_loss: 0.5522 - val_accuracy: 0.7910\n",
            "Epoch 354/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5437 - accuracy: 0.8001 - val_loss: 0.5524 - val_accuracy: 0.7910\n",
            "Epoch 355/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5454 - accuracy: 0.7997 - val_loss: 0.5524 - val_accuracy: 0.7943\n",
            "Epoch 356/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5438 - accuracy: 0.7995 - val_loss: 0.5524 - val_accuracy: 0.7938\n",
            "Epoch 357/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5446 - accuracy: 0.7994 - val_loss: 0.5535 - val_accuracy: 0.7935\n",
            "Epoch 358/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8000 - val_loss: 0.5527 - val_accuracy: 0.7938\n",
            "Epoch 359/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.7918\n",
            "Epoch 360/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5447 - accuracy: 0.8006 - val_loss: 0.5550 - val_accuracy: 0.7894\n",
            "Epoch 361/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5434 - accuracy: 0.7991 - val_loss: 0.5536 - val_accuracy: 0.7927\n",
            "Epoch 362/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.7991 - val_loss: 0.5526 - val_accuracy: 0.7913\n",
            "Epoch 363/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.7995 - val_loss: 0.5520 - val_accuracy: 0.7913\n",
            "Epoch 364/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.7996 - val_loss: 0.5542 - val_accuracy: 0.7905\n",
            "Epoch 365/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7998 - val_loss: 0.5523 - val_accuracy: 0.7935\n",
            "Epoch 366/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.8009 - val_loss: 0.5522 - val_accuracy: 0.7921\n",
            "Epoch 367/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5444 - accuracy: 0.7989 - val_loss: 0.5524 - val_accuracy: 0.7929\n",
            "Epoch 368/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7996 - val_loss: 0.5519 - val_accuracy: 0.7927\n",
            "Epoch 369/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5438 - accuracy: 0.7999 - val_loss: 0.5521 - val_accuracy: 0.7916\n",
            "Epoch 370/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5438 - accuracy: 0.8010 - val_loss: 0.5529 - val_accuracy: 0.7902\n",
            "Epoch 371/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5437 - accuracy: 0.7985 - val_loss: 0.5531 - val_accuracy: 0.7921\n",
            "Epoch 372/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5442 - accuracy: 0.7992 - val_loss: 0.5523 - val_accuracy: 0.7943\n",
            "Epoch 373/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7995 - val_loss: 0.5529 - val_accuracy: 0.7929\n",
            "Epoch 374/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5432 - accuracy: 0.8005 - val_loss: 0.5525 - val_accuracy: 0.7929\n",
            "Epoch 375/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.8005 - val_loss: 0.5519 - val_accuracy: 0.7938\n",
            "Epoch 376/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5443 - accuracy: 0.7977 - val_loss: 0.5521 - val_accuracy: 0.7935\n",
            "Epoch 377/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5455 - accuracy: 0.8003 - val_loss: 0.5528 - val_accuracy: 0.7924\n",
            "Epoch 378/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7905\n",
            "Epoch 379/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.8003 - val_loss: 0.5538 - val_accuracy: 0.7907\n",
            "Epoch 380/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5443 - accuracy: 0.7998 - val_loss: 0.5552 - val_accuracy: 0.7902\n",
            "Epoch 381/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5444 - accuracy: 0.8004 - val_loss: 0.5549 - val_accuracy: 0.7894\n",
            "Epoch 382/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.8005 - val_loss: 0.5529 - val_accuracy: 0.7927\n",
            "Epoch 383/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5449 - accuracy: 0.8011 - val_loss: 0.5522 - val_accuracy: 0.7907\n",
            "Epoch 384/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5447 - accuracy: 0.7999 - val_loss: 0.5528 - val_accuracy: 0.7929\n",
            "Epoch 385/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7998 - val_loss: 0.5519 - val_accuracy: 0.7951\n",
            "Epoch 386/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7992 - val_loss: 0.5529 - val_accuracy: 0.7935\n",
            "Epoch 387/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5449 - accuracy: 0.8008 - val_loss: 0.5519 - val_accuracy: 0.7938\n",
            "Epoch 388/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.8001 - val_loss: 0.5530 - val_accuracy: 0.7935\n",
            "Epoch 389/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5526 - val_accuracy: 0.7927\n",
            "Epoch 390/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5436 - accuracy: 0.7996 - val_loss: 0.5522 - val_accuracy: 0.7916\n",
            "Epoch 391/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5445 - accuracy: 0.7998 - val_loss: 0.5527 - val_accuracy: 0.7943\n",
            "Epoch 392/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.8000 - val_loss: 0.5537 - val_accuracy: 0.7921\n",
            "Epoch 393/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8006 - val_loss: 0.5583 - val_accuracy: 0.7877\n",
            "Epoch 394/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5445 - accuracy: 0.8007 - val_loss: 0.5553 - val_accuracy: 0.7907\n",
            "Epoch 395/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7998 - val_loss: 0.5521 - val_accuracy: 0.7932\n",
            "Epoch 396/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5444 - accuracy: 0.8004 - val_loss: 0.5614 - val_accuracy: 0.7877\n",
            "Epoch 397/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8000 - val_loss: 0.5522 - val_accuracy: 0.7918\n",
            "Epoch 398/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.5525 - val_accuracy: 0.7935\n",
            "Epoch 399/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5438 - accuracy: 0.8007 - val_loss: 0.5539 - val_accuracy: 0.7929\n",
            "Epoch 400/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5436 - accuracy: 0.8004 - val_loss: 0.5521 - val_accuracy: 0.7929\n",
            "Epoch 401/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5440 - accuracy: 0.8003 - val_loss: 0.5524 - val_accuracy: 0.7949\n",
            "Epoch 402/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5433 - accuracy: 0.8003 - val_loss: 0.5525 - val_accuracy: 0.7935\n",
            "Epoch 403/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.7998 - val_loss: 0.5520 - val_accuracy: 0.7907\n",
            "Epoch 404/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7997 - val_loss: 0.5520 - val_accuracy: 0.7918\n",
            "Epoch 405/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5439 - accuracy: 0.8001 - val_loss: 0.5520 - val_accuracy: 0.7896\n",
            "Epoch 406/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7998 - val_loss: 0.5524 - val_accuracy: 0.7927\n",
            "Epoch 407/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7993 - val_loss: 0.5522 - val_accuracy: 0.7913\n",
            "Epoch 408/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.7998 - val_loss: 0.5521 - val_accuracy: 0.7935\n",
            "Epoch 409/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.8014 - val_loss: 0.5520 - val_accuracy: 0.7949\n",
            "Epoch 410/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.7993 - val_loss: 0.5527 - val_accuracy: 0.7918\n",
            "Epoch 411/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.7996 - val_loss: 0.5583 - val_accuracy: 0.7872\n",
            "Epoch 412/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5438 - accuracy: 0.7997 - val_loss: 0.5526 - val_accuracy: 0.7932\n",
            "Epoch 413/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5447 - accuracy: 0.8001 - val_loss: 0.5519 - val_accuracy: 0.7929\n",
            "Epoch 414/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.8006 - val_loss: 0.5527 - val_accuracy: 0.7940\n",
            "Epoch 415/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5447 - accuracy: 0.7991 - val_loss: 0.5524 - val_accuracy: 0.7918\n",
            "Epoch 416/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5441 - accuracy: 0.8004 - val_loss: 0.5522 - val_accuracy: 0.7943\n",
            "Epoch 417/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5440 - accuracy: 0.7995 - val_loss: 0.5557 - val_accuracy: 0.7918\n",
            "Epoch 418/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5439 - accuracy: 0.7998 - val_loss: 0.5527 - val_accuracy: 0.7940\n",
            "Epoch 419/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5432 - accuracy: 0.7998 - val_loss: 0.5521 - val_accuracy: 0.7929\n",
            "Epoch 420/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7996 - val_loss: 0.5529 - val_accuracy: 0.7927\n",
            "Epoch 421/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.7989 - val_loss: 0.5539 - val_accuracy: 0.7916\n",
            "Epoch 422/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.8004 - val_loss: 0.5522 - val_accuracy: 0.7940\n",
            "Epoch 423/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5522 - val_accuracy: 0.7918\n",
            "Epoch 424/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5434 - accuracy: 0.8000 - val_loss: 0.5529 - val_accuracy: 0.7921\n",
            "Epoch 425/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5532 - val_accuracy: 0.7932\n",
            "Epoch 426/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5532 - val_accuracy: 0.7957\n",
            "Epoch 427/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5442 - accuracy: 0.8004 - val_loss: 0.5543 - val_accuracy: 0.7916\n",
            "Epoch 428/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8003 - val_loss: 0.5534 - val_accuracy: 0.7916\n",
            "Epoch 429/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7986 - val_loss: 0.5536 - val_accuracy: 0.7938\n",
            "Epoch 430/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7995 - val_loss: 0.5556 - val_accuracy: 0.7913\n",
            "Epoch 431/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5444 - accuracy: 0.8006 - val_loss: 0.5519 - val_accuracy: 0.7935\n",
            "Epoch 432/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7998 - val_loss: 0.5523 - val_accuracy: 0.7957\n",
            "Epoch 433/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5436 - accuracy: 0.7997 - val_loss: 0.5522 - val_accuracy: 0.7954\n",
            "Epoch 434/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5437 - accuracy: 0.8000 - val_loss: 0.5519 - val_accuracy: 0.7938\n",
            "Epoch 435/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5445 - accuracy: 0.7993 - val_loss: 0.5531 - val_accuracy: 0.7924\n",
            "Epoch 436/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.7995 - val_loss: 0.5531 - val_accuracy: 0.7896\n",
            "Epoch 437/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.7996 - val_loss: 0.5543 - val_accuracy: 0.7929\n",
            "Epoch 438/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5443 - accuracy: 0.7997 - val_loss: 0.5528 - val_accuracy: 0.7938\n",
            "Epoch 439/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8011 - val_loss: 0.5540 - val_accuracy: 0.7874\n",
            "Epoch 440/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.8004 - val_loss: 0.5535 - val_accuracy: 0.7918\n",
            "Epoch 441/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5444 - accuracy: 0.7998 - val_loss: 0.5530 - val_accuracy: 0.7932\n",
            "Epoch 442/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7992 - val_loss: 0.5517 - val_accuracy: 0.7938\n",
            "Epoch 443/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5434 - accuracy: 0.7991 - val_loss: 0.5522 - val_accuracy: 0.7910\n",
            "Epoch 444/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7997 - val_loss: 0.5521 - val_accuracy: 0.7916\n",
            "Epoch 445/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5432 - accuracy: 0.8001 - val_loss: 0.5530 - val_accuracy: 0.7932\n",
            "Epoch 446/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5440 - accuracy: 0.8005 - val_loss: 0.5525 - val_accuracy: 0.7938\n",
            "Epoch 447/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5439 - accuracy: 0.8008 - val_loss: 0.5553 - val_accuracy: 0.7907\n",
            "Epoch 448/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5440 - accuracy: 0.8001 - val_loss: 0.5525 - val_accuracy: 0.7943\n",
            "Epoch 449/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5438 - accuracy: 0.7998 - val_loss: 0.5520 - val_accuracy: 0.7924\n",
            "Epoch 450/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5439 - accuracy: 0.8002 - val_loss: 0.5523 - val_accuracy: 0.7921\n",
            "Epoch 451/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.7991 - val_loss: 0.5529 - val_accuracy: 0.7905\n",
            "Epoch 452/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5445 - accuracy: 0.7996 - val_loss: 0.5519 - val_accuracy: 0.7932\n",
            "Epoch 453/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5441 - accuracy: 0.8002 - val_loss: 0.5522 - val_accuracy: 0.7910\n",
            "Epoch 454/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5436 - accuracy: 0.8012 - val_loss: 0.5540 - val_accuracy: 0.7885\n",
            "Epoch 455/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5443 - accuracy: 0.8001 - val_loss: 0.5543 - val_accuracy: 0.7899\n",
            "Epoch 456/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7999 - val_loss: 0.5522 - val_accuracy: 0.7910\n",
            "Epoch 457/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8011 - val_loss: 0.5523 - val_accuracy: 0.7888\n",
            "Epoch 458/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5524 - val_accuracy: 0.7929\n",
            "Epoch 459/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7990 - val_loss: 0.5520 - val_accuracy: 0.7916\n",
            "Epoch 460/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8003 - val_loss: 0.5536 - val_accuracy: 0.7910\n",
            "Epoch 461/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.8007 - val_loss: 0.5568 - val_accuracy: 0.7888\n",
            "Epoch 462/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5441 - accuracy: 0.8010 - val_loss: 0.5535 - val_accuracy: 0.7929\n",
            "Epoch 463/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5439 - accuracy: 0.8002 - val_loss: 0.5531 - val_accuracy: 0.7910\n",
            "Epoch 464/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5520 - val_accuracy: 0.7940\n",
            "Epoch 465/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5448 - accuracy: 0.8000 - val_loss: 0.5522 - val_accuracy: 0.7913\n",
            "Epoch 466/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5530 - val_accuracy: 0.7921\n",
            "Epoch 467/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.7999 - val_loss: 0.5521 - val_accuracy: 0.7918\n",
            "Epoch 468/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7983 - val_loss: 0.5523 - val_accuracy: 0.7924\n",
            "Epoch 469/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8010 - val_loss: 0.5520 - val_accuracy: 0.7935\n",
            "Epoch 470/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.8012 - val_loss: 0.5520 - val_accuracy: 0.7954\n",
            "Epoch 471/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7999 - val_loss: 0.5518 - val_accuracy: 0.7946\n",
            "Epoch 472/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.8002 - val_loss: 0.5544 - val_accuracy: 0.7910\n",
            "Epoch 473/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5442 - accuracy: 0.8008 - val_loss: 0.5521 - val_accuracy: 0.7949\n",
            "Epoch 474/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5432 - accuracy: 0.7984 - val_loss: 0.5523 - val_accuracy: 0.7921\n",
            "Epoch 475/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5433 - accuracy: 0.7994 - val_loss: 0.5518 - val_accuracy: 0.7927\n",
            "Epoch 476/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.8011 - val_loss: 0.5518 - val_accuracy: 0.7924\n",
            "Epoch 477/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5439 - accuracy: 0.8001 - val_loss: 0.5517 - val_accuracy: 0.7927\n",
            "Epoch 478/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.8005 - val_loss: 0.5524 - val_accuracy: 0.7916\n",
            "Epoch 479/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5433 - accuracy: 0.7989 - val_loss: 0.5522 - val_accuracy: 0.7907\n",
            "Epoch 480/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5438 - accuracy: 0.7998 - val_loss: 0.5521 - val_accuracy: 0.7951\n",
            "Epoch 481/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5453 - accuracy: 0.8001 - val_loss: 0.5525 - val_accuracy: 0.7929\n",
            "Epoch 482/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5444 - accuracy: 0.7996 - val_loss: 0.5519 - val_accuracy: 0.7907\n",
            "Epoch 483/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5443 - accuracy: 0.8009 - val_loss: 0.5522 - val_accuracy: 0.7896\n",
            "Epoch 484/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.8004 - val_loss: 0.5516 - val_accuracy: 0.7943\n",
            "Epoch 485/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.7997 - val_loss: 0.5529 - val_accuracy: 0.7929\n",
            "Epoch 486/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.8001 - val_loss: 0.5526 - val_accuracy: 0.7935\n",
            "Epoch 487/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5442 - accuracy: 0.8005 - val_loss: 0.5529 - val_accuracy: 0.7913\n",
            "Epoch 488/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.7998 - val_loss: 0.5557 - val_accuracy: 0.7896\n",
            "Epoch 489/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5432 - accuracy: 0.7999 - val_loss: 0.5554 - val_accuracy: 0.7910\n",
            "Epoch 490/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.7993 - val_loss: 0.5524 - val_accuracy: 0.7924\n",
            "Epoch 491/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.8003 - val_loss: 0.5518 - val_accuracy: 0.7924\n",
            "Epoch 492/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5434 - accuracy: 0.7993 - val_loss: 0.5527 - val_accuracy: 0.7943\n",
            "Epoch 493/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.8005 - val_loss: 0.5541 - val_accuracy: 0.7921\n",
            "Epoch 494/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5447 - accuracy: 0.8009 - val_loss: 0.5531 - val_accuracy: 0.7951\n",
            "Epoch 495/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.8004 - val_loss: 0.5519 - val_accuracy: 0.7935\n",
            "Epoch 496/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5438 - accuracy: 0.8002 - val_loss: 0.5525 - val_accuracy: 0.7916\n",
            "Epoch 497/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5432 - accuracy: 0.7999 - val_loss: 0.5558 - val_accuracy: 0.7902\n",
            "Epoch 498/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.7997 - val_loss: 0.5521 - val_accuracy: 0.7943\n",
            "Epoch 499/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5533 - val_accuracy: 0.7910\n",
            "Epoch 500/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7991 - val_loss: 0.5518 - val_accuracy: 0.7940\n",
            "Epoch 501/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7990 - val_loss: 0.5528 - val_accuracy: 0.7927\n",
            "Epoch 502/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.8001 - val_loss: 0.5528 - val_accuracy: 0.7927\n",
            "Epoch 503/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8008 - val_loss: 0.5520 - val_accuracy: 0.7940\n",
            "Epoch 504/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8001 - val_loss: 0.5524 - val_accuracy: 0.7927\n",
            "Epoch 505/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.8001 - val_loss: 0.5526 - val_accuracy: 0.7924\n",
            "Epoch 506/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7995 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 507/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5434 - accuracy: 0.7997 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 508/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.7994 - val_loss: 0.5524 - val_accuracy: 0.7938\n",
            "Epoch 509/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5436 - accuracy: 0.7994 - val_loss: 0.5539 - val_accuracy: 0.7916\n",
            "Epoch 510/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5441 - accuracy: 0.8005 - val_loss: 0.5519 - val_accuracy: 0.7946\n",
            "Epoch 511/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5437 - accuracy: 0.7997 - val_loss: 0.5525 - val_accuracy: 0.7896\n",
            "Epoch 512/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.8000 - val_loss: 0.5529 - val_accuracy: 0.7913\n",
            "Epoch 513/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5454 - accuracy: 0.8005 - val_loss: 0.5521 - val_accuracy: 0.7929\n",
            "Epoch 514/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5432 - accuracy: 0.8001 - val_loss: 0.5521 - val_accuracy: 0.7921\n",
            "Epoch 515/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5449 - accuracy: 0.8010 - val_loss: 0.5597 - val_accuracy: 0.7880\n",
            "Epoch 516/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5455 - accuracy: 0.7995 - val_loss: 0.5537 - val_accuracy: 0.7905\n",
            "Epoch 517/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.7999 - val_loss: 0.5541 - val_accuracy: 0.7916\n",
            "Epoch 518/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8005 - val_loss: 0.5521 - val_accuracy: 0.7932\n",
            "Epoch 519/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.8004 - val_loss: 0.5522 - val_accuracy: 0.7924\n",
            "Epoch 520/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8002 - val_loss: 0.5523 - val_accuracy: 0.7932\n",
            "Epoch 521/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7994 - val_loss: 0.5539 - val_accuracy: 0.7907\n",
            "Epoch 522/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5446 - accuracy: 0.7999 - val_loss: 0.5547 - val_accuracy: 0.7883\n",
            "Epoch 523/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5442 - accuracy: 0.8016 - val_loss: 0.5533 - val_accuracy: 0.7891\n",
            "Epoch 524/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5438 - accuracy: 0.8003 - val_loss: 0.5519 - val_accuracy: 0.7918\n",
            "Epoch 525/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5443 - accuracy: 0.7999 - val_loss: 0.5523 - val_accuracy: 0.7938\n",
            "Epoch 526/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5446 - accuracy: 0.8006 - val_loss: 0.5554 - val_accuracy: 0.7899\n",
            "Epoch 527/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5443 - accuracy: 0.7991 - val_loss: 0.5525 - val_accuracy: 0.7940\n",
            "Epoch 528/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5433 - accuracy: 0.7994 - val_loss: 0.5520 - val_accuracy: 0.7924\n",
            "Epoch 529/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5438 - accuracy: 0.7995 - val_loss: 0.5533 - val_accuracy: 0.7927\n",
            "Epoch 530/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5438 - accuracy: 0.7998 - val_loss: 0.5544 - val_accuracy: 0.7899\n",
            "Epoch 531/850\n",
            "52/52 [==============================] - 2s 31ms/step - loss: 0.5441 - accuracy: 0.7996 - val_loss: 0.5549 - val_accuracy: 0.7907\n",
            "Epoch 532/850\n",
            "52/52 [==============================] - 2s 32ms/step - loss: 0.5445 - accuracy: 0.8005 - val_loss: 0.5540 - val_accuracy: 0.7869\n",
            "Epoch 533/850\n",
            "52/52 [==============================] - 2s 32ms/step - loss: 0.5456 - accuracy: 0.7985 - val_loss: 0.5522 - val_accuracy: 0.7940\n",
            "Epoch 534/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5440 - accuracy: 0.7996 - val_loss: 0.5520 - val_accuracy: 0.7943\n",
            "Epoch 535/850\n",
            "52/52 [==============================] - 2s 31ms/step - loss: 0.5439 - accuracy: 0.8005 - val_loss: 0.5538 - val_accuracy: 0.7918\n",
            "Epoch 536/850\n",
            "52/52 [==============================] - 2s 47ms/step - loss: 0.5440 - accuracy: 0.8010 - val_loss: 0.5530 - val_accuracy: 0.7902\n",
            "Epoch 537/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5433 - accuracy: 0.7993 - val_loss: 0.5520 - val_accuracy: 0.7907\n",
            "Epoch 538/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5435 - accuracy: 0.7999 - val_loss: 0.5519 - val_accuracy: 0.7927\n",
            "Epoch 539/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7995 - val_loss: 0.5518 - val_accuracy: 0.7935\n",
            "Epoch 540/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7991 - val_loss: 0.5521 - val_accuracy: 0.7929\n",
            "Epoch 541/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.8007 - val_loss: 0.5525 - val_accuracy: 0.7927\n",
            "Epoch 542/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7996 - val_loss: 0.5522 - val_accuracy: 0.7921\n",
            "Epoch 543/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7986 - val_loss: 0.5523 - val_accuracy: 0.7924\n",
            "Epoch 544/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7996 - val_loss: 0.5523 - val_accuracy: 0.7894\n",
            "Epoch 545/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5436 - accuracy: 0.7988 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 546/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5440 - accuracy: 0.8010 - val_loss: 0.5545 - val_accuracy: 0.7888\n",
            "Epoch 547/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5459 - accuracy: 0.7991 - val_loss: 0.5516 - val_accuracy: 0.7929\n",
            "Epoch 548/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5446 - accuracy: 0.7995 - val_loss: 0.5560 - val_accuracy: 0.7907\n",
            "Epoch 549/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.7996 - val_loss: 0.5518 - val_accuracy: 0.7910\n",
            "Epoch 550/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.8002 - val_loss: 0.5523 - val_accuracy: 0.7910\n",
            "Epoch 551/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5445 - accuracy: 0.7994 - val_loss: 0.5532 - val_accuracy: 0.7940\n",
            "Epoch 552/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5445 - accuracy: 0.8014 - val_loss: 0.5549 - val_accuracy: 0.7899\n",
            "Epoch 553/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5447 - accuracy: 0.8000 - val_loss: 0.5533 - val_accuracy: 0.7907\n",
            "Epoch 554/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5434 - accuracy: 0.7998 - val_loss: 0.5517 - val_accuracy: 0.7938\n",
            "Epoch 555/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5443 - accuracy: 0.7992 - val_loss: 0.5528 - val_accuracy: 0.7907\n",
            "Epoch 556/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8006 - val_loss: 0.5523 - val_accuracy: 0.7940\n",
            "Epoch 557/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7997 - val_loss: 0.5529 - val_accuracy: 0.7929\n",
            "Epoch 558/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5445 - accuracy: 0.7995 - val_loss: 0.5552 - val_accuracy: 0.7902\n",
            "Epoch 559/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.7999 - val_loss: 0.5529 - val_accuracy: 0.7916\n",
            "Epoch 560/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7990 - val_loss: 0.5527 - val_accuracy: 0.7927\n",
            "Epoch 561/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5534 - val_accuracy: 0.7921\n",
            "Epoch 562/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8009 - val_loss: 0.5524 - val_accuracy: 0.7935\n",
            "Epoch 563/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.8001 - val_loss: 0.5530 - val_accuracy: 0.7943\n",
            "Epoch 564/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8005 - val_loss: 0.5534 - val_accuracy: 0.7913\n",
            "Epoch 565/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.8002 - val_loss: 0.5517 - val_accuracy: 0.7938\n",
            "Epoch 566/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7991 - val_loss: 0.5541 - val_accuracy: 0.7894\n",
            "Epoch 567/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5439 - accuracy: 0.7997 - val_loss: 0.5530 - val_accuracy: 0.7913\n",
            "Epoch 568/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5436 - accuracy: 0.7987 - val_loss: 0.5520 - val_accuracy: 0.7910\n",
            "Epoch 569/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5444 - accuracy: 0.7999 - val_loss: 0.5544 - val_accuracy: 0.7885\n",
            "Epoch 570/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5436 - accuracy: 0.8006 - val_loss: 0.5522 - val_accuracy: 0.7916\n",
            "Epoch 571/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5451 - accuracy: 0.8008 - val_loss: 0.5521 - val_accuracy: 0.7929\n",
            "Epoch 572/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5443 - accuracy: 0.7995 - val_loss: 0.5564 - val_accuracy: 0.7896\n",
            "Epoch 573/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5444 - accuracy: 0.8010 - val_loss: 0.5522 - val_accuracy: 0.7902\n",
            "Epoch 574/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7987 - val_loss: 0.5526 - val_accuracy: 0.7935\n",
            "Epoch 575/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5439 - accuracy: 0.7993 - val_loss: 0.5521 - val_accuracy: 0.7921\n",
            "Epoch 576/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5438 - accuracy: 0.8009 - val_loss: 0.5522 - val_accuracy: 0.7938\n",
            "Epoch 577/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.8003 - val_loss: 0.5571 - val_accuracy: 0.7877\n",
            "Epoch 578/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5449 - accuracy: 0.7978 - val_loss: 0.5516 - val_accuracy: 0.7905\n",
            "Epoch 579/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7997 - val_loss: 0.5564 - val_accuracy: 0.7894\n",
            "Epoch 580/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.8004 - val_loss: 0.5524 - val_accuracy: 0.7905\n",
            "Epoch 581/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7999 - val_loss: 0.5535 - val_accuracy: 0.7902\n",
            "Epoch 582/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5439 - accuracy: 0.7988 - val_loss: 0.5519 - val_accuracy: 0.7943\n",
            "Epoch 583/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5432 - accuracy: 0.7996 - val_loss: 0.5520 - val_accuracy: 0.7949\n",
            "Epoch 584/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.8008 - val_loss: 0.5539 - val_accuracy: 0.7905\n",
            "Epoch 585/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5432 - accuracy: 0.7994 - val_loss: 0.5522 - val_accuracy: 0.7935\n",
            "Epoch 586/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.8001 - val_loss: 0.5575 - val_accuracy: 0.7896\n",
            "Epoch 587/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5456 - accuracy: 0.8007 - val_loss: 0.5529 - val_accuracy: 0.7938\n",
            "Epoch 588/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7995 - val_loss: 0.5521 - val_accuracy: 0.7907\n",
            "Epoch 589/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.7994 - val_loss: 0.5520 - val_accuracy: 0.7910\n",
            "Epoch 590/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.8001 - val_loss: 0.5531 - val_accuracy: 0.7924\n",
            "Epoch 591/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8005 - val_loss: 0.5520 - val_accuracy: 0.7924\n",
            "Epoch 592/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7984 - val_loss: 0.5537 - val_accuracy: 0.7940\n",
            "Epoch 593/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5437 - accuracy: 0.7997 - val_loss: 0.5521 - val_accuracy: 0.7924\n",
            "Epoch 594/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.7993 - val_loss: 0.5572 - val_accuracy: 0.7885\n",
            "Epoch 595/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.8005 - val_loss: 0.5581 - val_accuracy: 0.7905\n",
            "Epoch 596/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5446 - accuracy: 0.7997 - val_loss: 0.5520 - val_accuracy: 0.7938\n",
            "Epoch 597/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5438 - accuracy: 0.7999 - val_loss: 0.5534 - val_accuracy: 0.7943\n",
            "Epoch 598/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5436 - accuracy: 0.8003 - val_loss: 0.5524 - val_accuracy: 0.7905\n",
            "Epoch 599/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5448 - accuracy: 0.8002 - val_loss: 0.5557 - val_accuracy: 0.7902\n",
            "Epoch 600/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5438 - accuracy: 0.7999 - val_loss: 0.5521 - val_accuracy: 0.7927\n",
            "Epoch 601/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5436 - accuracy: 0.7997 - val_loss: 0.5523 - val_accuracy: 0.7913\n",
            "Epoch 602/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5438 - accuracy: 0.7996 - val_loss: 0.5524 - val_accuracy: 0.7910\n",
            "Epoch 603/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.8007 - val_loss: 0.5523 - val_accuracy: 0.7932\n",
            "Epoch 604/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.8004 - val_loss: 0.5538 - val_accuracy: 0.7896\n",
            "Epoch 605/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5442 - accuracy: 0.7999 - val_loss: 0.5524 - val_accuracy: 0.7927\n",
            "Epoch 606/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7991 - val_loss: 0.5531 - val_accuracy: 0.7907\n",
            "Epoch 607/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5446 - accuracy: 0.7996 - val_loss: 0.5519 - val_accuracy: 0.7913\n",
            "Epoch 608/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5436 - accuracy: 0.8012 - val_loss: 0.5536 - val_accuracy: 0.7896\n",
            "Epoch 609/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8009 - val_loss: 0.5534 - val_accuracy: 0.7899\n",
            "Epoch 610/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5431 - accuracy: 0.7989 - val_loss: 0.5525 - val_accuracy: 0.7907\n",
            "Epoch 611/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8001 - val_loss: 0.5525 - val_accuracy: 0.7918\n",
            "Epoch 612/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8007 - val_loss: 0.5525 - val_accuracy: 0.7938\n",
            "Epoch 613/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5437 - accuracy: 0.7996 - val_loss: 0.5525 - val_accuracy: 0.7916\n",
            "Epoch 614/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5437 - accuracy: 0.7993 - val_loss: 0.5567 - val_accuracy: 0.7883\n",
            "Epoch 615/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5439 - accuracy: 0.8004 - val_loss: 0.5526 - val_accuracy: 0.7924\n",
            "Epoch 616/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5439 - accuracy: 0.8009 - val_loss: 0.5519 - val_accuracy: 0.7921\n",
            "Epoch 617/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5436 - accuracy: 0.7999 - val_loss: 0.5542 - val_accuracy: 0.7913\n",
            "Epoch 618/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5435 - accuracy: 0.7999 - val_loss: 0.5520 - val_accuracy: 0.7921\n",
            "Epoch 619/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7993 - val_loss: 0.5525 - val_accuracy: 0.7927\n",
            "Epoch 620/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.8004 - val_loss: 0.5529 - val_accuracy: 0.7910\n",
            "Epoch 621/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5444 - accuracy: 0.7996 - val_loss: 0.5528 - val_accuracy: 0.7927\n",
            "Epoch 622/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7995 - val_loss: 0.5520 - val_accuracy: 0.7910\n",
            "Epoch 623/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5430 - accuracy: 0.7989 - val_loss: 0.5543 - val_accuracy: 0.7935\n",
            "Epoch 624/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8014 - val_loss: 0.5547 - val_accuracy: 0.7902\n",
            "Epoch 625/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.8005 - val_loss: 0.5525 - val_accuracy: 0.7938\n",
            "Epoch 626/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.7999 - val_loss: 0.5523 - val_accuracy: 0.7913\n",
            "Epoch 627/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7997 - val_loss: 0.5521 - val_accuracy: 0.7940\n",
            "Epoch 628/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8001 - val_loss: 0.5520 - val_accuracy: 0.7932\n",
            "Epoch 629/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5434 - accuracy: 0.7991 - val_loss: 0.5524 - val_accuracy: 0.7935\n",
            "Epoch 630/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5436 - accuracy: 0.8000 - val_loss: 0.5519 - val_accuracy: 0.7924\n",
            "Epoch 631/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5436 - accuracy: 0.7999 - val_loss: 0.5537 - val_accuracy: 0.7916\n",
            "Epoch 632/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5435 - accuracy: 0.8011 - val_loss: 0.5525 - val_accuracy: 0.7907\n",
            "Epoch 633/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5435 - accuracy: 0.8003 - val_loss: 0.5522 - val_accuracy: 0.7894\n",
            "Epoch 634/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5435 - accuracy: 0.8004 - val_loss: 0.5520 - val_accuracy: 0.7918\n",
            "Epoch 635/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5564 - val_accuracy: 0.7907\n",
            "Epoch 636/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7994 - val_loss: 0.5527 - val_accuracy: 0.7954\n",
            "Epoch 637/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5459 - accuracy: 0.7994 - val_loss: 0.5522 - val_accuracy: 0.7927\n",
            "Epoch 638/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5438 - accuracy: 0.8010 - val_loss: 0.5518 - val_accuracy: 0.7938\n",
            "Epoch 639/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.8006 - val_loss: 0.5519 - val_accuracy: 0.7916\n",
            "Epoch 640/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5430 - accuracy: 0.8004 - val_loss: 0.5568 - val_accuracy: 0.7905\n",
            "Epoch 641/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.8008 - val_loss: 0.5521 - val_accuracy: 0.7918\n",
            "Epoch 642/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.8000 - val_loss: 0.5555 - val_accuracy: 0.7894\n",
            "Epoch 643/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5446 - accuracy: 0.8004 - val_loss: 0.5524 - val_accuracy: 0.7907\n",
            "Epoch 644/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.5434 - accuracy: 0.8001 - val_loss: 0.5535 - val_accuracy: 0.7921\n",
            "Epoch 645/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5441 - accuracy: 0.7991 - val_loss: 0.5531 - val_accuracy: 0.7927\n",
            "Epoch 646/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5432 - accuracy: 0.8009 - val_loss: 0.5566 - val_accuracy: 0.7888\n",
            "Epoch 647/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.8000 - val_loss: 0.5519 - val_accuracy: 0.7932\n",
            "Epoch 648/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5438 - accuracy: 0.7992 - val_loss: 0.5519 - val_accuracy: 0.7927\n",
            "Epoch 649/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5439 - accuracy: 0.7999 - val_loss: 0.5520 - val_accuracy: 0.7940\n",
            "Epoch 650/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5441 - accuracy: 0.7997 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 651/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8002 - val_loss: 0.5526 - val_accuracy: 0.7932\n",
            "Epoch 652/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.8005 - val_loss: 0.5567 - val_accuracy: 0.7883\n",
            "Epoch 653/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5442 - accuracy: 0.8014 - val_loss: 0.5537 - val_accuracy: 0.7902\n",
            "Epoch 654/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.8008 - val_loss: 0.5541 - val_accuracy: 0.7924\n",
            "Epoch 655/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7998 - val_loss: 0.5525 - val_accuracy: 0.7929\n",
            "Epoch 656/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7992 - val_loss: 0.5521 - val_accuracy: 0.7924\n",
            "Epoch 657/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.7998 - val_loss: 0.5534 - val_accuracy: 0.7918\n",
            "Epoch 658/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5447 - accuracy: 0.7984 - val_loss: 0.5526 - val_accuracy: 0.7954\n",
            "Epoch 659/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5451 - accuracy: 0.7988 - val_loss: 0.5522 - val_accuracy: 0.7921\n",
            "Epoch 660/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5433 - accuracy: 0.7992 - val_loss: 0.5518 - val_accuracy: 0.7938\n",
            "Epoch 661/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5440 - accuracy: 0.8003 - val_loss: 0.5522 - val_accuracy: 0.7907\n",
            "Epoch 662/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5440 - accuracy: 0.7991 - val_loss: 0.5526 - val_accuracy: 0.7918\n",
            "Epoch 663/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.7994 - val_loss: 0.5530 - val_accuracy: 0.7896\n",
            "Epoch 664/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5445 - accuracy: 0.7992 - val_loss: 0.5543 - val_accuracy: 0.7921\n",
            "Epoch 665/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5437 - accuracy: 0.7993 - val_loss: 0.5557 - val_accuracy: 0.7894\n",
            "Epoch 666/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5456 - accuracy: 0.7992 - val_loss: 0.5519 - val_accuracy: 0.7938\n",
            "Epoch 667/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5445 - accuracy: 0.8001 - val_loss: 0.5532 - val_accuracy: 0.7921\n",
            "Epoch 668/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5436 - accuracy: 0.7996 - val_loss: 0.5522 - val_accuracy: 0.7918\n",
            "Epoch 669/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.8001 - val_loss: 0.5519 - val_accuracy: 0.7935\n",
            "Epoch 670/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5435 - accuracy: 0.7996 - val_loss: 0.5523 - val_accuracy: 0.7929\n",
            "Epoch 671/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7997 - val_loss: 0.5523 - val_accuracy: 0.7918\n",
            "Epoch 672/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7997 - val_loss: 0.5520 - val_accuracy: 0.7940\n",
            "Epoch 673/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.8002 - val_loss: 0.5527 - val_accuracy: 0.7913\n",
            "Epoch 674/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5439 - accuracy: 0.7996 - val_loss: 0.5526 - val_accuracy: 0.7918\n",
            "Epoch 675/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5442 - accuracy: 0.8012 - val_loss: 0.5536 - val_accuracy: 0.7921\n",
            "Epoch 676/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5438 - accuracy: 0.7998 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 677/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5432 - accuracy: 0.8000 - val_loss: 0.5519 - val_accuracy: 0.7927\n",
            "Epoch 678/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5431 - accuracy: 0.7987 - val_loss: 0.5532 - val_accuracy: 0.7916\n",
            "Epoch 679/850\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.5437 - accuracy: 0.8001 - val_loss: 0.5524 - val_accuracy: 0.7929\n",
            "Epoch 680/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7995 - val_loss: 0.5533 - val_accuracy: 0.7907\n",
            "Epoch 681/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.7996 - val_loss: 0.5529 - val_accuracy: 0.7918\n",
            "Epoch 682/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7995 - val_loss: 0.5522 - val_accuracy: 0.7918\n",
            "Epoch 683/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.8000 - val_loss: 0.5520 - val_accuracy: 0.7932\n",
            "Epoch 684/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5432 - accuracy: 0.7996 - val_loss: 0.5518 - val_accuracy: 0.7932\n",
            "Epoch 685/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.8001 - val_loss: 0.5525 - val_accuracy: 0.7907\n",
            "Epoch 686/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.5525 - val_accuracy: 0.7943\n",
            "Epoch 687/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5434 - accuracy: 0.7997 - val_loss: 0.5561 - val_accuracy: 0.7899\n",
            "Epoch 688/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5445 - accuracy: 0.7997 - val_loss: 0.5542 - val_accuracy: 0.7921\n",
            "Epoch 689/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7996 - val_loss: 0.5521 - val_accuracy: 0.7932\n",
            "Epoch 690/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.7997 - val_loss: 0.5533 - val_accuracy: 0.7938\n",
            "Epoch 691/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5440 - accuracy: 0.8010 - val_loss: 0.5527 - val_accuracy: 0.7938\n",
            "Epoch 692/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.8006 - val_loss: 0.5517 - val_accuracy: 0.7938\n",
            "Epoch 693/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.7999 - val_loss: 0.5535 - val_accuracy: 0.7918\n",
            "Epoch 694/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.5521 - val_accuracy: 0.7935\n",
            "Epoch 695/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5441 - accuracy: 0.7996 - val_loss: 0.5534 - val_accuracy: 0.7905\n",
            "Epoch 696/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.8001 - val_loss: 0.5520 - val_accuracy: 0.7935\n",
            "Epoch 697/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5432 - accuracy: 0.8005 - val_loss: 0.5523 - val_accuracy: 0.7943\n",
            "Epoch 698/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7995 - val_loss: 0.5535 - val_accuracy: 0.7927\n",
            "Epoch 699/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5452 - accuracy: 0.7992 - val_loss: 0.5536 - val_accuracy: 0.7918\n",
            "Epoch 700/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5438 - accuracy: 0.8008 - val_loss: 0.5525 - val_accuracy: 0.7913\n",
            "Epoch 701/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7995 - val_loss: 0.5522 - val_accuracy: 0.7913\n",
            "Epoch 702/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5445 - accuracy: 0.7994 - val_loss: 0.5539 - val_accuracy: 0.7913\n",
            "Epoch 703/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7999 - val_loss: 0.5544 - val_accuracy: 0.7916\n",
            "Epoch 704/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5518 - val_accuracy: 0.7943\n",
            "Epoch 705/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5432 - accuracy: 0.7992 - val_loss: 0.5519 - val_accuracy: 0.7921\n",
            "Epoch 706/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5455 - accuracy: 0.8010 - val_loss: 0.5520 - val_accuracy: 0.7943\n",
            "Epoch 707/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5444 - accuracy: 0.8006 - val_loss: 0.5522 - val_accuracy: 0.7913\n",
            "Epoch 708/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.8003 - val_loss: 0.5522 - val_accuracy: 0.7949\n",
            "Epoch 709/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5528 - val_accuracy: 0.7938\n",
            "Epoch 710/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5435 - accuracy: 0.7996 - val_loss: 0.5529 - val_accuracy: 0.7913\n",
            "Epoch 711/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.5524 - val_accuracy: 0.7929\n",
            "Epoch 712/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5450 - accuracy: 0.8007 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 713/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5445 - accuracy: 0.8008 - val_loss: 0.5528 - val_accuracy: 0.7929\n",
            "Epoch 714/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7996 - val_loss: 0.5527 - val_accuracy: 0.7960\n",
            "Epoch 715/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5432 - accuracy: 0.7999 - val_loss: 0.5527 - val_accuracy: 0.7910\n",
            "Epoch 716/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5436 - accuracy: 0.7996 - val_loss: 0.5520 - val_accuracy: 0.7935\n",
            "Epoch 717/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.7993 - val_loss: 0.5518 - val_accuracy: 0.7932\n",
            "Epoch 718/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5433 - accuracy: 0.7994 - val_loss: 0.5524 - val_accuracy: 0.7899\n",
            "Epoch 719/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5433 - accuracy: 0.7993 - val_loss: 0.5554 - val_accuracy: 0.7891\n",
            "Epoch 720/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7992 - val_loss: 0.5533 - val_accuracy: 0.7916\n",
            "Epoch 721/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7994 - val_loss: 0.5527 - val_accuracy: 0.7916\n",
            "Epoch 722/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5431 - accuracy: 0.7986 - val_loss: 0.5519 - val_accuracy: 0.7913\n",
            "Epoch 723/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5450 - accuracy: 0.7998 - val_loss: 0.5528 - val_accuracy: 0.7921\n",
            "Epoch 724/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5450 - accuracy: 0.8008 - val_loss: 0.5530 - val_accuracy: 0.7940\n",
            "Epoch 725/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5433 - accuracy: 0.7993 - val_loss: 0.5516 - val_accuracy: 0.7929\n",
            "Epoch 726/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5436 - accuracy: 0.7994 - val_loss: 0.5524 - val_accuracy: 0.7935\n",
            "Epoch 727/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.8004 - val_loss: 0.5520 - val_accuracy: 0.7921\n",
            "Epoch 728/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5439 - accuracy: 0.8001 - val_loss: 0.5556 - val_accuracy: 0.7905\n",
            "Epoch 729/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5437 - accuracy: 0.7999 - val_loss: 0.5517 - val_accuracy: 0.7929\n",
            "Epoch 730/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7992 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 731/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.5525 - val_accuracy: 0.7929\n",
            "Epoch 732/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5433 - accuracy: 0.8002 - val_loss: 0.5531 - val_accuracy: 0.7929\n",
            "Epoch 733/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5447 - accuracy: 0.8002 - val_loss: 0.5518 - val_accuracy: 0.7927\n",
            "Epoch 734/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7993 - val_loss: 0.5523 - val_accuracy: 0.7940\n",
            "Epoch 735/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.7996 - val_loss: 0.5526 - val_accuracy: 0.7921\n",
            "Epoch 736/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7990 - val_loss: 0.5522 - val_accuracy: 0.7902\n",
            "Epoch 737/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5438 - accuracy: 0.8008 - val_loss: 0.5520 - val_accuracy: 0.7918\n",
            "Epoch 738/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5430 - accuracy: 0.8000 - val_loss: 0.5521 - val_accuracy: 0.7938\n",
            "Epoch 739/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5433 - accuracy: 0.8010 - val_loss: 0.5519 - val_accuracy: 0.7916\n",
            "Epoch 740/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5435 - accuracy: 0.8005 - val_loss: 0.5522 - val_accuracy: 0.7927\n",
            "Epoch 741/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5433 - accuracy: 0.7996 - val_loss: 0.5529 - val_accuracy: 0.7910\n",
            "Epoch 742/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7993 - val_loss: 0.5544 - val_accuracy: 0.7916\n",
            "Epoch 743/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7986 - val_loss: 0.5523 - val_accuracy: 0.7924\n",
            "Epoch 744/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.8006 - val_loss: 0.5518 - val_accuracy: 0.7946\n",
            "Epoch 745/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7995 - val_loss: 0.5527 - val_accuracy: 0.7916\n",
            "Epoch 746/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5446 - accuracy: 0.7994 - val_loss: 0.5524 - val_accuracy: 0.7910\n",
            "Epoch 747/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5441 - accuracy: 0.8000 - val_loss: 0.5532 - val_accuracy: 0.7916\n",
            "Epoch 748/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.8004 - val_loss: 0.5519 - val_accuracy: 0.7943\n",
            "Epoch 749/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5432 - accuracy: 0.7992 - val_loss: 0.5536 - val_accuracy: 0.7902\n",
            "Epoch 750/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.7996 - val_loss: 0.5523 - val_accuracy: 0.7905\n",
            "Epoch 751/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5432 - accuracy: 0.7998 - val_loss: 0.5520 - val_accuracy: 0.7940\n",
            "Epoch 752/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5439 - accuracy: 0.8010 - val_loss: 0.5562 - val_accuracy: 0.7899\n",
            "Epoch 753/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5442 - accuracy: 0.8011 - val_loss: 0.5524 - val_accuracy: 0.7916\n",
            "Epoch 754/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5440 - accuracy: 0.8002 - val_loss: 0.5533 - val_accuracy: 0.7891\n",
            "Epoch 755/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5453 - accuracy: 0.8002 - val_loss: 0.5517 - val_accuracy: 0.7940\n",
            "Epoch 756/850\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.5437 - accuracy: 0.7993 - val_loss: 0.5528 - val_accuracy: 0.7954\n",
            "Epoch 757/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5433 - accuracy: 0.8000 - val_loss: 0.5531 - val_accuracy: 0.7929\n",
            "Epoch 758/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5433 - accuracy: 0.8004 - val_loss: 0.5522 - val_accuracy: 0.7894\n",
            "Epoch 759/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5433 - accuracy: 0.8005 - val_loss: 0.5531 - val_accuracy: 0.7902\n",
            "Epoch 760/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5439 - accuracy: 0.7992 - val_loss: 0.5519 - val_accuracy: 0.7929\n",
            "Epoch 761/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5435 - accuracy: 0.7992 - val_loss: 0.5522 - val_accuracy: 0.7918\n",
            "Epoch 762/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5432 - accuracy: 0.7995 - val_loss: 0.5518 - val_accuracy: 0.7927\n",
            "Epoch 763/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5432 - accuracy: 0.7995 - val_loss: 0.5519 - val_accuracy: 0.7935\n",
            "Epoch 764/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5435 - accuracy: 0.8001 - val_loss: 0.5525 - val_accuracy: 0.7916\n",
            "Epoch 765/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5433 - accuracy: 0.8000 - val_loss: 0.5520 - val_accuracy: 0.7929\n",
            "Epoch 766/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5436 - accuracy: 0.8002 - val_loss: 0.5523 - val_accuracy: 0.7927\n",
            "Epoch 767/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5437 - accuracy: 0.7998 - val_loss: 0.5522 - val_accuracy: 0.7929\n",
            "Epoch 768/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5438 - accuracy: 0.7999 - val_loss: 0.5521 - val_accuracy: 0.7940\n",
            "Epoch 769/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5433 - accuracy: 0.7989 - val_loss: 0.5524 - val_accuracy: 0.7924\n",
            "Epoch 770/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.5437 - accuracy: 0.8005 - val_loss: 0.5528 - val_accuracy: 0.7935\n",
            "Epoch 771/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5433 - accuracy: 0.7988 - val_loss: 0.5539 - val_accuracy: 0.7910\n",
            "Epoch 772/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5438 - accuracy: 0.8002 - val_loss: 0.5562 - val_accuracy: 0.7885\n",
            "Epoch 773/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5441 - accuracy: 0.8006 - val_loss: 0.5525 - val_accuracy: 0.7954\n",
            "Epoch 774/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5521 - val_accuracy: 0.7924\n",
            "Epoch 775/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5436 - accuracy: 0.7999 - val_loss: 0.5524 - val_accuracy: 0.7918\n",
            "Epoch 776/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5434 - accuracy: 0.7996 - val_loss: 0.5518 - val_accuracy: 0.7921\n",
            "Epoch 777/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5454 - accuracy: 0.7995 - val_loss: 0.5520 - val_accuracy: 0.7932\n",
            "Epoch 778/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5441 - accuracy: 0.8009 - val_loss: 0.5554 - val_accuracy: 0.7883\n",
            "Epoch 779/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.7991 - val_loss: 0.5521 - val_accuracy: 0.7932\n",
            "Epoch 780/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5449 - accuracy: 0.8005 - val_loss: 0.5517 - val_accuracy: 0.7927\n",
            "Epoch 781/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5440 - accuracy: 0.7992 - val_loss: 0.5518 - val_accuracy: 0.7938\n",
            "Epoch 782/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5439 - accuracy: 0.7999 - val_loss: 0.5524 - val_accuracy: 0.7943\n",
            "Epoch 783/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5435 - accuracy: 0.7992 - val_loss: 0.5535 - val_accuracy: 0.7910\n",
            "Epoch 784/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5434 - accuracy: 0.7997 - val_loss: 0.5522 - val_accuracy: 0.7905\n",
            "Epoch 785/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.7984 - val_loss: 0.5526 - val_accuracy: 0.7932\n",
            "Epoch 786/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5447 - accuracy: 0.8014 - val_loss: 0.5535 - val_accuracy: 0.7921\n",
            "Epoch 787/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5441 - accuracy: 0.8006 - val_loss: 0.5527 - val_accuracy: 0.7907\n",
            "Epoch 788/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5442 - accuracy: 0.7995 - val_loss: 0.5523 - val_accuracy: 0.7921\n",
            "Epoch 789/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.8004 - val_loss: 0.5525 - val_accuracy: 0.7932\n",
            "Epoch 790/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5443 - accuracy: 0.7998 - val_loss: 0.5519 - val_accuracy: 0.7927\n",
            "Epoch 791/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5434 - accuracy: 0.8006 - val_loss: 0.5521 - val_accuracy: 0.7943\n",
            "Epoch 792/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5439 - accuracy: 0.7990 - val_loss: 0.5521 - val_accuracy: 0.7913\n",
            "Epoch 793/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5436 - accuracy: 0.7998 - val_loss: 0.5524 - val_accuracy: 0.7918\n",
            "Epoch 794/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5433 - accuracy: 0.7993 - val_loss: 0.5521 - val_accuracy: 0.7935\n",
            "Epoch 795/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5436 - accuracy: 0.7988 - val_loss: 0.5529 - val_accuracy: 0.7954\n",
            "Epoch 796/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5438 - accuracy: 0.7998 - val_loss: 0.5521 - val_accuracy: 0.7938\n",
            "Epoch 797/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5439 - accuracy: 0.8008 - val_loss: 0.5520 - val_accuracy: 0.7932\n",
            "Epoch 798/850\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.5432 - accuracy: 0.8004 - val_loss: 0.5519 - val_accuracy: 0.7916\n",
            "Epoch 799/850\n",
            "52/52 [==============================] - 3s 48ms/step - loss: 0.5431 - accuracy: 0.7989 - val_loss: 0.5521 - val_accuracy: 0.7921\n",
            "Epoch 800/850\n",
            "52/52 [==============================] - 2s 48ms/step - loss: 0.5436 - accuracy: 0.7999 - val_loss: 0.5555 - val_accuracy: 0.7896\n",
            "Epoch 801/850\n",
            "52/52 [==============================] - 2s 38ms/step - loss: 0.5436 - accuracy: 0.8005 - val_loss: 0.5524 - val_accuracy: 0.7932\n",
            "Epoch 802/850\n",
            "52/52 [==============================] - 2s 33ms/step - loss: 0.5431 - accuracy: 0.7994 - val_loss: 0.5547 - val_accuracy: 0.7902\n",
            "Epoch 803/850\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.5438 - accuracy: 0.8015 - val_loss: 0.5524 - val_accuracy: 0.7932\n",
            "Epoch 804/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5442 - accuracy: 0.8002 - val_loss: 0.5531 - val_accuracy: 0.7918\n",
            "Epoch 805/850\n",
            "52/52 [==============================] - 2s 33ms/step - loss: 0.5437 - accuracy: 0.8008 - val_loss: 0.5524 - val_accuracy: 0.7916\n",
            "Epoch 806/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5439 - accuracy: 0.7979 - val_loss: 0.5530 - val_accuracy: 0.7951\n",
            "Epoch 807/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5441 - accuracy: 0.8002 - val_loss: 0.5530 - val_accuracy: 0.7916\n",
            "Epoch 808/850\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.5441 - accuracy: 0.7999 - val_loss: 0.5522 - val_accuracy: 0.7899\n",
            "Epoch 809/850\n",
            "52/52 [==============================] - 2s 33ms/step - loss: 0.5431 - accuracy: 0.7992 - val_loss: 0.5536 - val_accuracy: 0.7924\n",
            "Epoch 810/850\n",
            "52/52 [==============================] - 2s 38ms/step - loss: 0.5438 - accuracy: 0.7992 - val_loss: 0.5524 - val_accuracy: 0.7921\n",
            "Epoch 811/850\n",
            "52/52 [==============================] - 2s 38ms/step - loss: 0.5435 - accuracy: 0.8000 - val_loss: 0.5521 - val_accuracy: 0.7951\n",
            "Epoch 812/850\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.5439 - accuracy: 0.8012 - val_loss: 0.5532 - val_accuracy: 0.7894\n",
            "Epoch 813/850\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.5434 - accuracy: 0.7988 - val_loss: 0.5531 - val_accuracy: 0.7921\n",
            "Epoch 814/850\n",
            "52/52 [==============================] - 2s 34ms/step - loss: 0.5435 - accuracy: 0.8001 - val_loss: 0.5521 - val_accuracy: 0.7938\n",
            "Epoch 815/850\n",
            "52/52 [==============================] - 2s 42ms/step - loss: 0.5439 - accuracy: 0.8000 - val_loss: 0.5521 - val_accuracy: 0.7910\n",
            "Epoch 816/850\n",
            "52/52 [==============================] - 2s 36ms/step - loss: 0.5437 - accuracy: 0.7992 - val_loss: 0.5518 - val_accuracy: 0.7929\n",
            "Epoch 817/850\n",
            "52/52 [==============================] - 2s 39ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5519 - val_accuracy: 0.7951\n",
            "Epoch 818/850\n",
            "52/52 [==============================] - 2s 33ms/step - loss: 0.5436 - accuracy: 0.8003 - val_loss: 0.5521 - val_accuracy: 0.7921\n",
            "Epoch 819/850\n",
            "52/52 [==============================] - 2s 38ms/step - loss: 0.5434 - accuracy: 0.8006 - val_loss: 0.5524 - val_accuracy: 0.7929\n",
            "Epoch 820/850\n",
            "52/52 [==============================] - 2s 38ms/step - loss: 0.5443 - accuracy: 0.8009 - val_loss: 0.5529 - val_accuracy: 0.7918\n",
            "Epoch 821/850\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.5436 - accuracy: 0.7987 - val_loss: 0.5526 - val_accuracy: 0.7905\n",
            "Epoch 822/850\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.5433 - accuracy: 0.7998 - val_loss: 0.5528 - val_accuracy: 0.7921\n",
            "Epoch 823/850\n",
            "52/52 [==============================] - 1s 27ms/step - loss: 0.5442 - accuracy: 0.8001 - val_loss: 0.5533 - val_accuracy: 0.7910\n",
            "Epoch 824/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5434 - accuracy: 0.7999 - val_loss: 0.5531 - val_accuracy: 0.7946\n",
            "Epoch 825/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5432 - accuracy: 0.8005 - val_loss: 0.5522 - val_accuracy: 0.7929\n",
            "Epoch 826/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.7998 - val_loss: 0.5522 - val_accuracy: 0.7907\n",
            "Epoch 827/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5438 - accuracy: 0.8002 - val_loss: 0.5526 - val_accuracy: 0.7907\n",
            "Epoch 828/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5438 - accuracy: 0.8007 - val_loss: 0.5526 - val_accuracy: 0.7918\n",
            "Epoch 829/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5451 - accuracy: 0.7988 - val_loss: 0.5592 - val_accuracy: 0.7907\n",
            "Epoch 830/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5456 - accuracy: 0.7995 - val_loss: 0.5523 - val_accuracy: 0.7910\n",
            "Epoch 831/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5439 - accuracy: 0.8003 - val_loss: 0.5532 - val_accuracy: 0.7938\n",
            "Epoch 832/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5435 - accuracy: 0.7999 - val_loss: 0.5522 - val_accuracy: 0.7913\n",
            "Epoch 833/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5448 - accuracy: 0.8000 - val_loss: 0.5534 - val_accuracy: 0.7927\n",
            "Epoch 834/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5436 - accuracy: 0.7989 - val_loss: 0.5518 - val_accuracy: 0.7927\n",
            "Epoch 835/850\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.5440 - accuracy: 0.7997 - val_loss: 0.5525 - val_accuracy: 0.7954\n",
            "Epoch 836/850\n",
            "52/52 [==============================] - 2s 31ms/step - loss: 0.5446 - accuracy: 0.7990 - val_loss: 0.5518 - val_accuracy: 0.7935\n",
            "Epoch 837/850\n",
            "52/52 [==============================] - 2s 30ms/step - loss: 0.5434 - accuracy: 0.7990 - val_loss: 0.5520 - val_accuracy: 0.7935\n",
            "Epoch 838/850\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.5434 - accuracy: 0.7996 - val_loss: 0.5527 - val_accuracy: 0.7902\n",
            "Epoch 839/850\n",
            "52/52 [==============================] - 2s 29ms/step - loss: 0.5430 - accuracy: 0.7992 - val_loss: 0.5525 - val_accuracy: 0.7916\n",
            "Epoch 840/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.5443 - accuracy: 0.8005 - val_loss: 0.5637 - val_accuracy: 0.7877\n",
            "Epoch 841/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.7990 - val_loss: 0.5524 - val_accuracy: 0.7927\n",
            "Epoch 842/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.5434 - accuracy: 0.7995 - val_loss: 0.5519 - val_accuracy: 0.7938\n",
            "Epoch 843/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.5439 - accuracy: 0.7989 - val_loss: 0.5532 - val_accuracy: 0.7918\n",
            "Epoch 844/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5437 - accuracy: 0.7987 - val_loss: 0.5526 - val_accuracy: 0.7943\n",
            "Epoch 845/850\n",
            "52/52 [==============================] - 1s 26ms/step - loss: 0.5437 - accuracy: 0.8004 - val_loss: 0.5521 - val_accuracy: 0.7949\n",
            "Epoch 846/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.5439 - accuracy: 0.7998 - val_loss: 0.5520 - val_accuracy: 0.7910\n",
            "Epoch 847/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5433 - accuracy: 0.8001 - val_loss: 0.5529 - val_accuracy: 0.7949\n",
            "Epoch 848/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.7998 - val_loss: 0.5522 - val_accuracy: 0.7938\n",
            "Epoch 849/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.5434 - accuracy: 0.7994 - val_loss: 0.5521 - val_accuracy: 0.7924\n",
            "Epoch 850/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.5440 - accuracy: 0.8004 - val_loss: 0.5528 - val_accuracy: 0.7916\n"
          ]
        }
      ],
      "source": [
        "#2. Build the deep neural model\n",
        "init = he_normal(seed=1243)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=16, batch_size=BATCH_SIZE))\n",
        "for neurons in neurons_per_layer:\n",
        "  model.add(Dense(neurons, activation=\"relu\", kernel_initializer=init, kernel_regularizer = l2(0.01)))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer = l2(0.01)))\n",
        "#3. Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "#4. Train the model with M-BGD\n",
        "train21 = model.fit(data_train, labels_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(data_dev, labels_dev))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "54x_JuWLDl4C",
        "outputId": "d7e0e386-193f-4d9c-d05a-9a4fb0a045db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss = train21.history[\"loss\"]\n",
        "\n",
        "plt.plot(range(1, len(loss) + 1), loss, 'b', label='Error de entrenamiento')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCMYHsaeEIW6",
        "outputId": "49fffbd0-280a-4c66-baed-b6db825c1e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.5440102219581604 | Train accuracy: 0.8003860116004944\n",
            "114/114 [==============================] - 1s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.60      0.65      1175\n",
            "           1       0.82      0.88      0.85      2452\n",
            "\n",
            "    accuracy                           0.79      3627\n",
            "   macro avg       0.77      0.74      0.75      3627\n",
            "weighted avg       0.79      0.79      0.79      3627\n",
            "\n"
          ]
        }
      ],
      "source": [
        "results=pd.DataFrame(train21.history)\n",
        "print(f\"Train loss: {results.iloc[-1,0]} | Train accuracy: {results.iloc[-1,1]}\")\n",
        "predictions = model.predict(data_dev)\n",
        "predictions_binary = np.round(predictions)\n",
        "print(classification_report(labels_dev.values, predictions_binary))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "x1jRytDZg4mv",
        "outputId": "0737ec1a-ee85-4aa4-df21-fa1b00bb8da4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.callbacks.History</b><br/>def __init__()</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py</a>Callback that records events into a `History` object.\n",
              "\n",
              "This callback is automatically applied to\n",
              "every Keras model. The `History` object\n",
              "gets returned by the `fit` method of models.\n",
              "\n",
              "Example:\n",
              "\n",
              "&gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])\n",
              "&gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#x27;mse&#x27;)\n",
              "&gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),\n",
              "...                     epochs=10, verbose=1)\n",
              "&gt;&gt;&gt; print(history.params)\n",
              "{&#x27;verbose&#x27;: 1, &#x27;epochs&#x27;: 10, &#x27;steps&#x27;: 1}\n",
              "&gt;&gt;&gt; # check the keys of history object\n",
              "&gt;&gt;&gt; print(history.history.keys())\n",
              "dict_keys([&#x27;loss&#x27;])</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1184);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "keras.src.callbacks.History"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjfEBAtGhuy_"
      },
      "outputs": [],
      "source": [
        "#Guardamos los resultados de este modelo\n",
        "path = \"/gdrive/MyDrive/GIA/AA2/trainHistoryModel21.csv\"\n",
        "results.to_csv(path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXjRtKlXc6yz"
      },
      "source": [
        "### Model 2.2: l2(0.005)\n",
        "Same model but changing the l2 regularizer from 0.01 to 0.005\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2EmErn5DtuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8cc1ed-4082-447b-d499-9108b5641d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/850\n",
            "52/52 [==============================] - 4s 31ms/step - loss: 6.1633 - accuracy: 0.7622 - val_loss: 4.6733 - val_accuracy: 0.7827\n",
            "Epoch 2/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 3.7467 - accuracy: 0.7968 - val_loss: 2.9968 - val_accuracy: 0.7877\n",
            "Epoch 3/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 2.4864 - accuracy: 0.8001 - val_loss: 2.0775 - val_accuracy: 0.7963\n",
            "Epoch 4/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 1.7956 - accuracy: 0.8000 - val_loss: 1.5656 - val_accuracy: 0.7921\n",
            "Epoch 5/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 1.3975 - accuracy: 0.8035 - val_loss: 1.2612 - val_accuracy: 0.7985\n",
            "Epoch 6/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 1.1526 - accuracy: 0.8032 - val_loss: 1.0710 - val_accuracy: 0.7960\n",
            "Epoch 7/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.9947 - accuracy: 0.8051 - val_loss: 0.9434 - val_accuracy: 0.7951\n",
            "Epoch 8/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.8893 - accuracy: 0.8047 - val_loss: 0.8589 - val_accuracy: 0.7968\n",
            "Epoch 9/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.8120 - accuracy: 0.8061 - val_loss: 0.7894 - val_accuracy: 0.8012\n",
            "Epoch 10/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.7570 - accuracy: 0.8077 - val_loss: 0.7420 - val_accuracy: 0.7987\n",
            "Epoch 11/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.7188 - accuracy: 0.8039 - val_loss: 0.7056 - val_accuracy: 0.7982\n",
            "Epoch 12/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.6839 - accuracy: 0.8076 - val_loss: 0.6771 - val_accuracy: 0.7987\n",
            "Epoch 13/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.6593 - accuracy: 0.8065 - val_loss: 0.6570 - val_accuracy: 0.8015\n",
            "Epoch 14/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.6387 - accuracy: 0.8068 - val_loss: 0.6458 - val_accuracy: 0.7891\n",
            "Epoch 15/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.6216 - accuracy: 0.8067 - val_loss: 0.6299 - val_accuracy: 0.7968\n",
            "Epoch 16/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.6075 - accuracy: 0.8069 - val_loss: 0.6222 - val_accuracy: 0.7982\n",
            "Epoch 17/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5981 - accuracy: 0.8049 - val_loss: 0.5987 - val_accuracy: 0.7996\n",
            "Epoch 18/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5836 - accuracy: 0.8094 - val_loss: 0.5923 - val_accuracy: 0.8031\n",
            "Epoch 19/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5768 - accuracy: 0.8091 - val_loss: 0.5811 - val_accuracy: 0.7998\n",
            "Epoch 20/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5678 - accuracy: 0.8093 - val_loss: 0.5746 - val_accuracy: 0.7968\n",
            "Epoch 21/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5616 - accuracy: 0.8072 - val_loss: 0.5663 - val_accuracy: 0.8009\n",
            "Epoch 22/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5537 - accuracy: 0.8106 - val_loss: 0.5665 - val_accuracy: 0.8037\n",
            "Epoch 23/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5495 - accuracy: 0.8095 - val_loss: 0.5566 - val_accuracy: 0.7998\n",
            "Epoch 24/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5439 - accuracy: 0.8098 - val_loss: 0.5613 - val_accuracy: 0.8015\n",
            "Epoch 25/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5396 - accuracy: 0.8105 - val_loss: 0.5581 - val_accuracy: 0.7907\n",
            "Epoch 26/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5365 - accuracy: 0.8114 - val_loss: 0.5424 - val_accuracy: 0.8020\n",
            "Epoch 27/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5317 - accuracy: 0.8124 - val_loss: 0.5455 - val_accuracy: 0.7929\n",
            "Epoch 28/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5287 - accuracy: 0.8132 - val_loss: 0.5392 - val_accuracy: 0.8062\n",
            "Epoch 29/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5242 - accuracy: 0.8144 - val_loss: 0.5362 - val_accuracy: 0.8001\n",
            "Epoch 30/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5225 - accuracy: 0.8143 - val_loss: 0.5312 - val_accuracy: 0.8037\n",
            "Epoch 31/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.5187 - accuracy: 0.8159 - val_loss: 0.5295 - val_accuracy: 0.8029\n",
            "Epoch 32/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5178 - accuracy: 0.8143 - val_loss: 0.5317 - val_accuracy: 0.7965\n",
            "Epoch 33/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.5147 - accuracy: 0.8156 - val_loss: 0.5244 - val_accuracy: 0.8106\n",
            "Epoch 34/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.5151 - accuracy: 0.8140 - val_loss: 0.5240 - val_accuracy: 0.8029\n",
            "Epoch 35/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5140 - accuracy: 0.8144 - val_loss: 0.5211 - val_accuracy: 0.8084\n",
            "Epoch 36/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5115 - accuracy: 0.8151 - val_loss: 0.5203 - val_accuracy: 0.8062\n",
            "Epoch 37/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5078 - accuracy: 0.8170 - val_loss: 0.5174 - val_accuracy: 0.8051\n",
            "Epoch 38/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5065 - accuracy: 0.8166 - val_loss: 0.5157 - val_accuracy: 0.8078\n",
            "Epoch 39/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5063 - accuracy: 0.8165 - val_loss: 0.5177 - val_accuracy: 0.8018\n",
            "Epoch 40/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5049 - accuracy: 0.8152 - val_loss: 0.5197 - val_accuracy: 0.7987\n",
            "Epoch 41/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5086 - accuracy: 0.8137 - val_loss: 0.5139 - val_accuracy: 0.8070\n",
            "Epoch 42/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5030 - accuracy: 0.8151 - val_loss: 0.5122 - val_accuracy: 0.8098\n",
            "Epoch 43/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.5029 - accuracy: 0.8164 - val_loss: 0.5150 - val_accuracy: 0.8092\n",
            "Epoch 44/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.5001 - accuracy: 0.8173 - val_loss: 0.5168 - val_accuracy: 0.8111\n",
            "Epoch 45/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4981 - accuracy: 0.8177 - val_loss: 0.5098 - val_accuracy: 0.8042\n",
            "Epoch 46/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4980 - accuracy: 0.8175 - val_loss: 0.5101 - val_accuracy: 0.8034\n",
            "Epoch 47/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4982 - accuracy: 0.8163 - val_loss: 0.5088 - val_accuracy: 0.8089\n",
            "Epoch 48/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4982 - accuracy: 0.8159 - val_loss: 0.5086 - val_accuracy: 0.8029\n",
            "Epoch 49/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4950 - accuracy: 0.8192 - val_loss: 0.5070 - val_accuracy: 0.8106\n",
            "Epoch 50/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4947 - accuracy: 0.8190 - val_loss: 0.5065 - val_accuracy: 0.8120\n",
            "Epoch 51/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4930 - accuracy: 0.8197 - val_loss: 0.5073 - val_accuracy: 0.8098\n",
            "Epoch 52/850\n",
            "52/52 [==============================] - 1s 28ms/step - loss: 0.4933 - accuracy: 0.8199 - val_loss: 0.5060 - val_accuracy: 0.8133\n",
            "Epoch 53/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4944 - accuracy: 0.8187 - val_loss: 0.5185 - val_accuracy: 0.7951\n",
            "Epoch 54/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4948 - accuracy: 0.8166 - val_loss: 0.5024 - val_accuracy: 0.8103\n",
            "Epoch 55/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4926 - accuracy: 0.8163 - val_loss: 0.5029 - val_accuracy: 0.8103\n",
            "Epoch 56/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4913 - accuracy: 0.8187 - val_loss: 0.5023 - val_accuracy: 0.8114\n",
            "Epoch 57/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4906 - accuracy: 0.8187 - val_loss: 0.5010 - val_accuracy: 0.8133\n",
            "Epoch 58/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4889 - accuracy: 0.8205 - val_loss: 0.5007 - val_accuracy: 0.8144\n",
            "Epoch 59/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4927 - accuracy: 0.8185 - val_loss: 0.5024 - val_accuracy: 0.8133\n",
            "Epoch 60/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4887 - accuracy: 0.8196 - val_loss: 0.5004 - val_accuracy: 0.8084\n",
            "Epoch 61/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4892 - accuracy: 0.8191 - val_loss: 0.5134 - val_accuracy: 0.8147\n",
            "Epoch 62/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4897 - accuracy: 0.8188 - val_loss: 0.4982 - val_accuracy: 0.8100\n",
            "Epoch 63/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4870 - accuracy: 0.8191 - val_loss: 0.4982 - val_accuracy: 0.8180\n",
            "Epoch 64/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4866 - accuracy: 0.8217 - val_loss: 0.4986 - val_accuracy: 0.8153\n",
            "Epoch 65/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4875 - accuracy: 0.8216 - val_loss: 0.5004 - val_accuracy: 0.8076\n",
            "Epoch 66/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4863 - accuracy: 0.8220 - val_loss: 0.4988 - val_accuracy: 0.8133\n",
            "Epoch 67/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4877 - accuracy: 0.8192 - val_loss: 0.4983 - val_accuracy: 0.8136\n",
            "Epoch 68/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4854 - accuracy: 0.8213 - val_loss: 0.4969 - val_accuracy: 0.8114\n",
            "Epoch 69/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4863 - accuracy: 0.8208 - val_loss: 0.4982 - val_accuracy: 0.8153\n",
            "Epoch 70/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4848 - accuracy: 0.8209 - val_loss: 0.4980 - val_accuracy: 0.8139\n",
            "Epoch 71/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4838 - accuracy: 0.8232 - val_loss: 0.4993 - val_accuracy: 0.8156\n",
            "Epoch 72/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4851 - accuracy: 0.8209 - val_loss: 0.4968 - val_accuracy: 0.8087\n",
            "Epoch 73/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4841 - accuracy: 0.8219 - val_loss: 0.4958 - val_accuracy: 0.8136\n",
            "Epoch 74/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4843 - accuracy: 0.8210 - val_loss: 0.5000 - val_accuracy: 0.8012\n",
            "Epoch 75/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4845 - accuracy: 0.8202 - val_loss: 0.4981 - val_accuracy: 0.8122\n",
            "Epoch 76/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4842 - accuracy: 0.8224 - val_loss: 0.4938 - val_accuracy: 0.8186\n",
            "Epoch 77/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4827 - accuracy: 0.8232 - val_loss: 0.4953 - val_accuracy: 0.8133\n",
            "Epoch 78/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4843 - accuracy: 0.8204 - val_loss: 0.4938 - val_accuracy: 0.8128\n",
            "Epoch 79/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4837 - accuracy: 0.8212 - val_loss: 0.4952 - val_accuracy: 0.8109\n",
            "Epoch 80/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4817 - accuracy: 0.8230 - val_loss: 0.4949 - val_accuracy: 0.8136\n",
            "Epoch 81/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4814 - accuracy: 0.8226 - val_loss: 0.4971 - val_accuracy: 0.8053\n",
            "Epoch 82/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4818 - accuracy: 0.8236 - val_loss: 0.4944 - val_accuracy: 0.8136\n",
            "Epoch 83/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4811 - accuracy: 0.8215 - val_loss: 0.4953 - val_accuracy: 0.8114\n",
            "Epoch 84/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4844 - accuracy: 0.8189 - val_loss: 0.4931 - val_accuracy: 0.8202\n",
            "Epoch 85/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4834 - accuracy: 0.8188 - val_loss: 0.4960 - val_accuracy: 0.8150\n",
            "Epoch 86/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4849 - accuracy: 0.8190 - val_loss: 0.4930 - val_accuracy: 0.8167\n",
            "Epoch 87/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4803 - accuracy: 0.8228 - val_loss: 0.4934 - val_accuracy: 0.8158\n",
            "Epoch 88/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4807 - accuracy: 0.8226 - val_loss: 0.4930 - val_accuracy: 0.8098\n",
            "Epoch 89/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4804 - accuracy: 0.8250 - val_loss: 0.4916 - val_accuracy: 0.8133\n",
            "Epoch 90/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4798 - accuracy: 0.8234 - val_loss: 0.4919 - val_accuracy: 0.8125\n",
            "Epoch 91/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4811 - accuracy: 0.8218 - val_loss: 0.4904 - val_accuracy: 0.8161\n",
            "Epoch 92/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4793 - accuracy: 0.8241 - val_loss: 0.4918 - val_accuracy: 0.8150\n",
            "Epoch 93/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4790 - accuracy: 0.8234 - val_loss: 0.4909 - val_accuracy: 0.8191\n",
            "Epoch 94/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4802 - accuracy: 0.8244 - val_loss: 0.4908 - val_accuracy: 0.8169\n",
            "Epoch 95/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4785 - accuracy: 0.8243 - val_loss: 0.4997 - val_accuracy: 0.8156\n",
            "Epoch 96/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4805 - accuracy: 0.8210 - val_loss: 0.4905 - val_accuracy: 0.8161\n",
            "Epoch 97/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4816 - accuracy: 0.8218 - val_loss: 0.4924 - val_accuracy: 0.8098\n",
            "Epoch 98/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4799 - accuracy: 0.8218 - val_loss: 0.4895 - val_accuracy: 0.8180\n",
            "Epoch 99/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4789 - accuracy: 0.8235 - val_loss: 0.4899 - val_accuracy: 0.8142\n",
            "Epoch 100/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4784 - accuracy: 0.8243 - val_loss: 0.4910 - val_accuracy: 0.8125\n",
            "Epoch 101/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4793 - accuracy: 0.8233 - val_loss: 0.4904 - val_accuracy: 0.8172\n",
            "Epoch 102/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4795 - accuracy: 0.8227 - val_loss: 0.4902 - val_accuracy: 0.8156\n",
            "Epoch 103/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4790 - accuracy: 0.8225 - val_loss: 0.4889 - val_accuracy: 0.8183\n",
            "Epoch 104/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4776 - accuracy: 0.8235 - val_loss: 0.4904 - val_accuracy: 0.8120\n",
            "Epoch 105/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4792 - accuracy: 0.8243 - val_loss: 0.4906 - val_accuracy: 0.8175\n",
            "Epoch 106/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4806 - accuracy: 0.8212 - val_loss: 0.4932 - val_accuracy: 0.8164\n",
            "Epoch 107/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4793 - accuracy: 0.8227 - val_loss: 0.4892 - val_accuracy: 0.8153\n",
            "Epoch 108/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4782 - accuracy: 0.8231 - val_loss: 0.4911 - val_accuracy: 0.8122\n",
            "Epoch 109/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4784 - accuracy: 0.8249 - val_loss: 0.4895 - val_accuracy: 0.8158\n",
            "Epoch 110/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4800 - accuracy: 0.8219 - val_loss: 0.4900 - val_accuracy: 0.8158\n",
            "Epoch 111/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4784 - accuracy: 0.8229 - val_loss: 0.4885 - val_accuracy: 0.8144\n",
            "Epoch 112/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4813 - accuracy: 0.8213 - val_loss: 0.4886 - val_accuracy: 0.8156\n",
            "Epoch 113/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4782 - accuracy: 0.8220 - val_loss: 0.4921 - val_accuracy: 0.8067\n",
            "Epoch 114/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4776 - accuracy: 0.8242 - val_loss: 0.4878 - val_accuracy: 0.8167\n",
            "Epoch 115/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4774 - accuracy: 0.8222 - val_loss: 0.4920 - val_accuracy: 0.8150\n",
            "Epoch 116/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4781 - accuracy: 0.8241 - val_loss: 0.4896 - val_accuracy: 0.8164\n",
            "Epoch 117/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4765 - accuracy: 0.8230 - val_loss: 0.4880 - val_accuracy: 0.8164\n",
            "Epoch 118/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4774 - accuracy: 0.8214 - val_loss: 0.4890 - val_accuracy: 0.8133\n",
            "Epoch 119/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4764 - accuracy: 0.8250 - val_loss: 0.4942 - val_accuracy: 0.8056\n",
            "Epoch 120/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4779 - accuracy: 0.8238 - val_loss: 0.4892 - val_accuracy: 0.8197\n",
            "Epoch 121/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4770 - accuracy: 0.8246 - val_loss: 0.4874 - val_accuracy: 0.8189\n",
            "Epoch 122/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4759 - accuracy: 0.8251 - val_loss: 0.4895 - val_accuracy: 0.8216\n",
            "Epoch 123/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4761 - accuracy: 0.8266 - val_loss: 0.4921 - val_accuracy: 0.8150\n",
            "Epoch 124/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4764 - accuracy: 0.8249 - val_loss: 0.4878 - val_accuracy: 0.8169\n",
            "Epoch 125/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4761 - accuracy: 0.8253 - val_loss: 0.4934 - val_accuracy: 0.8191\n",
            "Epoch 126/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4756 - accuracy: 0.8264 - val_loss: 0.4894 - val_accuracy: 0.8202\n",
            "Epoch 127/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4774 - accuracy: 0.8248 - val_loss: 0.4909 - val_accuracy: 0.8111\n",
            "Epoch 128/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4759 - accuracy: 0.8244 - val_loss: 0.4882 - val_accuracy: 0.8158\n",
            "Epoch 129/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4750 - accuracy: 0.8256 - val_loss: 0.4982 - val_accuracy: 0.8169\n",
            "Epoch 130/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4769 - accuracy: 0.8243 - val_loss: 0.4914 - val_accuracy: 0.8128\n",
            "Epoch 131/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4760 - accuracy: 0.8237 - val_loss: 0.4887 - val_accuracy: 0.8111\n",
            "Epoch 132/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.4769 - accuracy: 0.8258 - val_loss: 0.4919 - val_accuracy: 0.8136\n",
            "Epoch 133/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4795 - accuracy: 0.8229 - val_loss: 0.5060 - val_accuracy: 0.8122\n",
            "Epoch 134/850\n",
            "52/52 [==============================] - 1s 12ms/step - loss: 0.4788 - accuracy: 0.8207 - val_loss: 0.4873 - val_accuracy: 0.8191\n",
            "Epoch 135/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4772 - accuracy: 0.8236 - val_loss: 0.4875 - val_accuracy: 0.8167\n",
            "Epoch 136/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4763 - accuracy: 0.8255 - val_loss: 0.4949 - val_accuracy: 0.8169\n",
            "Epoch 137/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4757 - accuracy: 0.8249 - val_loss: 0.4898 - val_accuracy: 0.8136\n",
            "Epoch 138/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4749 - accuracy: 0.8248 - val_loss: 0.4870 - val_accuracy: 0.8183\n",
            "Epoch 139/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4761 - accuracy: 0.8247 - val_loss: 0.4882 - val_accuracy: 0.8144\n",
            "Epoch 140/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4752 - accuracy: 0.8247 - val_loss: 0.4874 - val_accuracy: 0.8158\n",
            "Epoch 141/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4746 - accuracy: 0.8253 - val_loss: 0.4970 - val_accuracy: 0.8156\n",
            "Epoch 142/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4757 - accuracy: 0.8245 - val_loss: 0.4887 - val_accuracy: 0.8169\n",
            "Epoch 143/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4762 - accuracy: 0.8238 - val_loss: 0.4872 - val_accuracy: 0.8167\n",
            "Epoch 144/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4747 - accuracy: 0.8260 - val_loss: 0.4873 - val_accuracy: 0.8189\n",
            "Epoch 145/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4744 - accuracy: 0.8262 - val_loss: 0.4930 - val_accuracy: 0.8205\n",
            "Epoch 146/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4757 - accuracy: 0.8255 - val_loss: 0.4873 - val_accuracy: 0.8197\n",
            "Epoch 147/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4751 - accuracy: 0.8263 - val_loss: 0.4882 - val_accuracy: 0.8211\n",
            "Epoch 148/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4769 - accuracy: 0.8229 - val_loss: 0.4868 - val_accuracy: 0.8153\n",
            "Epoch 149/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4752 - accuracy: 0.8248 - val_loss: 0.4887 - val_accuracy: 0.8191\n",
            "Epoch 150/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4755 - accuracy: 0.8259 - val_loss: 0.4868 - val_accuracy: 0.8167\n",
            "Epoch 151/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4734 - accuracy: 0.8276 - val_loss: 0.4888 - val_accuracy: 0.8161\n",
            "Epoch 152/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4767 - accuracy: 0.8240 - val_loss: 0.4951 - val_accuracy: 0.8172\n",
            "Epoch 153/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4749 - accuracy: 0.8251 - val_loss: 0.4884 - val_accuracy: 0.8180\n",
            "Epoch 154/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4757 - accuracy: 0.8260 - val_loss: 0.4886 - val_accuracy: 0.8219\n",
            "Epoch 155/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4747 - accuracy: 0.8274 - val_loss: 0.4874 - val_accuracy: 0.8186\n",
            "Epoch 156/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.8256 - val_loss: 0.4891 - val_accuracy: 0.8180\n",
            "Epoch 157/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4750 - accuracy: 0.8252 - val_loss: 0.4869 - val_accuracy: 0.8164\n",
            "Epoch 158/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4763 - accuracy: 0.8236 - val_loss: 0.4922 - val_accuracy: 0.8158\n",
            "Epoch 159/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4746 - accuracy: 0.8263 - val_loss: 0.4864 - val_accuracy: 0.8172\n",
            "Epoch 160/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4761 - accuracy: 0.8241 - val_loss: 0.4911 - val_accuracy: 0.8156\n",
            "Epoch 161/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4748 - accuracy: 0.8253 - val_loss: 0.4890 - val_accuracy: 0.8169\n",
            "Epoch 162/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4742 - accuracy: 0.8275 - val_loss: 0.4889 - val_accuracy: 0.8191\n",
            "Epoch 163/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4739 - accuracy: 0.8254 - val_loss: 0.4861 - val_accuracy: 0.8202\n",
            "Epoch 164/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4740 - accuracy: 0.8268 - val_loss: 0.4868 - val_accuracy: 0.8222\n",
            "Epoch 165/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4738 - accuracy: 0.8269 - val_loss: 0.4863 - val_accuracy: 0.8189\n",
            "Epoch 166/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4738 - accuracy: 0.8265 - val_loss: 0.4862 - val_accuracy: 0.8180\n",
            "Epoch 167/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4744 - accuracy: 0.8253 - val_loss: 0.4879 - val_accuracy: 0.8200\n",
            "Epoch 168/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4750 - accuracy: 0.8252 - val_loss: 0.4865 - val_accuracy: 0.8222\n",
            "Epoch 169/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4748 - accuracy: 0.8270 - val_loss: 0.4883 - val_accuracy: 0.8169\n",
            "Epoch 170/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4751 - accuracy: 0.8260 - val_loss: 0.4879 - val_accuracy: 0.8164\n",
            "Epoch 171/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4737 - accuracy: 0.8273 - val_loss: 0.4871 - val_accuracy: 0.8169\n",
            "Epoch 172/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4745 - accuracy: 0.8270 - val_loss: 0.4876 - val_accuracy: 0.8191\n",
            "Epoch 173/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4737 - accuracy: 0.8283 - val_loss: 0.4904 - val_accuracy: 0.8183\n",
            "Epoch 174/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4740 - accuracy: 0.8271 - val_loss: 0.4890 - val_accuracy: 0.8180\n",
            "Epoch 175/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4738 - accuracy: 0.8268 - val_loss: 0.4884 - val_accuracy: 0.8219\n",
            "Epoch 176/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4734 - accuracy: 0.8258 - val_loss: 0.4889 - val_accuracy: 0.8153\n",
            "Epoch 177/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4751 - accuracy: 0.8252 - val_loss: 0.4855 - val_accuracy: 0.8205\n",
            "Epoch 178/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4742 - accuracy: 0.8269 - val_loss: 0.4909 - val_accuracy: 0.8208\n",
            "Epoch 179/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4752 - accuracy: 0.8252 - val_loss: 0.4857 - val_accuracy: 0.8194\n",
            "Epoch 180/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4737 - accuracy: 0.8268 - val_loss: 0.4865 - val_accuracy: 0.8189\n",
            "Epoch 181/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4733 - accuracy: 0.8271 - val_loss: 0.4865 - val_accuracy: 0.8208\n",
            "Epoch 182/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4742 - accuracy: 0.8262 - val_loss: 0.4879 - val_accuracy: 0.8191\n",
            "Epoch 183/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.8267 - val_loss: 0.4862 - val_accuracy: 0.8194\n",
            "Epoch 184/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4737 - accuracy: 0.8275 - val_loss: 0.4888 - val_accuracy: 0.8150\n",
            "Epoch 185/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4744 - accuracy: 0.8261 - val_loss: 0.4854 - val_accuracy: 0.8189\n",
            "Epoch 186/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4731 - accuracy: 0.8278 - val_loss: 0.4871 - val_accuracy: 0.8227\n",
            "Epoch 187/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4732 - accuracy: 0.8285 - val_loss: 0.4936 - val_accuracy: 0.8172\n",
            "Epoch 188/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4757 - accuracy: 0.8254 - val_loss: 0.4887 - val_accuracy: 0.8208\n",
            "Epoch 189/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4735 - accuracy: 0.8276 - val_loss: 0.4862 - val_accuracy: 0.8189\n",
            "Epoch 190/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4748 - accuracy: 0.8253 - val_loss: 0.4866 - val_accuracy: 0.8161\n",
            "Epoch 191/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4735 - accuracy: 0.8270 - val_loss: 0.4883 - val_accuracy: 0.8161\n",
            "Epoch 192/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4766 - accuracy: 0.8256 - val_loss: 0.4982 - val_accuracy: 0.8161\n",
            "Epoch 193/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4738 - accuracy: 0.8265 - val_loss: 0.4856 - val_accuracy: 0.8175\n",
            "Epoch 194/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4733 - accuracy: 0.8279 - val_loss: 0.4873 - val_accuracy: 0.8202\n",
            "Epoch 195/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4737 - accuracy: 0.8271 - val_loss: 0.4936 - val_accuracy: 0.8186\n",
            "Epoch 196/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.4727 - accuracy: 0.8268 - val_loss: 0.4859 - val_accuracy: 0.8175\n",
            "Epoch 197/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4733 - accuracy: 0.8264 - val_loss: 0.4931 - val_accuracy: 0.8197\n",
            "Epoch 198/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4730 - accuracy: 0.8275 - val_loss: 0.4865 - val_accuracy: 0.8189\n",
            "Epoch 199/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8265 - val_loss: 0.4879 - val_accuracy: 0.8186\n",
            "Epoch 200/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4735 - accuracy: 0.8272 - val_loss: 0.4872 - val_accuracy: 0.8183\n",
            "Epoch 201/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4745 - accuracy: 0.8280 - val_loss: 0.4855 - val_accuracy: 0.8191\n",
            "Epoch 202/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4730 - accuracy: 0.8273 - val_loss: 0.4868 - val_accuracy: 0.8202\n",
            "Epoch 203/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4738 - accuracy: 0.8263 - val_loss: 0.4915 - val_accuracy: 0.8178\n",
            "Epoch 204/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4732 - accuracy: 0.8266 - val_loss: 0.4872 - val_accuracy: 0.8200\n",
            "Epoch 205/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4733 - accuracy: 0.8265 - val_loss: 0.4859 - val_accuracy: 0.8211\n",
            "Epoch 206/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4727 - accuracy: 0.8274 - val_loss: 0.4856 - val_accuracy: 0.8178\n",
            "Epoch 207/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4723 - accuracy: 0.8280 - val_loss: 0.4847 - val_accuracy: 0.8202\n",
            "Epoch 208/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4754 - accuracy: 0.8260 - val_loss: 0.4929 - val_accuracy: 0.8164\n",
            "Epoch 209/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4735 - accuracy: 0.8260 - val_loss: 0.4900 - val_accuracy: 0.8208\n",
            "Epoch 210/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4745 - accuracy: 0.8265 - val_loss: 0.4877 - val_accuracy: 0.8125\n",
            "Epoch 211/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4739 - accuracy: 0.8258 - val_loss: 0.4919 - val_accuracy: 0.8040\n",
            "Epoch 212/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4728 - accuracy: 0.8275 - val_loss: 0.4852 - val_accuracy: 0.8180\n",
            "Epoch 213/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4749 - accuracy: 0.8256 - val_loss: 0.4912 - val_accuracy: 0.8191\n",
            "Epoch 214/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4727 - accuracy: 0.8276 - val_loss: 0.4854 - val_accuracy: 0.8213\n",
            "Epoch 215/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8285 - val_loss: 0.4897 - val_accuracy: 0.8213\n",
            "Epoch 216/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.8261 - val_loss: 0.4948 - val_accuracy: 0.8136\n",
            "Epoch 217/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.8249 - val_loss: 0.4855 - val_accuracy: 0.8133\n",
            "Epoch 218/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8273 - val_loss: 0.4884 - val_accuracy: 0.8183\n",
            "Epoch 219/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4732 - accuracy: 0.8277 - val_loss: 0.4871 - val_accuracy: 0.8153\n",
            "Epoch 220/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4735 - accuracy: 0.8272 - val_loss: 0.4914 - val_accuracy: 0.8106\n",
            "Epoch 221/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4753 - accuracy: 0.8265 - val_loss: 0.4879 - val_accuracy: 0.8213\n",
            "Epoch 222/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4734 - accuracy: 0.8275 - val_loss: 0.4861 - val_accuracy: 0.8178\n",
            "Epoch 223/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4738 - accuracy: 0.8252 - val_loss: 0.4892 - val_accuracy: 0.8144\n",
            "Epoch 224/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4729 - accuracy: 0.8271 - val_loss: 0.4861 - val_accuracy: 0.8230\n",
            "Epoch 225/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4743 - accuracy: 0.8267 - val_loss: 0.4874 - val_accuracy: 0.8172\n",
            "Epoch 226/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4729 - accuracy: 0.8266 - val_loss: 0.4864 - val_accuracy: 0.8180\n",
            "Epoch 227/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4729 - accuracy: 0.8283 - val_loss: 0.4893 - val_accuracy: 0.8161\n",
            "Epoch 228/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4734 - accuracy: 0.8259 - val_loss: 0.4853 - val_accuracy: 0.8205\n",
            "Epoch 229/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4730 - accuracy: 0.8275 - val_loss: 0.4852 - val_accuracy: 0.8202\n",
            "Epoch 230/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4722 - accuracy: 0.8273 - val_loss: 0.4852 - val_accuracy: 0.8211\n",
            "Epoch 231/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4736 - accuracy: 0.8263 - val_loss: 0.4866 - val_accuracy: 0.8175\n",
            "Epoch 232/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4751 - accuracy: 0.8245 - val_loss: 0.4863 - val_accuracy: 0.8197\n",
            "Epoch 233/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8274 - val_loss: 0.4879 - val_accuracy: 0.8200\n",
            "Epoch 234/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8273 - val_loss: 0.4857 - val_accuracy: 0.8183\n",
            "Epoch 235/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4737 - accuracy: 0.8267 - val_loss: 0.4854 - val_accuracy: 0.8189\n",
            "Epoch 236/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4737 - accuracy: 0.8243 - val_loss: 0.4856 - val_accuracy: 0.8216\n",
            "Epoch 237/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8282 - val_loss: 0.4938 - val_accuracy: 0.8197\n",
            "Epoch 238/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4738 - accuracy: 0.8265 - val_loss: 0.4855 - val_accuracy: 0.8219\n",
            "Epoch 239/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4741 - accuracy: 0.8271 - val_loss: 0.4925 - val_accuracy: 0.8202\n",
            "Epoch 240/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4766 - accuracy: 0.8243 - val_loss: 0.4852 - val_accuracy: 0.8189\n",
            "Epoch 241/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4720 - accuracy: 0.8268 - val_loss: 0.4898 - val_accuracy: 0.8158\n",
            "Epoch 242/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4726 - accuracy: 0.8270 - val_loss: 0.4872 - val_accuracy: 0.8150\n",
            "Epoch 243/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4727 - accuracy: 0.8268 - val_loss: 0.4896 - val_accuracy: 0.8189\n",
            "Epoch 244/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4720 - accuracy: 0.8283 - val_loss: 0.4845 - val_accuracy: 0.8241\n",
            "Epoch 245/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4727 - accuracy: 0.8263 - val_loss: 0.4847 - val_accuracy: 0.8202\n",
            "Epoch 246/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4718 - accuracy: 0.8277 - val_loss: 0.4844 - val_accuracy: 0.8222\n",
            "Epoch 247/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4728 - accuracy: 0.8270 - val_loss: 0.4857 - val_accuracy: 0.8186\n",
            "Epoch 248/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4737 - accuracy: 0.8267 - val_loss: 0.4849 - val_accuracy: 0.8183\n",
            "Epoch 249/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8280 - val_loss: 0.4897 - val_accuracy: 0.8213\n",
            "Epoch 250/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8274 - val_loss: 0.4854 - val_accuracy: 0.8216\n",
            "Epoch 251/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4730 - accuracy: 0.8269 - val_loss: 0.4858 - val_accuracy: 0.8178\n",
            "Epoch 252/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4729 - accuracy: 0.8270 - val_loss: 0.4854 - val_accuracy: 0.8186\n",
            "Epoch 253/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8277 - val_loss: 0.4846 - val_accuracy: 0.8213\n",
            "Epoch 254/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8281 - val_loss: 0.4859 - val_accuracy: 0.8156\n",
            "Epoch 255/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4739 - accuracy: 0.8273 - val_loss: 0.4865 - val_accuracy: 0.8194\n",
            "Epoch 256/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4729 - accuracy: 0.8283 - val_loss: 0.4854 - val_accuracy: 0.8191\n",
            "Epoch 257/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4732 - accuracy: 0.8282 - val_loss: 0.4861 - val_accuracy: 0.8227\n",
            "Epoch 258/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4721 - accuracy: 0.8282 - val_loss: 0.4851 - val_accuracy: 0.8191\n",
            "Epoch 259/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4722 - accuracy: 0.8281 - val_loss: 0.4889 - val_accuracy: 0.8156\n",
            "Epoch 260/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4756 - accuracy: 0.8256 - val_loss: 0.4879 - val_accuracy: 0.8169\n",
            "Epoch 261/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8286 - val_loss: 0.4852 - val_accuracy: 0.8205\n",
            "Epoch 262/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4730 - accuracy: 0.8285 - val_loss: 0.4847 - val_accuracy: 0.8194\n",
            "Epoch 263/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4745 - accuracy: 0.8262 - val_loss: 0.4848 - val_accuracy: 0.8169\n",
            "Epoch 264/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4726 - accuracy: 0.8269 - val_loss: 0.4849 - val_accuracy: 0.8197\n",
            "Epoch 265/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4726 - accuracy: 0.8273 - val_loss: 0.4844 - val_accuracy: 0.8233\n",
            "Epoch 266/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4722 - accuracy: 0.8285 - val_loss: 0.4855 - val_accuracy: 0.8227\n",
            "Epoch 267/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4722 - accuracy: 0.8279 - val_loss: 0.4855 - val_accuracy: 0.8172\n",
            "Epoch 268/850\n",
            "52/52 [==============================] - 1s 25ms/step - loss: 0.4733 - accuracy: 0.8266 - val_loss: 0.4843 - val_accuracy: 0.8222\n",
            "Epoch 269/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4736 - accuracy: 0.8277 - val_loss: 0.4936 - val_accuracy: 0.8186\n",
            "Epoch 270/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4726 - accuracy: 0.8288 - val_loss: 0.4850 - val_accuracy: 0.8224\n",
            "Epoch 271/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4726 - accuracy: 0.8283 - val_loss: 0.4851 - val_accuracy: 0.8208\n",
            "Epoch 272/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4719 - accuracy: 0.8278 - val_loss: 0.4847 - val_accuracy: 0.8216\n",
            "Epoch 273/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4715 - accuracy: 0.8274 - val_loss: 0.4859 - val_accuracy: 0.8235\n",
            "Epoch 274/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.8260 - val_loss: 0.4845 - val_accuracy: 0.8222\n",
            "Epoch 275/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8273 - val_loss: 0.4855 - val_accuracy: 0.8186\n",
            "Epoch 276/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4727 - accuracy: 0.8284 - val_loss: 0.4852 - val_accuracy: 0.8200\n",
            "Epoch 277/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.8277 - val_loss: 0.4852 - val_accuracy: 0.8167\n",
            "Epoch 278/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4733 - accuracy: 0.8259 - val_loss: 0.4850 - val_accuracy: 0.8211\n",
            "Epoch 279/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4742 - accuracy: 0.8254 - val_loss: 0.4851 - val_accuracy: 0.8180\n",
            "Epoch 280/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4742 - accuracy: 0.8262 - val_loss: 0.4858 - val_accuracy: 0.8202\n",
            "Epoch 281/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4719 - accuracy: 0.8284 - val_loss: 0.4860 - val_accuracy: 0.8164\n",
            "Epoch 282/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4720 - accuracy: 0.8275 - val_loss: 0.4855 - val_accuracy: 0.8216\n",
            "Epoch 283/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8289 - val_loss: 0.4876 - val_accuracy: 0.8208\n",
            "Epoch 284/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4726 - accuracy: 0.8275 - val_loss: 0.4901 - val_accuracy: 0.8200\n",
            "Epoch 285/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4727 - accuracy: 0.8284 - val_loss: 0.4847 - val_accuracy: 0.8216\n",
            "Epoch 286/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8278 - val_loss: 0.4881 - val_accuracy: 0.8202\n",
            "Epoch 287/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4726 - accuracy: 0.8283 - val_loss: 0.4919 - val_accuracy: 0.8172\n",
            "Epoch 288/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4746 - accuracy: 0.8258 - val_loss: 0.4944 - val_accuracy: 0.8189\n",
            "Epoch 289/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4731 - accuracy: 0.8272 - val_loss: 0.4896 - val_accuracy: 0.8109\n",
            "Epoch 290/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4725 - accuracy: 0.8273 - val_loss: 0.4858 - val_accuracy: 0.8194\n",
            "Epoch 291/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8286 - val_loss: 0.4847 - val_accuracy: 0.8219\n",
            "Epoch 292/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4727 - accuracy: 0.8270 - val_loss: 0.4846 - val_accuracy: 0.8213\n",
            "Epoch 293/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8267 - val_loss: 0.4858 - val_accuracy: 0.8191\n",
            "Epoch 294/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4726 - accuracy: 0.8276 - val_loss: 0.4867 - val_accuracy: 0.8158\n",
            "Epoch 295/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8276 - val_loss: 0.4862 - val_accuracy: 0.8227\n",
            "Epoch 296/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4723 - accuracy: 0.8289 - val_loss: 0.4873 - val_accuracy: 0.8189\n",
            "Epoch 297/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4727 - accuracy: 0.8270 - val_loss: 0.4882 - val_accuracy: 0.8144\n",
            "Epoch 298/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4747 - accuracy: 0.8253 - val_loss: 0.4902 - val_accuracy: 0.8186\n",
            "Epoch 299/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4739 - accuracy: 0.8269 - val_loss: 0.4900 - val_accuracy: 0.8189\n",
            "Epoch 300/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4731 - accuracy: 0.8274 - val_loss: 0.4862 - val_accuracy: 0.8175\n",
            "Epoch 301/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8284 - val_loss: 0.4850 - val_accuracy: 0.8222\n",
            "Epoch 302/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4745 - accuracy: 0.8253 - val_loss: 0.4846 - val_accuracy: 0.8224\n",
            "Epoch 303/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4737 - accuracy: 0.8274 - val_loss: 0.4844 - val_accuracy: 0.8213\n",
            "Epoch 304/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8277 - val_loss: 0.4852 - val_accuracy: 0.8186\n",
            "Epoch 305/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8289 - val_loss: 0.4844 - val_accuracy: 0.8194\n",
            "Epoch 306/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8277 - val_loss: 0.4853 - val_accuracy: 0.8191\n",
            "Epoch 307/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4721 - accuracy: 0.8287 - val_loss: 0.4862 - val_accuracy: 0.8169\n",
            "Epoch 308/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4721 - accuracy: 0.8298 - val_loss: 0.4848 - val_accuracy: 0.8197\n",
            "Epoch 309/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4718 - accuracy: 0.8282 - val_loss: 0.4852 - val_accuracy: 0.8222\n",
            "Epoch 310/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4736 - accuracy: 0.8284 - val_loss: 0.4923 - val_accuracy: 0.8062\n",
            "Epoch 311/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4747 - accuracy: 0.8248 - val_loss: 0.4866 - val_accuracy: 0.8169\n",
            "Epoch 312/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8285 - val_loss: 0.4849 - val_accuracy: 0.8169\n",
            "Epoch 313/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4718 - accuracy: 0.8290 - val_loss: 0.4852 - val_accuracy: 0.8208\n",
            "Epoch 314/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4729 - accuracy: 0.8266 - val_loss: 0.4852 - val_accuracy: 0.8219\n",
            "Epoch 315/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4715 - accuracy: 0.8291 - val_loss: 0.4853 - val_accuracy: 0.8156\n",
            "Epoch 316/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4708 - accuracy: 0.8289 - val_loss: 0.4845 - val_accuracy: 0.8178\n",
            "Epoch 317/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4730 - accuracy: 0.8278 - val_loss: 0.4897 - val_accuracy: 0.8180\n",
            "Epoch 318/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8285 - val_loss: 0.4855 - val_accuracy: 0.8216\n",
            "Epoch 319/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8280 - val_loss: 0.4876 - val_accuracy: 0.8197\n",
            "Epoch 320/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4720 - accuracy: 0.8286 - val_loss: 0.4890 - val_accuracy: 0.8125\n",
            "Epoch 321/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8280 - val_loss: 0.4841 - val_accuracy: 0.8202\n",
            "Epoch 322/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4714 - accuracy: 0.8293 - val_loss: 0.4864 - val_accuracy: 0.8211\n",
            "Epoch 323/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8284 - val_loss: 0.4853 - val_accuracy: 0.8213\n",
            "Epoch 324/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8281 - val_loss: 0.4844 - val_accuracy: 0.8233\n",
            "Epoch 325/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4715 - accuracy: 0.8295 - val_loss: 0.4853 - val_accuracy: 0.8219\n",
            "Epoch 326/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4711 - accuracy: 0.8297 - val_loss: 0.4843 - val_accuracy: 0.8224\n",
            "Epoch 327/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8284 - val_loss: 0.4914 - val_accuracy: 0.8191\n",
            "Epoch 328/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4720 - accuracy: 0.8288 - val_loss: 0.4867 - val_accuracy: 0.8222\n",
            "Epoch 329/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8274 - val_loss: 0.4887 - val_accuracy: 0.8191\n",
            "Epoch 330/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8271 - val_loss: 0.4850 - val_accuracy: 0.8202\n",
            "Epoch 331/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4719 - accuracy: 0.8294 - val_loss: 0.4845 - val_accuracy: 0.8241\n",
            "Epoch 332/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4735 - accuracy: 0.8268 - val_loss: 0.4872 - val_accuracy: 0.8158\n",
            "Epoch 333/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4724 - accuracy: 0.8275 - val_loss: 0.4856 - val_accuracy: 0.8180\n",
            "Epoch 334/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4717 - accuracy: 0.8287 - val_loss: 0.4877 - val_accuracy: 0.8169\n",
            "Epoch 335/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4720 - accuracy: 0.8294 - val_loss: 0.4861 - val_accuracy: 0.8175\n",
            "Epoch 336/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4723 - accuracy: 0.8281 - val_loss: 0.4863 - val_accuracy: 0.8194\n",
            "Epoch 337/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4718 - accuracy: 0.8278 - val_loss: 0.4871 - val_accuracy: 0.8227\n",
            "Epoch 338/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8275 - val_loss: 0.4900 - val_accuracy: 0.8189\n",
            "Epoch 339/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4735 - accuracy: 0.8283 - val_loss: 0.4895 - val_accuracy: 0.8131\n",
            "Epoch 340/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4726 - accuracy: 0.8283 - val_loss: 0.4858 - val_accuracy: 0.8167\n",
            "Epoch 341/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4714 - accuracy: 0.8284 - val_loss: 0.4854 - val_accuracy: 0.8211\n",
            "Epoch 342/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4710 - accuracy: 0.8301 - val_loss: 0.4872 - val_accuracy: 0.8186\n",
            "Epoch 343/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4727 - accuracy: 0.8279 - val_loss: 0.4846 - val_accuracy: 0.8213\n",
            "Epoch 344/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4719 - accuracy: 0.8283 - val_loss: 0.4849 - val_accuracy: 0.8249\n",
            "Epoch 345/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8286 - val_loss: 0.4919 - val_accuracy: 0.8065\n",
            "Epoch 346/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4730 - accuracy: 0.8274 - val_loss: 0.4845 - val_accuracy: 0.8241\n",
            "Epoch 347/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4713 - accuracy: 0.8287 - val_loss: 0.4854 - val_accuracy: 0.8180\n",
            "Epoch 348/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4729 - accuracy: 0.8277 - val_loss: 0.4856 - val_accuracy: 0.8197\n",
            "Epoch 349/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4724 - accuracy: 0.8271 - val_loss: 0.4841 - val_accuracy: 0.8205\n",
            "Epoch 350/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4721 - accuracy: 0.8286 - val_loss: 0.4872 - val_accuracy: 0.8150\n",
            "Epoch 351/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4723 - accuracy: 0.8288 - val_loss: 0.4881 - val_accuracy: 0.8224\n",
            "Epoch 352/850\n",
            "52/52 [==============================] - 1s 29ms/step - loss: 0.4718 - accuracy: 0.8296 - val_loss: 0.4852 - val_accuracy: 0.8224\n",
            "Epoch 353/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4727 - accuracy: 0.8284 - val_loss: 0.4896 - val_accuracy: 0.8142\n",
            "Epoch 354/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4732 - accuracy: 0.8267 - val_loss: 0.4859 - val_accuracy: 0.8205\n",
            "Epoch 355/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4715 - accuracy: 0.8294 - val_loss: 0.4849 - val_accuracy: 0.8211\n",
            "Epoch 356/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4734 - accuracy: 0.8258 - val_loss: 0.4840 - val_accuracy: 0.8235\n",
            "Epoch 357/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8289 - val_loss: 0.4876 - val_accuracy: 0.8200\n",
            "Epoch 358/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8283 - val_loss: 0.4877 - val_accuracy: 0.8189\n",
            "Epoch 359/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4726 - accuracy: 0.8273 - val_loss: 0.4843 - val_accuracy: 0.8211\n",
            "Epoch 360/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8288 - val_loss: 0.4852 - val_accuracy: 0.8244\n",
            "Epoch 361/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8288 - val_loss: 0.4854 - val_accuracy: 0.8191\n",
            "Epoch 362/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4741 - accuracy: 0.8279 - val_loss: 0.4869 - val_accuracy: 0.8180\n",
            "Epoch 363/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4736 - accuracy: 0.8268 - val_loss: 0.4844 - val_accuracy: 0.8224\n",
            "Epoch 364/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4719 - accuracy: 0.8290 - val_loss: 0.4862 - val_accuracy: 0.8169\n",
            "Epoch 365/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4721 - accuracy: 0.8280 - val_loss: 0.4864 - val_accuracy: 0.8169\n",
            "Epoch 366/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4748 - accuracy: 0.8254 - val_loss: 0.4932 - val_accuracy: 0.8216\n",
            "Epoch 367/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4725 - accuracy: 0.8279 - val_loss: 0.4848 - val_accuracy: 0.8211\n",
            "Epoch 368/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4715 - accuracy: 0.8281 - val_loss: 0.4928 - val_accuracy: 0.8186\n",
            "Epoch 369/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8282 - val_loss: 0.4865 - val_accuracy: 0.8227\n",
            "Epoch 370/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8292 - val_loss: 0.4856 - val_accuracy: 0.8167\n",
            "Epoch 371/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4711 - accuracy: 0.8294 - val_loss: 0.4854 - val_accuracy: 0.8255\n",
            "Epoch 372/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4730 - accuracy: 0.8274 - val_loss: 0.4856 - val_accuracy: 0.8222\n",
            "Epoch 373/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4708 - accuracy: 0.8299 - val_loss: 0.4843 - val_accuracy: 0.8213\n",
            "Epoch 374/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4718 - accuracy: 0.8302 - val_loss: 0.4844 - val_accuracy: 0.8197\n",
            "Epoch 375/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4721 - accuracy: 0.8283 - val_loss: 0.4847 - val_accuracy: 0.8189\n",
            "Epoch 376/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8279 - val_loss: 0.4860 - val_accuracy: 0.8213\n",
            "Epoch 377/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4716 - accuracy: 0.8290 - val_loss: 0.4849 - val_accuracy: 0.8213\n",
            "Epoch 378/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4713 - accuracy: 0.8297 - val_loss: 0.4884 - val_accuracy: 0.8153\n",
            "Epoch 379/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4729 - accuracy: 0.8272 - val_loss: 0.4874 - val_accuracy: 0.8164\n",
            "Epoch 380/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4719 - accuracy: 0.8279 - val_loss: 0.4886 - val_accuracy: 0.8208\n",
            "Epoch 381/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4713 - accuracy: 0.8283 - val_loss: 0.4843 - val_accuracy: 0.8238\n",
            "Epoch 382/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4720 - accuracy: 0.8284 - val_loss: 0.4859 - val_accuracy: 0.8194\n",
            "Epoch 383/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4717 - accuracy: 0.8294 - val_loss: 0.4857 - val_accuracy: 0.8202\n",
            "Epoch 384/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4724 - accuracy: 0.8273 - val_loss: 0.4840 - val_accuracy: 0.8213\n",
            "Epoch 385/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4722 - accuracy: 0.8284 - val_loss: 0.4866 - val_accuracy: 0.8241\n",
            "Epoch 386/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4719 - accuracy: 0.8287 - val_loss: 0.4847 - val_accuracy: 0.8216\n",
            "Epoch 387/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8285 - val_loss: 0.4847 - val_accuracy: 0.8189\n",
            "Epoch 388/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4722 - accuracy: 0.8293 - val_loss: 0.4846 - val_accuracy: 0.8233\n",
            "Epoch 389/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4719 - accuracy: 0.8293 - val_loss: 0.4853 - val_accuracy: 0.8197\n",
            "Epoch 390/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4719 - accuracy: 0.8293 - val_loss: 0.4868 - val_accuracy: 0.8258\n",
            "Epoch 391/850\n",
            "52/52 [==============================] - 1s 13ms/step - loss: 0.4728 - accuracy: 0.8290 - val_loss: 0.4857 - val_accuracy: 0.8249\n",
            "Epoch 392/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.8293 - val_loss: 0.4845 - val_accuracy: 0.8216\n",
            "Epoch 393/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4713 - accuracy: 0.8279 - val_loss: 0.4858 - val_accuracy: 0.8249\n",
            "Epoch 394/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4710 - accuracy: 0.8290 - val_loss: 0.4946 - val_accuracy: 0.8200\n",
            "Epoch 395/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8286 - val_loss: 0.4903 - val_accuracy: 0.8194\n",
            "Epoch 396/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4733 - accuracy: 0.8269 - val_loss: 0.4857 - val_accuracy: 0.8153\n",
            "Epoch 397/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4718 - accuracy: 0.8286 - val_loss: 0.4867 - val_accuracy: 0.8183\n",
            "Epoch 398/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4730 - accuracy: 0.8285 - val_loss: 0.4875 - val_accuracy: 0.8125\n",
            "Epoch 399/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.4718 - accuracy: 0.8290 - val_loss: 0.4843 - val_accuracy: 0.8205\n",
            "Epoch 400/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4711 - accuracy: 0.8286 - val_loss: 0.4847 - val_accuracy: 0.8213\n",
            "Epoch 401/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4712 - accuracy: 0.8297 - val_loss: 0.4852 - val_accuracy: 0.8213\n",
            "Epoch 402/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4734 - accuracy: 0.8253 - val_loss: 0.4908 - val_accuracy: 0.8186\n",
            "Epoch 403/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.4726 - accuracy: 0.8273 - val_loss: 0.4855 - val_accuracy: 0.8172\n",
            "Epoch 404/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4735 - accuracy: 0.8264 - val_loss: 0.4842 - val_accuracy: 0.8208\n",
            "Epoch 405/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8268 - val_loss: 0.4895 - val_accuracy: 0.8131\n",
            "Epoch 406/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8289 - val_loss: 0.4843 - val_accuracy: 0.8208\n",
            "Epoch 407/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4720 - accuracy: 0.8277 - val_loss: 0.4846 - val_accuracy: 0.8246\n",
            "Epoch 408/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4711 - accuracy: 0.8299 - val_loss: 0.4858 - val_accuracy: 0.8219\n",
            "Epoch 409/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4748 - accuracy: 0.8261 - val_loss: 0.4848 - val_accuracy: 0.8194\n",
            "Epoch 410/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4715 - accuracy: 0.8294 - val_loss: 0.4862 - val_accuracy: 0.8241\n",
            "Epoch 411/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4715 - accuracy: 0.8286 - val_loss: 0.4881 - val_accuracy: 0.8164\n",
            "Epoch 412/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4743 - accuracy: 0.8270 - val_loss: 0.4910 - val_accuracy: 0.8178\n",
            "Epoch 413/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.8281 - val_loss: 0.4839 - val_accuracy: 0.8202\n",
            "Epoch 414/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4719 - accuracy: 0.8282 - val_loss: 0.4846 - val_accuracy: 0.8219\n",
            "Epoch 415/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8285 - val_loss: 0.4871 - val_accuracy: 0.8224\n",
            "Epoch 416/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8290 - val_loss: 0.4845 - val_accuracy: 0.8235\n",
            "Epoch 417/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4724 - accuracy: 0.8290 - val_loss: 0.4855 - val_accuracy: 0.8180\n",
            "Epoch 418/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4727 - accuracy: 0.8292 - val_loss: 0.4886 - val_accuracy: 0.8200\n",
            "Epoch 419/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4719 - accuracy: 0.8291 - val_loss: 0.4844 - val_accuracy: 0.8202\n",
            "Epoch 420/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4713 - accuracy: 0.8297 - val_loss: 0.4852 - val_accuracy: 0.8216\n",
            "Epoch 421/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8291 - val_loss: 0.4842 - val_accuracy: 0.8235\n",
            "Epoch 422/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8300 - val_loss: 0.4891 - val_accuracy: 0.8213\n",
            "Epoch 423/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4728 - accuracy: 0.8288 - val_loss: 0.4874 - val_accuracy: 0.8183\n",
            "Epoch 424/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4724 - accuracy: 0.8285 - val_loss: 0.4847 - val_accuracy: 0.8147\n",
            "Epoch 425/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4721 - accuracy: 0.8282 - val_loss: 0.4848 - val_accuracy: 0.8227\n",
            "Epoch 426/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4742 - accuracy: 0.8261 - val_loss: 0.4855 - val_accuracy: 0.8224\n",
            "Epoch 427/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4729 - accuracy: 0.8275 - val_loss: 0.4877 - val_accuracy: 0.8197\n",
            "Epoch 428/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8279 - val_loss: 0.4865 - val_accuracy: 0.8167\n",
            "Epoch 429/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4735 - accuracy: 0.8266 - val_loss: 0.4844 - val_accuracy: 0.8202\n",
            "Epoch 430/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8310 - val_loss: 0.4842 - val_accuracy: 0.8186\n",
            "Epoch 431/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4712 - accuracy: 0.8293 - val_loss: 0.4864 - val_accuracy: 0.8202\n",
            "Epoch 432/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4730 - accuracy: 0.8280 - val_loss: 0.4854 - val_accuracy: 0.8213\n",
            "Epoch 433/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4722 - accuracy: 0.8276 - val_loss: 0.4843 - val_accuracy: 0.8216\n",
            "Epoch 434/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4716 - accuracy: 0.8295 - val_loss: 0.4843 - val_accuracy: 0.8219\n",
            "Epoch 435/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4736 - accuracy: 0.8263 - val_loss: 0.4849 - val_accuracy: 0.8230\n",
            "Epoch 436/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4713 - accuracy: 0.8295 - val_loss: 0.4873 - val_accuracy: 0.8178\n",
            "Epoch 437/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4722 - accuracy: 0.8292 - val_loss: 0.4865 - val_accuracy: 0.8200\n",
            "Epoch 438/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4735 - accuracy: 0.8282 - val_loss: 0.4876 - val_accuracy: 0.8186\n",
            "Epoch 439/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8294 - val_loss: 0.4840 - val_accuracy: 0.8224\n",
            "Epoch 440/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4722 - accuracy: 0.8295 - val_loss: 0.4859 - val_accuracy: 0.8156\n",
            "Epoch 441/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4735 - accuracy: 0.8284 - val_loss: 0.4913 - val_accuracy: 0.8037\n",
            "Epoch 442/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4731 - accuracy: 0.8276 - val_loss: 0.4878 - val_accuracy: 0.8200\n",
            "Epoch 443/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4712 - accuracy: 0.8287 - val_loss: 0.4889 - val_accuracy: 0.8186\n",
            "Epoch 444/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4720 - accuracy: 0.8289 - val_loss: 0.4871 - val_accuracy: 0.8183\n",
            "Epoch 445/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8299 - val_loss: 0.4856 - val_accuracy: 0.8158\n",
            "Epoch 446/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4710 - accuracy: 0.8291 - val_loss: 0.4835 - val_accuracy: 0.8233\n",
            "Epoch 447/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8296 - val_loss: 0.4874 - val_accuracy: 0.8200\n",
            "Epoch 448/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4727 - accuracy: 0.8285 - val_loss: 0.4841 - val_accuracy: 0.8213\n",
            "Epoch 449/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4709 - accuracy: 0.8281 - val_loss: 0.4875 - val_accuracy: 0.8211\n",
            "Epoch 450/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8285 - val_loss: 0.4857 - val_accuracy: 0.8169\n",
            "Epoch 451/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4723 - accuracy: 0.8283 - val_loss: 0.4872 - val_accuracy: 0.8180\n",
            "Epoch 452/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4733 - accuracy: 0.8276 - val_loss: 0.4875 - val_accuracy: 0.8213\n",
            "Epoch 453/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4714 - accuracy: 0.8298 - val_loss: 0.4840 - val_accuracy: 0.8200\n",
            "Epoch 454/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4714 - accuracy: 0.8305 - val_loss: 0.4845 - val_accuracy: 0.8191\n",
            "Epoch 455/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4716 - accuracy: 0.8290 - val_loss: 0.4839 - val_accuracy: 0.8202\n",
            "Epoch 456/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8286 - val_loss: 0.4859 - val_accuracy: 0.8202\n",
            "Epoch 457/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4728 - accuracy: 0.8290 - val_loss: 0.4898 - val_accuracy: 0.8211\n",
            "Epoch 458/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8284 - val_loss: 0.4867 - val_accuracy: 0.8175\n",
            "Epoch 459/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8271 - val_loss: 0.4896 - val_accuracy: 0.8169\n",
            "Epoch 460/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.8286 - val_loss: 0.4865 - val_accuracy: 0.8222\n",
            "Epoch 461/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4726 - accuracy: 0.8269 - val_loss: 0.4867 - val_accuracy: 0.8175\n",
            "Epoch 462/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4725 - accuracy: 0.8288 - val_loss: 0.4852 - val_accuracy: 0.8180\n",
            "Epoch 463/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4712 - accuracy: 0.8291 - val_loss: 0.4877 - val_accuracy: 0.8197\n",
            "Epoch 464/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4719 - accuracy: 0.8298 - val_loss: 0.4853 - val_accuracy: 0.8180\n",
            "Epoch 465/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8283 - val_loss: 0.4861 - val_accuracy: 0.8191\n",
            "Epoch 466/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4727 - accuracy: 0.8274 - val_loss: 0.4844 - val_accuracy: 0.8180\n",
            "Epoch 467/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4716 - accuracy: 0.8287 - val_loss: 0.4943 - val_accuracy: 0.8178\n",
            "Epoch 468/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4734 - accuracy: 0.8272 - val_loss: 0.4886 - val_accuracy: 0.8180\n",
            "Epoch 469/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4716 - accuracy: 0.8279 - val_loss: 0.4863 - val_accuracy: 0.8211\n",
            "Epoch 470/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4716 - accuracy: 0.8287 - val_loss: 0.4837 - val_accuracy: 0.8200\n",
            "Epoch 471/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4713 - accuracy: 0.8304 - val_loss: 0.4903 - val_accuracy: 0.8178\n",
            "Epoch 472/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8297 - val_loss: 0.4846 - val_accuracy: 0.8222\n",
            "Epoch 473/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4720 - accuracy: 0.8284 - val_loss: 0.4835 - val_accuracy: 0.8202\n",
            "Epoch 474/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4727 - accuracy: 0.8290 - val_loss: 0.4836 - val_accuracy: 0.8216\n",
            "Epoch 475/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4720 - accuracy: 0.8282 - val_loss: 0.4840 - val_accuracy: 0.8227\n",
            "Epoch 476/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8302 - val_loss: 0.4860 - val_accuracy: 0.8213\n",
            "Epoch 477/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8295 - val_loss: 0.4847 - val_accuracy: 0.8227\n",
            "Epoch 478/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4714 - accuracy: 0.8281 - val_loss: 0.4843 - val_accuracy: 0.8205\n",
            "Epoch 479/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4712 - accuracy: 0.8306 - val_loss: 0.4844 - val_accuracy: 0.8213\n",
            "Epoch 480/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4737 - accuracy: 0.8285 - val_loss: 0.4925 - val_accuracy: 0.8142\n",
            "Epoch 481/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4723 - accuracy: 0.8284 - val_loss: 0.4877 - val_accuracy: 0.8197\n",
            "Epoch 482/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8300 - val_loss: 0.4848 - val_accuracy: 0.8219\n",
            "Epoch 483/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4709 - accuracy: 0.8298 - val_loss: 0.4920 - val_accuracy: 0.8189\n",
            "Epoch 484/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8297 - val_loss: 0.4861 - val_accuracy: 0.8222\n",
            "Epoch 485/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4722 - accuracy: 0.8297 - val_loss: 0.4840 - val_accuracy: 0.8216\n",
            "Epoch 486/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4721 - accuracy: 0.8292 - val_loss: 0.4852 - val_accuracy: 0.8178\n",
            "Epoch 487/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4732 - accuracy: 0.8287 - val_loss: 0.4856 - val_accuracy: 0.8202\n",
            "Epoch 488/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4712 - accuracy: 0.8303 - val_loss: 0.4848 - val_accuracy: 0.8194\n",
            "Epoch 489/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4720 - accuracy: 0.8278 - val_loss: 0.4863 - val_accuracy: 0.8211\n",
            "Epoch 490/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8296 - val_loss: 0.4853 - val_accuracy: 0.8222\n",
            "Epoch 491/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8272 - val_loss: 0.4836 - val_accuracy: 0.8241\n",
            "Epoch 492/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4716 - accuracy: 0.8288 - val_loss: 0.4858 - val_accuracy: 0.8180\n",
            "Epoch 493/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4734 - accuracy: 0.8292 - val_loss: 0.4879 - val_accuracy: 0.8178\n",
            "Epoch 494/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4721 - accuracy: 0.8277 - val_loss: 0.4840 - val_accuracy: 0.8183\n",
            "Epoch 495/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4728 - accuracy: 0.8270 - val_loss: 0.4867 - val_accuracy: 0.8175\n",
            "Epoch 496/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8296 - val_loss: 0.4890 - val_accuracy: 0.8222\n",
            "Epoch 497/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8302 - val_loss: 0.4843 - val_accuracy: 0.8202\n",
            "Epoch 498/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4730 - accuracy: 0.8290 - val_loss: 0.4873 - val_accuracy: 0.8153\n",
            "Epoch 499/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4715 - accuracy: 0.8295 - val_loss: 0.4854 - val_accuracy: 0.8205\n",
            "Epoch 500/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4716 - accuracy: 0.8301 - val_loss: 0.4856 - val_accuracy: 0.8197\n",
            "Epoch 501/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4717 - accuracy: 0.8278 - val_loss: 0.4874 - val_accuracy: 0.8202\n",
            "Epoch 502/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4709 - accuracy: 0.8299 - val_loss: 0.4853 - val_accuracy: 0.8213\n",
            "Epoch 503/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4713 - accuracy: 0.8302 - val_loss: 0.4849 - val_accuracy: 0.8186\n",
            "Epoch 504/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4717 - accuracy: 0.8294 - val_loss: 0.4841 - val_accuracy: 0.8219\n",
            "Epoch 505/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4724 - accuracy: 0.8294 - val_loss: 0.4852 - val_accuracy: 0.8235\n",
            "Epoch 506/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4714 - accuracy: 0.8296 - val_loss: 0.4845 - val_accuracy: 0.8208\n",
            "Epoch 507/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4728 - accuracy: 0.8274 - val_loss: 0.4844 - val_accuracy: 0.8238\n",
            "Epoch 508/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4711 - accuracy: 0.8297 - val_loss: 0.4844 - val_accuracy: 0.8216\n",
            "Epoch 509/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8302 - val_loss: 0.4864 - val_accuracy: 0.8189\n",
            "Epoch 510/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4737 - accuracy: 0.8282 - val_loss: 0.4880 - val_accuracy: 0.8197\n",
            "Epoch 511/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8297 - val_loss: 0.4846 - val_accuracy: 0.8222\n",
            "Epoch 512/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4709 - accuracy: 0.8289 - val_loss: 0.4847 - val_accuracy: 0.8238\n",
            "Epoch 513/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8286 - val_loss: 0.4843 - val_accuracy: 0.8200\n",
            "Epoch 514/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4705 - accuracy: 0.8304 - val_loss: 0.4853 - val_accuracy: 0.8202\n",
            "Epoch 515/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4710 - accuracy: 0.8292 - val_loss: 0.4846 - val_accuracy: 0.8230\n",
            "Epoch 516/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4713 - accuracy: 0.8289 - val_loss: 0.4849 - val_accuracy: 0.8230\n",
            "Epoch 517/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8286 - val_loss: 0.4849 - val_accuracy: 0.8216\n",
            "Epoch 518/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8289 - val_loss: 0.4875 - val_accuracy: 0.8197\n",
            "Epoch 519/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4714 - accuracy: 0.8282 - val_loss: 0.4853 - val_accuracy: 0.8156\n",
            "Epoch 520/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4719 - accuracy: 0.8287 - val_loss: 0.4865 - val_accuracy: 0.8233\n",
            "Epoch 521/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4726 - accuracy: 0.8292 - val_loss: 0.4888 - val_accuracy: 0.8133\n",
            "Epoch 522/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4732 - accuracy: 0.8285 - val_loss: 0.4979 - val_accuracy: 0.8161\n",
            "Epoch 523/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4728 - accuracy: 0.8279 - val_loss: 0.4856 - val_accuracy: 0.8197\n",
            "Epoch 524/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4723 - accuracy: 0.8291 - val_loss: 0.4839 - val_accuracy: 0.8219\n",
            "Epoch 525/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8291 - val_loss: 0.4853 - val_accuracy: 0.8252\n",
            "Epoch 526/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4718 - accuracy: 0.8281 - val_loss: 0.4853 - val_accuracy: 0.8175\n",
            "Epoch 527/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8294 - val_loss: 0.4837 - val_accuracy: 0.8213\n",
            "Epoch 528/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4710 - accuracy: 0.8298 - val_loss: 0.4845 - val_accuracy: 0.8183\n",
            "Epoch 529/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8298 - val_loss: 0.4843 - val_accuracy: 0.8219\n",
            "Epoch 530/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4713 - accuracy: 0.8294 - val_loss: 0.4849 - val_accuracy: 0.8213\n",
            "Epoch 531/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4720 - accuracy: 0.8285 - val_loss: 0.4852 - val_accuracy: 0.8216\n",
            "Epoch 532/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4722 - accuracy: 0.8296 - val_loss: 0.4879 - val_accuracy: 0.8158\n",
            "Epoch 533/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4739 - accuracy: 0.8283 - val_loss: 0.4855 - val_accuracy: 0.8224\n",
            "Epoch 534/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4727 - accuracy: 0.8277 - val_loss: 0.4848 - val_accuracy: 0.8197\n",
            "Epoch 535/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4716 - accuracy: 0.8275 - val_loss: 0.4864 - val_accuracy: 0.8219\n",
            "Epoch 536/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4719 - accuracy: 0.8286 - val_loss: 0.4843 - val_accuracy: 0.8233\n",
            "Epoch 537/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4721 - accuracy: 0.8298 - val_loss: 0.4853 - val_accuracy: 0.8183\n",
            "Epoch 538/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4722 - accuracy: 0.8273 - val_loss: 0.4851 - val_accuracy: 0.8186\n",
            "Epoch 539/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4719 - accuracy: 0.8272 - val_loss: 0.4897 - val_accuracy: 0.8076\n",
            "Epoch 540/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4725 - accuracy: 0.8283 - val_loss: 0.4855 - val_accuracy: 0.8167\n",
            "Epoch 541/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4722 - accuracy: 0.8287 - val_loss: 0.4844 - val_accuracy: 0.8186\n",
            "Epoch 542/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8293 - val_loss: 0.4851 - val_accuracy: 0.8211\n",
            "Epoch 543/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4716 - accuracy: 0.8290 - val_loss: 0.4868 - val_accuracy: 0.8197\n",
            "Epoch 544/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4714 - accuracy: 0.8293 - val_loss: 0.4891 - val_accuracy: 0.8178\n",
            "Epoch 545/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.8278 - val_loss: 0.4852 - val_accuracy: 0.8216\n",
            "Epoch 546/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8289 - val_loss: 0.4863 - val_accuracy: 0.8183\n",
            "Epoch 547/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8295 - val_loss: 0.4841 - val_accuracy: 0.8205\n",
            "Epoch 548/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4740 - accuracy: 0.8275 - val_loss: 0.4855 - val_accuracy: 0.8194\n",
            "Epoch 549/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4733 - accuracy: 0.8279 - val_loss: 0.4877 - val_accuracy: 0.8189\n",
            "Epoch 550/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8290 - val_loss: 0.4859 - val_accuracy: 0.8186\n",
            "Epoch 551/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8305 - val_loss: 0.4858 - val_accuracy: 0.8175\n",
            "Epoch 552/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8296 - val_loss: 0.4848 - val_accuracy: 0.8197\n",
            "Epoch 553/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4724 - accuracy: 0.8294 - val_loss: 0.4842 - val_accuracy: 0.8222\n",
            "Epoch 554/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4711 - accuracy: 0.8291 - val_loss: 0.4844 - val_accuracy: 0.8216\n",
            "Epoch 555/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4712 - accuracy: 0.8298 - val_loss: 0.4853 - val_accuracy: 0.8235\n",
            "Epoch 556/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4711 - accuracy: 0.8302 - val_loss: 0.4846 - val_accuracy: 0.8208\n",
            "Epoch 557/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4713 - accuracy: 0.8295 - val_loss: 0.4846 - val_accuracy: 0.8222\n",
            "Epoch 558/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4710 - accuracy: 0.8296 - val_loss: 0.4859 - val_accuracy: 0.8208\n",
            "Epoch 559/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4720 - accuracy: 0.8296 - val_loss: 0.4839 - val_accuracy: 0.8183\n",
            "Epoch 560/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4713 - accuracy: 0.8285 - val_loss: 0.4864 - val_accuracy: 0.8205\n",
            "Epoch 561/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8306 - val_loss: 0.4851 - val_accuracy: 0.8238\n",
            "Epoch 562/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8291 - val_loss: 0.4846 - val_accuracy: 0.8219\n",
            "Epoch 563/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8296 - val_loss: 0.4846 - val_accuracy: 0.8194\n",
            "Epoch 564/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4713 - accuracy: 0.8293 - val_loss: 0.4914 - val_accuracy: 0.8175\n",
            "Epoch 565/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4740 - accuracy: 0.8261 - val_loss: 0.4860 - val_accuracy: 0.8178\n",
            "Epoch 566/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8292 - val_loss: 0.4849 - val_accuracy: 0.8180\n",
            "Epoch 567/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8285 - val_loss: 0.4844 - val_accuracy: 0.8208\n",
            "Epoch 568/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8287 - val_loss: 0.4857 - val_accuracy: 0.8172\n",
            "Epoch 569/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4727 - accuracy: 0.8282 - val_loss: 0.4861 - val_accuracy: 0.8156\n",
            "Epoch 570/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4736 - accuracy: 0.8291 - val_loss: 0.4838 - val_accuracy: 0.8211\n",
            "Epoch 571/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4718 - accuracy: 0.8299 - val_loss: 0.4838 - val_accuracy: 0.8216\n",
            "Epoch 572/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4715 - accuracy: 0.8294 - val_loss: 0.4854 - val_accuracy: 0.8213\n",
            "Epoch 573/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4710 - accuracy: 0.8303 - val_loss: 0.4854 - val_accuracy: 0.8216\n",
            "Epoch 574/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4711 - accuracy: 0.8313 - val_loss: 0.4847 - val_accuracy: 0.8219\n",
            "Epoch 575/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4707 - accuracy: 0.8306 - val_loss: 0.4842 - val_accuracy: 0.8200\n",
            "Epoch 576/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4709 - accuracy: 0.8301 - val_loss: 0.4842 - val_accuracy: 0.8189\n",
            "Epoch 577/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4710 - accuracy: 0.8297 - val_loss: 0.4842 - val_accuracy: 0.8216\n",
            "Epoch 578/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4726 - accuracy: 0.8297 - val_loss: 0.4888 - val_accuracy: 0.8128\n",
            "Epoch 579/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8293 - val_loss: 0.4842 - val_accuracy: 0.8216\n",
            "Epoch 580/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8287 - val_loss: 0.4869 - val_accuracy: 0.8202\n",
            "Epoch 581/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4724 - accuracy: 0.8284 - val_loss: 0.4849 - val_accuracy: 0.8197\n",
            "Epoch 582/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4712 - accuracy: 0.8294 - val_loss: 0.4887 - val_accuracy: 0.8142\n",
            "Epoch 583/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8303 - val_loss: 0.4896 - val_accuracy: 0.8172\n",
            "Epoch 584/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8297 - val_loss: 0.4844 - val_accuracy: 0.8213\n",
            "Epoch 585/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8279 - val_loss: 0.4859 - val_accuracy: 0.8178\n",
            "Epoch 586/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8296 - val_loss: 0.4838 - val_accuracy: 0.8180\n",
            "Epoch 587/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4718 - accuracy: 0.8307 - val_loss: 0.4852 - val_accuracy: 0.8164\n",
            "Epoch 588/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4737 - accuracy: 0.8290 - val_loss: 0.4888 - val_accuracy: 0.8156\n",
            "Epoch 589/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4709 - accuracy: 0.8297 - val_loss: 0.4848 - val_accuracy: 0.8244\n",
            "Epoch 590/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4712 - accuracy: 0.8307 - val_loss: 0.4896 - val_accuracy: 0.8233\n",
            "Epoch 591/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4716 - accuracy: 0.8290 - val_loss: 0.4871 - val_accuracy: 0.8197\n",
            "Epoch 592/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4731 - accuracy: 0.8286 - val_loss: 0.4848 - val_accuracy: 0.8191\n",
            "Epoch 593/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8293 - val_loss: 0.4852 - val_accuracy: 0.8235\n",
            "Epoch 594/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4705 - accuracy: 0.8297 - val_loss: 0.4838 - val_accuracy: 0.8213\n",
            "Epoch 595/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4742 - accuracy: 0.8266 - val_loss: 0.4936 - val_accuracy: 0.8189\n",
            "Epoch 596/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4741 - accuracy: 0.8274 - val_loss: 0.4848 - val_accuracy: 0.8197\n",
            "Epoch 597/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8291 - val_loss: 0.4887 - val_accuracy: 0.8200\n",
            "Epoch 598/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4712 - accuracy: 0.8309 - val_loss: 0.4859 - val_accuracy: 0.8213\n",
            "Epoch 599/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8292 - val_loss: 0.4844 - val_accuracy: 0.8208\n",
            "Epoch 600/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4722 - accuracy: 0.8282 - val_loss: 0.4841 - val_accuracy: 0.8216\n",
            "Epoch 601/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8290 - val_loss: 0.4859 - val_accuracy: 0.8244\n",
            "Epoch 602/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4713 - accuracy: 0.8291 - val_loss: 0.4891 - val_accuracy: 0.8194\n",
            "Epoch 603/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4712 - accuracy: 0.8309 - val_loss: 0.4862 - val_accuracy: 0.8178\n",
            "Epoch 604/850\n",
            "52/52 [==============================] - 1s 19ms/step - loss: 0.4714 - accuracy: 0.8299 - val_loss: 0.4847 - val_accuracy: 0.8180\n",
            "Epoch 605/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4722 - accuracy: 0.8290 - val_loss: 0.4915 - val_accuracy: 0.8189\n",
            "Epoch 606/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4718 - accuracy: 0.8285 - val_loss: 0.4854 - val_accuracy: 0.8186\n",
            "Epoch 607/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4709 - accuracy: 0.8299 - val_loss: 0.4840 - val_accuracy: 0.8205\n",
            "Epoch 608/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4715 - accuracy: 0.8297 - val_loss: 0.4854 - val_accuracy: 0.8230\n",
            "Epoch 609/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4732 - accuracy: 0.8291 - val_loss: 0.4841 - val_accuracy: 0.8244\n",
            "Epoch 610/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4715 - accuracy: 0.8283 - val_loss: 0.4855 - val_accuracy: 0.8200\n",
            "Epoch 611/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4723 - accuracy: 0.8284 - val_loss: 0.4881 - val_accuracy: 0.8180\n",
            "Epoch 612/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8299 - val_loss: 0.4848 - val_accuracy: 0.8208\n",
            "Epoch 613/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4732 - accuracy: 0.8280 - val_loss: 0.4965 - val_accuracy: 0.8167\n",
            "Epoch 614/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4725 - accuracy: 0.8275 - val_loss: 0.4850 - val_accuracy: 0.8216\n",
            "Epoch 615/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4722 - accuracy: 0.8291 - val_loss: 0.4845 - val_accuracy: 0.8208\n",
            "Epoch 616/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8290 - val_loss: 0.4844 - val_accuracy: 0.8216\n",
            "Epoch 617/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4712 - accuracy: 0.8287 - val_loss: 0.4844 - val_accuracy: 0.8169\n",
            "Epoch 618/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4705 - accuracy: 0.8312 - val_loss: 0.4873 - val_accuracy: 0.8197\n",
            "Epoch 619/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4726 - accuracy: 0.8287 - val_loss: 0.4850 - val_accuracy: 0.8208\n",
            "Epoch 620/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4712 - accuracy: 0.8304 - val_loss: 0.4837 - val_accuracy: 0.8233\n",
            "Epoch 621/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4737 - accuracy: 0.8278 - val_loss: 0.4843 - val_accuracy: 0.8202\n",
            "Epoch 622/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4721 - accuracy: 0.8297 - val_loss: 0.4840 - val_accuracy: 0.8233\n",
            "Epoch 623/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4728 - accuracy: 0.8275 - val_loss: 0.4884 - val_accuracy: 0.8191\n",
            "Epoch 624/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4749 - accuracy: 0.8266 - val_loss: 0.4859 - val_accuracy: 0.8161\n",
            "Epoch 625/850\n",
            "52/52 [==============================] - 1s 21ms/step - loss: 0.4707 - accuracy: 0.8303 - val_loss: 0.4872 - val_accuracy: 0.8180\n",
            "Epoch 626/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4712 - accuracy: 0.8305 - val_loss: 0.4847 - val_accuracy: 0.8189\n",
            "Epoch 627/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4715 - accuracy: 0.8285 - val_loss: 0.4872 - val_accuracy: 0.8164\n",
            "Epoch 628/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4718 - accuracy: 0.8287 - val_loss: 0.4843 - val_accuracy: 0.8191\n",
            "Epoch 629/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4711 - accuracy: 0.8305 - val_loss: 0.4847 - val_accuracy: 0.8222\n",
            "Epoch 630/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4710 - accuracy: 0.8301 - val_loss: 0.4866 - val_accuracy: 0.8164\n",
            "Epoch 631/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4732 - accuracy: 0.8283 - val_loss: 0.4846 - val_accuracy: 0.8194\n",
            "Epoch 632/850\n",
            "52/52 [==============================] - 1s 14ms/step - loss: 0.4721 - accuracy: 0.8295 - val_loss: 0.4847 - val_accuracy: 0.8208\n",
            "Epoch 633/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8297 - val_loss: 0.4937 - val_accuracy: 0.8202\n",
            "Epoch 634/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4721 - accuracy: 0.8284 - val_loss: 0.4849 - val_accuracy: 0.8164\n",
            "Epoch 635/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4739 - accuracy: 0.8267 - val_loss: 0.4857 - val_accuracy: 0.8205\n",
            "Epoch 636/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4717 - accuracy: 0.8293 - val_loss: 0.4848 - val_accuracy: 0.8230\n",
            "Epoch 637/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4714 - accuracy: 0.8291 - val_loss: 0.4850 - val_accuracy: 0.8178\n",
            "Epoch 638/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4722 - accuracy: 0.8285 - val_loss: 0.4842 - val_accuracy: 0.8172\n",
            "Epoch 639/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4712 - accuracy: 0.8314 - val_loss: 0.4845 - val_accuracy: 0.8222\n",
            "Epoch 640/850\n",
            "52/52 [==============================] - 1s 24ms/step - loss: 0.4711 - accuracy: 0.8296 - val_loss: 0.4891 - val_accuracy: 0.8211\n",
            "Epoch 641/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4711 - accuracy: 0.8304 - val_loss: 0.4857 - val_accuracy: 0.8167\n",
            "Epoch 642/850\n",
            "52/52 [==============================] - 1s 20ms/step - loss: 0.4709 - accuracy: 0.8300 - val_loss: 0.4848 - val_accuracy: 0.8191\n",
            "Epoch 643/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8310 - val_loss: 0.4858 - val_accuracy: 0.8183\n",
            "Epoch 644/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4711 - accuracy: 0.8299 - val_loss: 0.4851 - val_accuracy: 0.8164\n",
            "Epoch 645/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4724 - accuracy: 0.8283 - val_loss: 0.4866 - val_accuracy: 0.8205\n",
            "Epoch 646/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4710 - accuracy: 0.8312 - val_loss: 0.4850 - val_accuracy: 0.8200\n",
            "Epoch 647/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4712 - accuracy: 0.8304 - val_loss: 0.4856 - val_accuracy: 0.8238\n",
            "Epoch 648/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4705 - accuracy: 0.8315 - val_loss: 0.4846 - val_accuracy: 0.8213\n",
            "Epoch 649/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8302 - val_loss: 0.4879 - val_accuracy: 0.8175\n",
            "Epoch 650/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4721 - accuracy: 0.8290 - val_loss: 0.4865 - val_accuracy: 0.8139\n",
            "Epoch 651/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4721 - accuracy: 0.8287 - val_loss: 0.4926 - val_accuracy: 0.8189\n",
            "Epoch 652/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4719 - accuracy: 0.8293 - val_loss: 0.4838 - val_accuracy: 0.8205\n",
            "Epoch 653/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8303 - val_loss: 0.4864 - val_accuracy: 0.8224\n",
            "Epoch 654/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4711 - accuracy: 0.8304 - val_loss: 0.4841 - val_accuracy: 0.8211\n",
            "Epoch 655/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4715 - accuracy: 0.8299 - val_loss: 0.4847 - val_accuracy: 0.8235\n",
            "Epoch 656/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4720 - accuracy: 0.8280 - val_loss: 0.4841 - val_accuracy: 0.8202\n",
            "Epoch 657/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4712 - accuracy: 0.8284 - val_loss: 0.4867 - val_accuracy: 0.8208\n",
            "Epoch 658/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4713 - accuracy: 0.8294 - val_loss: 0.4866 - val_accuracy: 0.8189\n",
            "Epoch 659/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4708 - accuracy: 0.8298 - val_loss: 0.4849 - val_accuracy: 0.8238\n",
            "Epoch 660/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4721 - accuracy: 0.8297 - val_loss: 0.4846 - val_accuracy: 0.8197\n",
            "Epoch 661/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4708 - accuracy: 0.8307 - val_loss: 0.4846 - val_accuracy: 0.8230\n",
            "Epoch 662/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4732 - accuracy: 0.8268 - val_loss: 0.4888 - val_accuracy: 0.8189\n",
            "Epoch 663/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4713 - accuracy: 0.8285 - val_loss: 0.4865 - val_accuracy: 0.8202\n",
            "Epoch 664/850\n",
            "52/52 [==============================] - 1s 16ms/step - loss: 0.4710 - accuracy: 0.8308 - val_loss: 0.4878 - val_accuracy: 0.8189\n",
            "Epoch 665/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4731 - accuracy: 0.8276 - val_loss: 0.4914 - val_accuracy: 0.8186\n",
            "Epoch 666/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4734 - accuracy: 0.8268 - val_loss: 0.4872 - val_accuracy: 0.8158\n",
            "Epoch 667/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4721 - accuracy: 0.8293 - val_loss: 0.4871 - val_accuracy: 0.8153\n",
            "Epoch 668/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4719 - accuracy: 0.8289 - val_loss: 0.4850 - val_accuracy: 0.8189\n",
            "Epoch 669/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4718 - accuracy: 0.8291 - val_loss: 0.4857 - val_accuracy: 0.8197\n",
            "Epoch 670/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4716 - accuracy: 0.8287 - val_loss: 0.4852 - val_accuracy: 0.8191\n",
            "Epoch 671/850\n",
            "52/52 [==============================] - 1s 17ms/step - loss: 0.4712 - accuracy: 0.8298 - val_loss: 0.4874 - val_accuracy: 0.8189\n",
            "Epoch 672/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4715 - accuracy: 0.8299 - val_loss: 0.4862 - val_accuracy: 0.8191\n",
            "Epoch 673/850\n",
            "52/52 [==============================] - 1s 22ms/step - loss: 0.4709 - accuracy: 0.8312 - val_loss: 0.4842 - val_accuracy: 0.8244\n",
            "Epoch 674/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4719 - accuracy: 0.8290 - val_loss: 0.4899 - val_accuracy: 0.8189\n",
            "Epoch 675/850\n",
            "52/52 [==============================] - 1s 23ms/step - loss: 0.4728 - accuracy: 0.8289 - val_loss: 0.4899 - val_accuracy: 0.8227\n",
            "Epoch 676/850\n",
            "52/52 [==============================] - 1s 18ms/step - loss: 0.4720 - accuracy: 0.8296 - val_loss: 0.4846 - val_accuracy: 0.8186\n",
            "Epoch 677/850\n",
            "52/52 [==============================] - 1s 15ms/step - loss: 0.4714 - accuracy: 0.8294 - val_loss: 0.4878 - val_accuracy: 0.8208\n",
            "Epoch 678/850\n",
            "33/52 [==================>...........] - ETA: 0s - loss: 0.4722 - accuracy: 0.8258"
          ]
        }
      ],
      "source": [
        "#2. Build the deep neural model\n",
        "init = he_normal(seed=1243)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=16, batch_size=BATCH_SIZE))\n",
        "for neurons in neurons_per_layer:\n",
        "  model.add(Dense(neurons, activation=\"relu\", kernel_initializer=init, kernel_regularizer = l2(0.005)))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer = l2(0.005)))\n",
        "#3. Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "#4. Train the model with M-BGD\n",
        "train22 = model.fit(data_train, labels_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(data_dev, labels_dev))\n",
        "# Save the results\n",
        "results=pd.DataFrame(train22.history)\n",
        "path = \"/gdrive/MyDrive/GIA/AA2/trainHistoryModel22.csv\"\n",
        "results.to_csv(path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "11lMK48PFg8l",
        "outputId": "6ca1ad4c-1869-4bf5-db53-08c8fd79aae3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss = train22.history[\"loss\"]\n",
        "\n",
        "plt.plot(range(1, len(loss) + 1), loss, 'b', label='Error de entrenamiento')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYJvlHfvFisz",
        "outputId": "abd90a76-ebca-4ea1-f6f8-de72a08deba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114/114 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(data_dev)\n",
        "predictions_binary = np.round(predictions)\n",
        "print(classification_report(labels_dev.values, predictions_binary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpGSyy8eb_D9"
      },
      "source": [
        "### Model 2.3: l2(0.001)\n",
        "Same model but changing the l2 regularizer from 0.005 to 0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EofMfYkyFq0I"
      },
      "outputs": [],
      "source": [
        "#2. Build the deep neural model\n",
        "init = he_normal(seed=1243)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=16, batch_size=BATCH_SIZE))\n",
        "for neurons in neurons_per_layer:\n",
        "  model.add(Dense(neurons, activation=\"relu\", kernel_initializer=init, kernel_regularizer = l2(0.001)))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer = l2(0.001)))\n",
        "#3. Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "#4. Train the model with M-BGD\n",
        "train23 = model.fit(data_train, labels_train, epochs = EPOCHS, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt_shND0F2E-",
        "outputId": "59862941-e689-4319-8321-b99c70e40e5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114/114 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(data_dev)\n",
        "predictions_binary = np.round(predictions)\n",
        "print(classification_report(labels_dev.values, predictions_binary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSJA2B9RcDsI"
      },
      "source": [
        "## Third model: dropout regularizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LN2LeJxIrdK"
      },
      "source": [
        "NO NOS HA CONVENCIDO MUCHO EL USO DEL L2, POR LO QUE PROBAREMOS A HACER DROPOUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wMADw_ZdY9A"
      },
      "source": [
        "### Model 3.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8zWAnZ6IyNU"
      },
      "outputs": [],
      "source": [
        "init = he_normal(seed=1243)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=16, batch_size=BATCH_SIZE))\n",
        "for neurons in neurons_per_layer:\n",
        "  model.add(Dropout(rate=0.1))\n",
        "  model.add(Dense(neurons, activation=\"relu\", kernel_initializer=init, kernel_regularizer = l2(0.001)))\n",
        "model.add(Dropout(rate=0.1))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer = l2(0.001)))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "train31 = model.fit(data_train, labels_train, epochs = EPOCHS, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtcdS-NdKeSq"
      },
      "source": [
        "CON DROPOUT DE 0.3 OBTENEMOS EN TRAIN UN 0.5 DE LOSS Y UN ACCURACY DE ALREDEDOR DE 0.75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "5isonOXZJ-vz",
        "outputId": "ad1bf10a-07ae-4967-f500-57b335049c8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss = train.history[\"loss\"]\n",
        "\n",
        "plt.plot(range(1, len(loss) + 1), loss, 'b', label='Error de entrenamiento')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QqD5XDmKGwf",
        "outputId": "d319dc76-45dd-4718-9ece-ef7250de6579"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114/114 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(data_dev)\n",
        "predictions_binary = np.round(predictions)\n",
        "print(classification_report(labels_dev, predictions_binary))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJa1oHJ_Mo6F"
      },
      "source": [
        "CON DROPOUT OBTENEMOS RESULTADOS BASTANTE MALOS, POR LO QUE VAMOS A INTENTAR AUMENTAR EL ACCURACY DE LA ANTERIOR RED QUE USADA L2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0eZiLv-dkYY"
      },
      "source": [
        "## Fourth model: change some hyper-parameters\n",
        "Adding one more hidden layer, more neurons per layer and more epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkI75TsNM0OZ"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 1500\n",
        "BATCH_SIZE = 558\n",
        "neurons_per_layer = [250, 500, 700, 500, 350, 150]\n",
        "\n",
        "init = he_normal(seed=1234)\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=16, batch_size=BATCH_SIZE))\n",
        "for neurons in neurons_per_layer:\n",
        "  model.add(Dense(neurons, activation=\"relu\", kernel_initializer=init, kernel_regularizer = l2(0.001)))\n",
        "model.add(Dense(1, activation=\"sigmoid\", kernel_regularizer = l2(0.001)))\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "train4 = model.fit(data_train, labels_train, epochs = EPOCHS, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "s6uHwiBlNZ4O",
        "outputId": "bd55abfc-9c71-4512-94aa-6c7f2730d8f1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss = train4.history[\"loss\"]\n",
        "\n",
        "plt.plot(range(1, len(loss) + 1), loss, 'b', label='Error de entrenamiento')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "ucL0uhbUNeXX",
        "outputId": "79a5b145-43bf-4516-95e1-9c56bcc00cea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>matplotlib.pyplot.show</b><br/>def show(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py</a>Display all open figures.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "block : bool, optional\n",
              "    Whether to wait for all figures to be closed before returning.\n",
              "\n",
              "    If `True` block and run the GUI main loop until all figure windows\n",
              "    are closed.\n",
              "\n",
              "    If `False` ensure that all figure windows are displayed and return\n",
              "    immediately.  In this case, you are responsible for ensuring\n",
              "    that the event loop is running to have responsive figures.\n",
              "\n",
              "    Defaults to True in non-interactive mode and to False in interactive\n",
              "    mode (see `.pyplot.isinteractive`).\n",
              "\n",
              "See Also\n",
              "--------\n",
              "ion : Enable interactive mode, which shows / updates the figure after\n",
              "      every plotting command, so that calling ``show()`` is not necessary.\n",
              "ioff : Disable interactive mode.\n",
              "savefig : Save the figure to an image file instead of showing it on screen.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "**Saving figures to file and showing a window at the same time**\n",
              "\n",
              "If you want an image file as well as a user interface window, use\n",
              "`.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\n",
              "``show()`` the figure is closed and thus unregistered from pyplot. Calling\n",
              "`.pyplot.savefig` afterwards would save a new and thus empty figure. This\n",
              "limitation of command order does not apply if the show is non-blocking or\n",
              "if you keep a reference to the figure and use `.Figure.savefig`.\n",
              "\n",
              "**Auto-show in jupyter notebooks**\n",
              "\n",
              "The jupyter backends (activated via ``%matplotlib inline``,\n",
              "``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\n",
              "the end of every cell by default. Thus, you usually don&#x27;t have to call it\n",
              "explicitly there.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 401);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "accuracy = train4.history[\"accuracy\"]\n",
        "\n",
        "plt.plot(range(1, len(accuracy) + 1), accuracy, 'b')\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHueLgRKNki6",
        "outputId": "a6149171-2a0f-411f-f00b-add369093f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "114/114 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(data_dev)\n",
        "predictions_binary = np.round(predictions)\n",
        "print(classification_report(labels_dev, predictions_binary))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}